<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gam0022.net</title>
    <link>https://gam0022.net/tags/gpu/index.xml</link>
    <description>Recent content on gam0022.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <copyright>&amp;copy; 2021 gam0022</copyright>
    <atom:link href="/tags/gpu/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>速度比較！レイマーチングvsレイキャスティング</title>
      <link>https://gam0022.net/blog/2022/08/08/raymarching-vs-raycasting/</link>
      <pubDate>Mon, 08 Aug 2022 02:12:50 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2022/08/08/raymarching-vs-raycasting/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://sites.google.com/view/raytracingcamp8&#34;&gt;レイトレ合宿8&lt;/a&gt;のアドベントカレンダーです。&lt;/p&gt;

&lt;p&gt;レイマーチングはレイキャスティングと比べて遅いと感じていましたが、なるべく同じ条件で計測した場合に実際どのくらい差があるのか比較してみました。&lt;/p&gt;

&lt;h1 id=&#34;検証内容の概要&#34;&gt;検証内容の概要&lt;/h1&gt;

&lt;p&gt;メンガーのスポンジをレイマーチングとレイキャスティングでそれぞれ交差判定を実装し、フラクタルの深度を1～4に変化しながら計測しました。&lt;/p&gt;

&lt;p&gt;次の画像はレイマーチングによる深度4のメンガーのスポンジです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256_l300.png&#34; alt=&#34;レイマーチング 深度4 300ステップ&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;計測結果のサマリー&#34;&gt;計測結果のサマリー&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;先に結果から発表すると、なんとレイマーチングはレイキャスティングの15～20倍くらい遅いようでした。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ここまで遅いなんてショック😨…&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/result_graph.png&#34; alt=&#34;計測結果の棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;256サンプリング時のレンダリング時間（秒）&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイマーチング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.85388秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i1_s256.png&#34; alt=&#34;レイマーチング 深度1&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.00077秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i2_s256.png&#34; alt=&#34;レイマーチング 深度2&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.14309秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i3_s256.png&#34; alt=&#34;レイマーチング 深度3&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.29724秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256.png&#34; alt=&#34;レイマーチング 深度4&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイキャスティング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.445493秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i1_s256.png&#34; alt=&#34;レイキャスティング 深度1&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.466056秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i2_s256.png&#34; alt=&#34;レイキャスティング 深度2&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50258秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i3_s256.png&#34; alt=&#34;レイキャスティング 深度3&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.602458秒 &lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i4_s256.png&#34; alt=&#34;レイキャスティング 深度4&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;検証内容の詳細&#34;&gt;検証内容の詳細&lt;/h1&gt;

&lt;h2 id=&#34;検証pcのスペック&#34;&gt;検証PCのスペック&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;OS: Windows 11&lt;/li&gt;
&lt;li&gt;CPU: Core i7-12700K&lt;/li&gt;
&lt;li&gt;GPU: GeForce RTX 3080&lt;/li&gt;
&lt;li&gt;メモリ: 64GB (3200MHz)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このピカピカ光るPCで検証しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;my new gear&amp;hellip; &lt;a href=&#34;https://t.co/eS2MbH7OKc&#34;&gt;pic.twitter.com/eS2MbH7OKc&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1546700194305437696?ref_src=twsrc%5Etfw&#34;&gt;July 12, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;共通条件&#34;&gt;共通条件&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;レンダラーはNVIDIA OptiX 7.5上で実装&lt;/li&gt;
&lt;li&gt;256サンプリングする時間を計測

&lt;ul&gt;
&lt;li&gt;1回のoptixLaunchで256サンプリング&lt;/li&gt;
&lt;li&gt;Ray generationプログラム（CUDAの関数）の中で256回ループ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;出力解像度は1920x1080&lt;/li&gt;
&lt;li&gt;計測時間の詳細

&lt;ul&gt;
&lt;li&gt;シーンの初期化やBVHの構築は含まない&lt;/li&gt;
&lt;li&gt;optixLaunchの実行時間を計測&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;シェーディングはパストレーシング

&lt;ul&gt;
&lt;li&gt;マテリアルは拡散反射のみ&lt;/li&gt;
&lt;li&gt;NEEやMISはしないシンプルなパストレーシング&lt;/li&gt;
&lt;li&gt;反射の最大震度は5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;レイマーチング&#34;&gt;レイマーチング&lt;/h2&gt;

&lt;p&gt;レイマーチングは繰り返しの計算で数値的な衝突判定の手法で、Sphere Tracingとも呼ばれます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;レイマーチングの最大ステップ回数（マーチングループのループ数）は100&lt;/li&gt;
&lt;li&gt;Intersectionプログラム（CUDAの関数）としてレイマーチングを実装

&lt;ul&gt;
&lt;li&gt;詳細は&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;過去の記事&lt;/a&gt;を参照&lt;/li&gt;
&lt;li&gt;Optix6の内容なので、Optix7対応のために実装を多少修正&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;高速化のためにカメラからレイは飛ばさずに、バウンディングボックスからレイを飛ばす

&lt;ul&gt;
&lt;li&gt;バウンディングボックスは最適になるようにギリギリに設定&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;レイキャスティング&#34;&gt;レイキャスティング&lt;/h2&gt;

&lt;p&gt;今回のレイキャスティングとは、レイと三角形の解析的な交差判定のことです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;メンガースポンジはHoudiniでモデリング

&lt;ul&gt;
&lt;li&gt;詳細は&lt;a href=&#34;https://gam0022.net/blog/2018/06/08/houdini/&#34;&gt;過去の記事&lt;/a&gt;を参照&lt;/li&gt;
&lt;li&gt;フラクタルの深度を指定可能にアップデート（ツイート参照）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Houdiniからobjで出力して自作のレンダラーで読み込み

&lt;ul&gt;
&lt;li&gt;OptiX7.xではobjのローダーが無かったので自作…&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OptiXのビルトインの機能で衝突判定

&lt;ul&gt;
&lt;li&gt;OptiX上では三角ポリゴンの集合として表現&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OptiXの機能でGAS（Geometry acceleration structure）を構築

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RTコアによるレイトレーシングのハードウェアアクセラレーションあり&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;フラクタルの再帰回数を自由に増やせるようになった。&lt;br&gt;HoudiniのTOPs Feedback Loopの良い使用例ですね。 &lt;a href=&#34;https://t.co/yTR60S5vgC&#34;&gt;https://t.co/yTR60S5vgC&lt;/a&gt; &lt;a href=&#34;https://t.co/OifBfoTCFa&#34;&gt;pic.twitter.com/OifBfoTCFa&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1556203400257503232?ref_src=twsrc%5Etfw&#34;&gt;August 7, 2022&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;結果詳細&#34;&gt;結果詳細&lt;/h1&gt;

&lt;p&gt;改めて計測結果を見てみましょう。&lt;/p&gt;

&lt;h2 id=&#34;レンダリング時間&#34;&gt;レンダリング時間&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/result_graph.png&#34; alt=&#34;計測結果の棒グラフ&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイマーチング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.85388&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.00077&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.14309&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.29724&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;レイキャスティング&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.445493&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.466056&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50258&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.602458&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;レンダリング時間以外&#34;&gt;レンダリング時間以外&lt;/h2&gt;

&lt;p&gt;レンダリング時間以外のデータです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GAS（Geometry Acceleration Structure）の構築時間（秒）

&lt;ul&gt;
&lt;li&gt;レイキャスティングのみの結果&lt;/li&gt;
&lt;li&gt;レイマーチングではAABBはできてもBVHを構築できない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ポリゴンの頂点数&lt;/li&gt;
&lt;li&gt;レイマーチングがレイキャスティングの何倍の時間がかかっているか&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;フラクタルの深度&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;GASの構築時間（秒）&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0008289&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0010064&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0030907&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0135217&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ポリゴンの頂点数&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;480&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;192000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3840000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;倍率（Raymarching / Raycasting）&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.87434146&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.31263625&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.19230769&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15.4321795&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;GASの構築は思ったより速いんですね。380万頂点でも0.01秒で完了しているのは驚きです。&lt;/p&gt;

&lt;p&gt;ポリゴンの頂点数は指数で増加しても描画時間は大きく変わらないので、Acceleration Structureは本当に偉大ですね🙏&lt;/p&gt;

&lt;p&gt;倍率について、フラクタルの深度が増えればレイマーチングの方が有利だと予想していましたが、予想通りにその傾向はありました。
ですが、思ったよりも差が縮まらないんだというのが率直な感想です。&lt;/p&gt;

&lt;h2 id=&#34;レンダリング結果&#34;&gt;レンダリング結果&lt;/h2&gt;

&lt;p&gt;大きなサイズのレンダリング結果です。&lt;/p&gt;

&lt;p&gt;異なるアルゴリズムでモデリングしているので、ジオメトリーは完全一致ではありません。&lt;/p&gt;

&lt;p&gt;記事を書いている途中で発覚しましたが、レイマーチングのステップ回数100では上部の法線とレイの角度が急な箇所でエラーが起きていました。
サムネの画像ではステップ回数300で再レンダリングして15.7267秒でした。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度1&#34;&gt;レイマーチング 深度1&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i1_s256.png&#34; alt=&#34;レイマーチング 深度1&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度2&#34;&gt;レイマーチング 深度2&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i2_s256.png&#34; alt=&#34;レイマーチング 深度2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度3&#34;&gt;レイマーチング 深度3&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i3_s256.png&#34; alt=&#34;レイマーチング 深度3&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイマーチング-深度4&#34;&gt;レイマーチング 深度4&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raymarching_i4_s256.png&#34; alt=&#34;レイマーチング 深度4&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度1&#34;&gt;レイキャスティング 深度1&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i1_s256.png&#34; alt=&#34;レイキャスティング 深度1&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度2&#34;&gt;レイキャスティング 深度2&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i2_s256.png&#34; alt=&#34;レイキャスティング 深度2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度3&#34;&gt;レイキャスティング 深度3&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i3_s256.png&#34; alt=&#34;レイキャスティング 深度3&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;レイキャスティング-深度4&#34;&gt;レイキャスティング 深度4&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2022-08-08-raymarching-vs-raycasting/raycast_i4_s256.png&#34; alt=&#34;レイキャスティング 深度4&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイマーチングの高速化手法&#34;&gt;レイマーチングの高速化手法&lt;/h1&gt;

&lt;p&gt;レイマーチングの高速化手法を軽く調べてみました。&lt;/p&gt;

&lt;p&gt;EnhancedSphereTracingやAccelerating Sphere Tracingはレイマーチングのステップを少し大きく調整してステップ数を減らす手法です。
IFSやMod Repetitionと乱数の組み合わせによる非連続な距離関数だとうまくいかない気もしていますが、ちゃんと試したことはないので分かりません。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;EnhancedSphereTracing [Benjamin Keinert 2014]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://erleuchtet.org/~cupe/permanent/enhanced_sphere_tracing.pdf&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/Hirai0827/items/eddcb73a1976c3088b88&#34;&gt;日本語解説 by @lucknknock さん&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Accelerating Sphere Tracing [Csaba Bálint 2018]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/331547302_Accelerating_Sphere_Tracing&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/Hirai0827/items/e05e13f343357d648b1b&#34;&gt;日本語解説 by @lucknknock さん&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cone Marchingは非連続な距離関数でもおそらく適用できそうです。
低解像度でDepthを計算しておいて、高解像度でDepthを引き継いでレイマーチングをすることで、トータルで距離関数の評価回数をかなり削減できます。
しかし、プライマリレイにしか適用できないため、パストレーシングでは効果が低そうです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.fulcrum-demo.org/wp-content/uploads/2012/04/Cone_Marching_Mandelbox_by_Seven_Fulcrum_LongVersion.pdf&#34;&gt;Cone_Marching_Mandelbox_by_Seven_Fulcrum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jp.gamesindustry.biz/article/1803/18032802/&#34;&gt;［GDC 2018］Cone Marching法で描くフラクタルVRの世界「CORAL」&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;このあたりはよく読んでいません。自分のための備忘録です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A Geometric Method for Accelerated Sphere Tracing of Implicit Surfaces [Csaba Bálint 2021]

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cyber.bibl.u-szeged.hu/index.php/actcybern/article/view/4203&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;後で読む&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Real-Time Rendering of Complex Fractals

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4842-7185-8_33&#34;&gt;リンク&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Real-Time Renderingの章らしいが、単なるレイマーチングの紹介かもしれない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Area Lights in Signed Distance Function Scenes

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://diglib.eg.org/bitstream/handle/10.2312/egs20191021/085-088.pdf?sequence=1&amp;amp;isAllowed=y&#34;&gt;論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;衝突判定ではないが気になるのでメモ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;レイマーチングはめちゃくちゃ遅いので、レイトレ合宿のようにレンダリング時間がシビアなら悪手かもしれません。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>レイトレ合宿7でレイマーチング対応のGPUパストレーサーを実装しました！</title>
      <link>https://gam0022.net/blog/2019/09/18/rtcamp7/</link>
      <pubDate>Wed, 18 Sep 2019 10:15:43 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/09/18/rtcamp7/</guid>
      <description>&lt;p&gt;9月7日(土)～9月8日(日)に猪苗代湖で開催された&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;自作のレンダラーでこんな画像を &lt;strong&gt;60秒の制限時間&lt;/strong&gt; でレンダリングして4位をいただきました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.jpg&#34; alt=&#34;本番のレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに4K解像度（3840x2160）です！&lt;/p&gt;

&lt;p&gt;事前に本番環境で動作確認できなかったこともあり、よく見ると意図しないアーティファクトが発生しているのですが、許容レベルに収まったのはラッキーでした。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイトレ合宿とは&#34;&gt;レイトレ合宿とは&lt;/h1&gt;

&lt;p&gt;レイトレ合宿は完全自作のレイトレーサーを走らせて画像の美しさを競うイベントです。&lt;/p&gt;

&lt;p&gt;参加者はレンダラーを自作する必要がある！というだけで面白いイベントなのですが、レンダリングの制限時間が毎年どんどん短縮されているのも注目ポイントです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sites.google.com/site/rendering1h/&#34;&gt;第1回のレンダリング合宿&lt;/a&gt;では制限時間が1時間だったのですが、第7回となる今年は60秒制限でした。&lt;/p&gt;

&lt;p&gt;この制限時間はレンダラーを起動してから画像を保存するまでの時間なので、シーンの読み込みからレンダリングをすべて含めて60秒で完了させなくてはなりません。&lt;/p&gt;

&lt;p&gt;そのため、参加者はあらゆる手段をつかって、レンダラーの高速化に本気で取り組む必要があります。&lt;/p&gt;

&lt;p&gt;パストレーシングの高速化のアプローチとしては、サンプリングを効率化する、BVHなどの構造をつかってシーンとの交差判定を効率化する、ノイズを軽減するためにデノイズを行う、などが挙げられます。&lt;/p&gt;

&lt;p&gt;パストレーシングを使わないといけないルールは無いのですが、近年のレイトレ合宿ではパストレーシングが人気です。
今年のレイトレ合宿では、Stochastic Progressive Photon Mappingを実装した&lt;a href=&#34;https://github.com/tabochans&#34;&gt;tabochan&lt;/a&gt;さん以外は全員パストレーシングだったと記憶しています。&lt;/p&gt;

&lt;p&gt;また、複数コアのCPU・複数のGPUを利用したり、メモリのキャッシュ効率を上げてマシンスペックを最大限に活かし切るというのも、実はかなり難しい課題だったりします。私は今年は複数のGPUをうまく使えませんでした…&lt;/p&gt;

&lt;p&gt;参加者はプロダクションレンダラーの開発者やコンピュータグラフィック分野の研究者などのプロの人から、私のように趣味でレンダラーを開発している人まで様々です。&lt;/p&gt;

&lt;p&gt;レイトレ合宿の参加者のレベルが年々向上していて、特に今年は技術的にもアートセンスにも秀でた作品が多い中、4位と上位に食い込めて本当に嬉しかったです！&lt;/p&gt;

&lt;h1 id=&#34;前回までのレイトレ合宿の参加レポート&#34;&gt;前回までのレイトレ合宿の参加レポート&lt;/h1&gt;

&lt;p&gt;ちなみに私は今年で4回目の参加になります。過去の参加レポートはこちらです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/25/rtcamp6-part2/&#34;&gt;レイトレ合宿6 参加報告 Part2（当日編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/18/rtcamp6-part1/&#34;&gt;レイトレ合宿6 参加報告 前編（準備編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/10/02/rtcamp5/&#34;&gt;レイトレ合宿5‽に参加して、Rustでパストレーシングを実装しました！ | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.hatenablog.com/entry/raytracingcamp4&#34;&gt;レイトレ合宿4!? に参加しました！ - gam0022のブログ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redflash-renderer&#34;&gt;Redflash Renderer&lt;/h1&gt;

&lt;p&gt;Redflash というGPUレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;Redflash は NVIDIA® OptiX 6.0 上で実装したパストレーシングによる物理ベースレンダラーで、ポリゴンと &lt;strong&gt;レイマーチング&lt;/strong&gt; が混在したシーンを一貫した描画ができます。&lt;/p&gt;

&lt;p&gt;GitHubにソースコードを公開しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/redflash&#34;&gt;https://github.com/gam0022/redflash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こちらはアーティファクトなしの想定のレンダリング結果です。レンダリングは30分です。クリックすると非圧縮形式の画像になります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030_1920x1080.jpg&#34; alt=&#34;想定したレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;別視点からのレンダリング結果も紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34; alt=&#34;別視点からのレンダリング結果1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.jpg&#34; alt=&#34;別視点からのレンダリング結果2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.jpg&#34; alt=&#34;別視点からのレンダリング結果3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;自作レンダラーの紹介スライドです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;ba3966aad908467e8b21249e828c26d0&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;レイトレ合宿の参加者にとっては常識だと思われる箇所の説明を省略してしまったので、ここから簡単に補足解説をします。&lt;/p&gt;

&lt;h2 id=&#34;neeとmisによるサンプリングの効率化&#34;&gt;NEEとMISによるサンプリングの効率化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.003.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この2つは「パストレーシングのサンプリングを効率化する」ための非常に有名なテクニックです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Next Event Estimation (Direct Light Sampling)&lt;/li&gt;
&lt;li&gt;Multiple Importance Sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next Event EstimationはよくNEEと省略されて呼ばれます。
光源が小さいシーンでは、BSDFによる重点的サンプリングだけではなかなか光源にヒットしません。
そのため、短い計算時間ではノイズだらけの結果になってしまいます。
また、BSDFの分布と光源の方向が異なる場合、むしろBSDFによる重点的サンプリングによって悪化するケースもありえます。
そこで、光源の表面上の点を明示的にサンプリングして光転送経路を生成することで、効率的なサンプリングを行うテクニックがNEEです。&lt;/p&gt;

&lt;p&gt;Multiple Importance SamplingはよくMISと省略されて呼ばれます。
MISは複数のサンプリング戦略を組み合わせることでサンプリングの効率を向上するテクニックです。
具体的には「BSDFによる重点的サンプリング」と「NEEによるライトのサンプリング」の2つの戦略の結果を適切なウェイトで組み合わせることで、サンプリングの効率を向上します。
それぞれのサンプリング戦略が得意な部分だけウェイトを大きくすることで、分散を抑えて効率的にサンプリングができるようになります。
例えば、光源が大きくてroughnessが大きいような「BSDFによる重点的サンプリング」が得意なケースなら「BSDFによる重点的サンプリング」の重みを大きくして、
逆に光源が小さくてroughnessが小さいような「NEEによるライトのサンプリング」が得意なケースなら「NEEによるライトのサンプリング」の重みを大きくします。&lt;/p&gt;

&lt;p&gt;NEEやMISについては、レイトレ合宿の参加者でもある &lt;a href=&#34;https://twitter.com/Shocker_0x15&#34;&gt;@Shocker_0x15&lt;/a&gt; さんが日本語で詳しく記事を書かれています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/path_tracing/&#34;&gt;パストレーシング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/MIS/&#34;&gt;多重重点的サンプリング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;optixとレイマーチングの統合&#34;&gt;OptiXとレイマーチングの統合&lt;/h2&gt;

&lt;p&gt;OptiXには独自のプリミティブを定義する仕組みがあるため、OptiXとレイマーチングの統合はそこまで苦労しませんでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IntersectionProgram&lt;/code&gt; と &lt;code&gt;BoundingBoxProgram&lt;/code&gt; としてレイマーチングによる交差判定とAABBの定義をCUDAで実装するだけでできました。&lt;/p&gt;

&lt;p&gt;詳細はレイトレ合宿アドベントカレンダーの記事で既に紹介しているので、気になる方は読んでみてください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;衝突判定の高速化&#34;&gt;衝突判定の高速化&lt;/h2&gt;

&lt;p&gt;BVHの構築はOptiXが自動でやってくれるので、ポリゴンの衝突判定は特に高速化しませんでした。
なんとOptiX 6.0ではRTXに対応しているので、RTX 2070ではハードウェアをつかって高速化な衝突判定ができました！（が、本番環境はRTX非対応でした…）&lt;/p&gt;

&lt;p&gt;一方でレイマーチングの衝突判定については自力で行う必要がありました。
シーン全体を1個の距離関数で表現したため、BVHなどの構造では衝突判定の高速化が難しいためです。&lt;/p&gt;

&lt;h3 id=&#34;距離関数の軽量化&#34;&gt;距離関数の軽量化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.008.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レイマーチングでは1本をレイを飛ばすごとに数百回も距離関数を評価する必要があります（今回のレンダリング結果は300回）。&lt;/p&gt;

&lt;p&gt;レイマーチングの負荷は距離関数の複雑さに比例するので、距離関数の軽量化は効果が大きい最適化でした。&lt;/p&gt;

&lt;p&gt;今回はMandelboxという伝統的なフラクタル図形を距離関数として用いたのですが、
メジャーなMandelboxの実装では &lt;code&gt;sphereFold&lt;/code&gt; という操作で分岐があったりとGPUには高負荷なものでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sphereFold&lt;/code&gt; のどちらの分岐に入るかはMandelboxのパラメータによって決まるので、
一部のパラメータを削除したり、パラメータの範囲を狭めることで分岐を削除して処理を簡略化しました。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチングの衝突判定の精度のlod&#34;&gt;レイマーチングの衝突判定の精度のLOD&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.009.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 1/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まず速度面では、カメラに近い部分は細部まで正確に衝突判定をする必要がありますが、遠い部分は大雑把でも問題にならないため、LODが有効でした。&lt;/p&gt;

&lt;p&gt;品質面でもLODが必要でした。
Mandelboxの距離関数は厳密には Distance Estimator（距離推定器）と呼ばれるものです。
通常の距離関数は表面までの距離をぴったりと計算できるのに対して、
Distance Estimatorは有限のイテレーション回数では表面に漸近しても、距離0になりません。&lt;/p&gt;

&lt;p&gt;そのため、適当な距離 eps で衝突とみなして計算を打ち切る必要があります。
また、eps を小さくすると、より細かい detail まで可視化できるのですが、
遠景まで同じ eps で処理すると高周波成分が現れて、まるでMipMap OFFのような汚い結果となります。&lt;/p&gt;

&lt;p&gt;このようにレイマーチングの高速化と品質向上の2つの目的ために、衝突判定の精度のLODが必要でした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.010.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 2/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LODはカメラからの距離に応じて動的に eps を決定することで実現しました。&lt;/p&gt;

&lt;p&gt;レイマーチングではレイを漸近的に進めるため、レイが進んだ距離を必ず計算する必要があります。
このとき &lt;code&gt;レイが進んだ距離 = カメラからの距離&lt;/code&gt; となるため、eps は簡単に決定できます。&lt;/p&gt;

&lt;p&gt;具体的にはレイが進んだ距離に定数を乗算したものを eps として扱うようにしました。&lt;/p&gt;

&lt;p&gt;今回の提出シーンのように同じレイマーチングのオブジェクトの近影〜遠景がひとつのカットで混在していても、綺麗に描画できるようになりました。&lt;/p&gt;

&lt;p&gt;また、カメラを近づけると実質無限に細部が現れるようになりました（フラクタル図形の特徴）。&lt;/p&gt;

&lt;h3 id=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34;&gt;1回のlaunchでなるべくたくさんサンプリングする戦略&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.011.jpeg&#34; alt=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OptiXでパストレーシングを実装する場合、通常は1回のlaunchでパストレーシングの1サンプリングを行うように実装するかと思います。&lt;/p&gt;

&lt;p&gt;ところが、launchにも多少のオーバーヘッドがあるため、手元のPCで実験した結果では、
&lt;code&gt;sample_per_launch&lt;/code&gt; （1回のlaunchごとのサンプリング回数）を大きくすれば大きくするほど60秒あたりのサンプリング回数を増やすことができました。&lt;/p&gt;

&lt;p&gt;そこで、最初の4サンプリングでマシンの性能をベンチマークして時間切れにならない最大の sample_per_launch を決定するような戦略をとりました。&lt;/p&gt;

&lt;h2 id=&#34;deep-learning-denoising&#34;&gt;Deep Learning Denoising&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.012.jpeg&#34; alt=&#34;Deep Learning Denoising&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディープラーニングをつかったデノイザーの性能が驚異的に良くて驚きました。&lt;/p&gt;

&lt;p&gt;左が10spp（sample per pixel）の結果で、右がデノイズした結果です。&lt;/p&gt;

&lt;p&gt;かなり少ないサンプリング数でも非常に綺麗にデノイズができました。
特にLucy像の拡散面の部分などは効果が絶大でした。&lt;/p&gt;

&lt;p&gt;Deep Learning DenoisingはOptiXの標準機能を利用しただけなので、詳細については私は理解していません。&lt;/p&gt;

&lt;p&gt;レンダリング結果とnormalとalbedoのバッファを与えてやると、綺麗にデノイズした結果を出力してくれました。&lt;/p&gt;

&lt;p&gt;速度面でも優秀で4K解像度でも&lt;a href=&#34;https://github.com/gam0022/redflash/pull/34&#34;&gt;1.4秒程度&lt;/a&gt;でデノイズが完了しました。&lt;/p&gt;

&lt;p&gt;まだリアルタイムレンダリングには速度的には使いづらいかもしれませんが、これまでの Bilateral Filter や Non-local Means Filter を遥かに凌駕する性能なので、改めてレンダリング技術とディープラーニングの親和性の高さを実感しました。&lt;/p&gt;

&lt;p&gt;これからの時代はグラフィックエンジニアもディープラーニングも勉強しなくては！と思いました。&lt;/p&gt;

&lt;h3 id=&#34;rt-buffer-gpu-local-による最適化&#34;&gt;RT_BUFFER_GPU_LOCAL による最適化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.013.jpeg&#34; alt=&#34;RT_BUFFER_GPU_LOCAL による最適化&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Deep Learning Denoising用にalbedoとnormalのバッファを生成したところ、合計で5枚もバッファが必要になりました。
バッファの読み書きもそれなりに重たい処理なので、対策を行いました。
createBuffer の第1引数に &lt;code&gt;RT_BUFFER_INPUT_OUTPUT&lt;/code&gt; を指定したところ、なんと13.6%くらい高速化しました。&lt;/p&gt;

&lt;p&gt;ディスプレイにバッファを同期するかのオプションのようでした。
ウィンドウにバッファを表示する場合はこのオプションをつけると描画結果が同期されなくなってしまいますが、
CUIモードで起動するときには同期は不要なので、このオプションを有効にすることで大幅に性能向上できました。&lt;/p&gt;

&lt;h1 id=&#34;反省-スケジュール面が厳しすぎた&#34;&gt;反省：スケジュール面が厳しすぎた&lt;/h1&gt;

&lt;p&gt;ここまでがレンダラーの紹介でした。ここからは振り返りを書こうと思います。&lt;/p&gt;

&lt;p&gt;最大の反省点はスケジュール面が厳しすぎたことでした…&lt;/p&gt;

&lt;p&gt;OptiXのキャッチアップを含めて約一ヶ月で開発したのですが、流石に無理なスケジュールだったと思います。&lt;/p&gt;

&lt;p&gt;8月は仕事のプロジェクトの追い込み時期とCEDECの登壇準備が重なって、なかなかレンダラー開発の時間を捻出できず、
睡眠時間と生活を削りすぎたため、体力的にも精神的にもかなり限界でした…&lt;/p&gt;

&lt;p&gt;そろそろ若さで無茶をカバーできない年齢になってきたので、締め切り直前になって慌てて開発するのではなく、
日頃から継続的にレンダラーを開発することが大事だろうと思います。&lt;/p&gt;

&lt;h1 id=&#34;余談-シーン作成はunity&#34;&gt;余談：シーン作成はUnity&lt;/h1&gt;

&lt;p&gt;時間がなくてシーン編集機能を実装できなかったので、
Unityで事前に距離関数のパラメータ調整や光源の配置を行ってシーンのイメージを固めてから、後からパラメータを自作レンダラーに移植しました。&lt;/p&gt;

&lt;p&gt;結果的には納得できるシーンを作成できたので、作戦は成功だったと思います。&lt;/p&gt;

&lt;p&gt;UnityのHDRPでレイマーチングを行うのには&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;@kanetaaaaa&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/kaneta1992/RaymarchingInHDRP/&#34;&gt;RaymarchingInHDRP&lt;/a&gt;を利用させていただきました。&lt;/p&gt;

&lt;p&gt;カッコいいシーンを大量に作れたので、ついスクリーンショットをたくさん撮影してしまいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unity HDRP + Raymarching by &lt;a href=&#34;https://twitter.com/kanetaaaaa?ref_src=twsrc%5Etfw&#34;&gt;@kanetaaaaa&lt;/a&gt; を試してみました！&lt;br&gt;カッコいいシーンが無限に作れてしまう😍&lt;br&gt;これは凄いです🙏&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#raymarching&lt;/a&gt;&lt;a href=&#34;https://t.co/EK6JsHpTBZ&#34;&gt;https://t.co/EK6JsHpTBZ&lt;/a&gt; &lt;a href=&#34;https://t.co/ZueP2hfzet&#34;&gt;pic.twitter.com/ZueP2hfzet&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1163876089489285120?ref_src=twsrc%5Etfw&#34;&gt;August 20, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;今後やりたいこと&#34;&gt;今後やりたいこと&lt;/h1&gt;

&lt;h2 id=&#34;シーン編集機能がほしい&#34;&gt;シーン編集機能がほしい&lt;/h2&gt;

&lt;p&gt;現状はGUIでカメラ操作だけができます。&lt;/p&gt;

&lt;p&gt;シーン編集に関して、上で紹介したようなUnityからパラメータを移植する方法だと最終的なルックの確認のイテレーションの高速化がしずらいので、
Redflash自体にシーン編集機能を実装したいと思っています。&lt;/p&gt;

&lt;p&gt;距離関数を定義したCUDAファイルのホットリロード機能を実装したり、 CallableProgramをつかって距離関数を差し替え可能にしたいです。&lt;/p&gt;

&lt;p&gt;他にも距離関数やマテリアルのパラメータをインスペクタで編集するなどは最低限欲しいなと思っています。&lt;/p&gt;

&lt;p&gt;あとはオブジェクトの配置などをマニピュレーターでできるようにしたいですが、どうしても実装工数がかかるので、どういう感じが良いのか思案しているところです。
DCCツールから直接シーンを出力する形式だと、距離関数の扱いに困るため、なかなか難しい問題です。&lt;/p&gt;

&lt;h2 id=&#34;リファクタリング&#34;&gt;リファクタリング&lt;/h2&gt;

&lt;p&gt;CallableProgramでBSDFを入れ替えられるようにしたり、ファイルを適切に分割したりして、もう少しコードをリファクタリングしたいです。&lt;/p&gt;

&lt;h2 id=&#34;pngのエンコード時間の短縮&#34;&gt;PNGのエンコード時間の短縮&lt;/h2&gt;

&lt;p&gt;PNGの保存には &lt;a href=&#34;https://github.com/nothings/stb/blob/master/stb_image.h&#34;&gt;stb_image&lt;/a&gt; を使わせていただきました。&lt;/p&gt;

&lt;p&gt;ただし、4K解像度となるとPNGの保存に1.7秒前後の時間が必要でした。&lt;/p&gt;

&lt;p&gt;制限時間が短くなると、PNGの保存やGPUの初期化に要する時間が相対的に増えて、レンダリングに使える時間がどんどん短くなってしまいます。&lt;/p&gt;

&lt;p&gt;そのため、PNGの保存やGPU初期化の高速化は、来年以降のレイトレ合宿では重要な課題になるだろうと予想しています。&lt;/p&gt;

&lt;h2 id=&#34;複数gpu対応&#34;&gt;複数GPU対応&lt;/h2&gt;

&lt;p&gt;OptiXをつかっても複数のGPUをうまく使ってくれなかったので、独自の仕組みで対応が必要のようでした。&lt;/p&gt;

&lt;p&gt;単純な解決策として、プロセスを複数起動して最後にレンダリング結果をマージする方法が考えられますが、ちゃんと検証をしたいです。&lt;/p&gt;

&lt;h2 id=&#34;フルスクラッチgpuレンダラー&#34;&gt;フルスクラッチGPUレンダラー&lt;/h2&gt;

&lt;p&gt;去年まではGPUインスタンス勢は1人だけだったのですが、今年は7人（レンダラーが動かなかった人も含む）もいました。&lt;/p&gt;

&lt;p&gt;GPU勢にも、私のようにOptiXなどのレイトレーシング用のフレームワークを使う勢と、フルスクラッチ実装勢で別れていました。&lt;/p&gt;

&lt;p&gt;フルスクラッチ勢からは「OptiXでは作法がきっちり決められているのがなんとなく嫌だった」「GPU向けのBVH実装をしてみたかった」といった意見を聞きました。&lt;/p&gt;

&lt;p&gt;たしかにRTXなどの登場によって交差判定がハードウェアに移りつつある今だからこそ、勉強する価値はあるのかもしれません。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;今年は忙しいからレイトレ合宿に参加できるか怪しいと思っていましたが、なんとかちゃんとレンダラーを提出できて良かったです。&lt;/p&gt;

&lt;p&gt;思えば「レイマーチングとポリゴンが混在したシーンをパストレーシングしたい」というのは3年前のレイトレ合宿4のときに本当は実現したいテーマでした。&lt;/p&gt;

&lt;p&gt;当時はレイトレ初心者だったので、ナイーブなパストレーシングで精一杯で高速化方法が分からず、
普通にレイマーチングを組み合わせたら激重になってしまい、5時間くらいかけないとまともな絵が出ない状態でした。
結局、パストレーシングを諦めて疑似手法でAOやシャドウを計算してなんとか見れる絵を提出しました…&lt;/p&gt;

&lt;p&gt;3年間で学んだ知識でようやくやりたいことを実現できて本当に良かったです。過去の自分に勝利できました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿は自身の成長や糧となる機会を与えてくれる、とても良い合宿勉強会だなと改めて感じました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿を毎年主催してくださっている&lt;a href=&#34;https://twitter.com/q_cinnamon&#34;&gt;q&lt;/a&gt;さんと&lt;a href=&#34;https://twitter.com/h013&#34;&gt;hole&lt;/a&gt;さん、その他の参加者のみなさん、本当にありがとうございました！&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

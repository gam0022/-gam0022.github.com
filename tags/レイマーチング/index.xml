<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gam0022.net</title>
    <link>https://gam0022.net/tags/%E3%83%AC%E3%82%A4%E3%83%9E%E3%83%BC%E3%83%81%E3%83%B3%E3%82%B0/index.xml</link>
    <description>Recent content on gam0022.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <copyright>&amp;copy; 2021 gam0022</copyright>
    <atom:link href="/tags/%E3%83%AC%E3%82%A4%E3%83%9E%E3%83%BC%E3%83%81%E3%83%B3%E3%82%B0/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tokyo Demo Fest 2021のShader Showdownに参加しました</title>
      <link>https://gam0022.net/blog/2021/12/31/tdf2021-shader-showdown/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/12/31/tdf2021-shader-showdown/</guid>
      <description>&lt;p&gt;12月11日～12日にオンラインで開催された&lt;a href=&#34;https://tokyodemofest.jp/&#34;&gt;Tokyo Demo Fest 2021&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
リアルタイムに映像や音楽を生成するプログラムを「デモ」と言い、デモを鑑賞したり完成度を競ったりして楽しむイベントを「デモパーティ」と言います。
「デモシーン」はデモやデモパーティを中心としたコンピューターのサブカルチャーです。&lt;/p&gt;

&lt;p&gt;TDFのShader Showdownというイベントに競技者として参加しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/Collage_Fotor_v3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-31-tdf2021-shader-showdown/Collage_Fotor_v3.jpg&#34; alt=&#34;Collage_Fotor_v3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;また、TDFのGLSL Graphics Compoにも参加したので、こちらは別記事にまとめました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/blog/2021/12/20/tdf2021-glsl/&#34;&gt;Tokyo Demo Fest 2021のGLSL Graphics Compo優勝作品の解説 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;shader-showdownとは&#34;&gt;Shader Showdownとは&lt;/h1&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TokyoDemoFestのShader Showdownは、世界的なDemoparty「Revision」と同じレギュレーションで開催します。&lt;br&gt;試合の放映はパーティー当日12/11-12となります。乞うご期待……！ &lt;a href=&#34;https://t.co/IlVue5npWz&#34;&gt;pic.twitter.com/IlVue5npWz&lt;/a&gt;&lt;/p&gt;&amp;mdash; Tokyo Demo Fest 2021 (2021/12/11-12) (@TokyoDemoFest) &lt;a href=&#34;https://twitter.com/TokyoDemoFest/status/1452275618997886976?ref_src=twsrc%5Etfw&#34;&gt;October 24, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Shader Showdownとは25分間でシェーダーを書き、どちらの作品が良いかを決める競技です。&lt;/p&gt;

&lt;p&gt;試合中は、一切のドキュメントの参照ができません。当然ながら必要な関数はすべて試合中に実装しないいけません。&lt;/p&gt;

&lt;p&gt;1対1のトーナメント形式で開催され、試合の勝敗は観衆（ビジター）の投票によって決定します。今回は私を含めた8人でトーナメントを行いました。&lt;/p&gt;

&lt;p&gt;対戦はGLSLのライブコーディングで行われます。&lt;a href=&#34;https://github.com/TheNuSan/Bonzomatic/releases/tag/v11&#34;&gt;Bonzomatic&lt;/a&gt;というアプリを利用し、対戦者の書いているコードやカーソルの位置が共有されます。&lt;/p&gt;

&lt;p&gt;ビジターは対戦者が25分の制限時間の中でどのような戦略とアイデアをもってコードを書いていくかをすぐ隣でみているかのように体験できます。&lt;/p&gt;

&lt;p&gt;詳しいGLSLライブコーディングの知識がなくても楽しめるよう、TDFでは対戦者がどのようなコードを書いているかのリアルタイムな解説があります。&lt;/p&gt;

&lt;h1 id=&#34;ライブコーディングした作品解説&#34;&gt;ライブコーディングした作品解説&lt;/h1&gt;

&lt;p&gt;今回のTDFでライブコーディングした作品を簡単に解説します。&lt;/p&gt;

&lt;p&gt;TDFのShader Showdownの全作品は&lt;a href=&#34;https://livecode.demozoo.org/party_series/174.html&#34;&gt;livecode.demozoo.org&lt;/a&gt;にもアーカイブされています。&lt;/p&gt;

&lt;h2 id=&#34;lightning-tunnel-quarter-final&#34;&gt;Lightning Tunnel | Quarter-Final&lt;/h2&gt;

&lt;p&gt;準々決勝（Quarter-Final）の作品です。&lt;/p&gt;

&lt;p&gt;稲妻が轟くトンネルをイメージして作りました。&lt;/p&gt;

&lt;p&gt;ボリュームレンダリングをしてBloom感を出しています。ボリュームレンダリングの実装が雑なのでアーティファクトが発生しているのですが、むしろ雷の荒々しい感じが再現できて良かったです。&lt;/p&gt;

&lt;p&gt;時間が余ったのでカメラのFoVのアニメーションをしたのですが、ちょっとワープっぽい効果になりました。&lt;/p&gt;

&lt;p&gt;モデリングはIFSでやっています。IFSで狙った形状を出すことは困難なので、パラメーターは事前に調整をして暗記しておきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;25分でライブコーディングしたシェーダーです。&lt;br&gt;&lt;br&gt;This shader was coded in 25 minutes.&lt;br&gt;&lt;br&gt;Shader showdown quarter-final at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Bonzomatic?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Bonzomatic&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/WTw7tHVsbk&#34;&gt;pic.twitter.com/WTw7tHVsbk&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469562828831195140?ref_src=twsrc%5Etfw&#34;&gt;December 11, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/sl3XWM&#34;&gt;Shadertoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://neort.io/art/c6qm3ls3p9f3hsje6360&#34;&gt;NEORT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;YouTubeのアーカイブ（Day1の2:15頃）です。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/2s9KfMn1J9M?start=8114&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;vj-feat-niko-14-semi-final&#34;&gt;VJ feat. Niko_14 | Semi-Final&lt;/h2&gt;

&lt;p&gt;準決勝（Semi-Final）の作品です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/himazin917&#34;&gt;Niko_14&lt;/a&gt;さんの音楽がとても素晴らしかったので、音楽と同期したVJに挑戦しました。&lt;/p&gt;

&lt;p&gt;試合の前日に自分の試合の音楽担当はNiko_14さんと聞いたので、そのタイミングでVJをする決意をしました。&lt;/p&gt;

&lt;p&gt;VJっぽい絵を狙ったことが無かったのですが、ほぼ狙い通りのバキバキな感じにできたので良かったです。
シェーダーの構成としてはQuarter-Finalとほぼ同じで、IFSとボリュームレンダリングの組み合わせです。
IFSのパラメーターは適当だったのですが、ちゃんと狙い通りの絵になったので良かったです。&lt;/p&gt;

&lt;p&gt;色はFFT（音楽の周波数ごとのボリューム）に対応していて、低音が赤、中音が緑、高音が青に対応しています。
キックの音が支配的だったので、キックに合わせて赤～ピンクっぽいビームが発生しています。&lt;/p&gt;

&lt;p&gt;Twitterの動画の4秒頃のように、音が切り替わるタイミングでサウンドリアクティブになっているのが分かりやすいと思います。ぜひ音声をONにして再生してください！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;25分でライブコーディングしたシェーダーです。&lt;br&gt;かっこいい音楽は &lt;a href=&#34;https://twitter.com/himazin917?ref_src=twsrc%5Etfw&#34;&gt;@himazin917&lt;/a&gt; さん制作です！&lt;br&gt;&lt;br&gt;This shader was coded in 25 minutes.&lt;br&gt;Sound by &lt;a href=&#34;https://twitter.com/himazin917?ref_src=twsrc%5Etfw&#34;&gt;@himazin917&lt;/a&gt;&lt;br&gt;&lt;br&gt;Shader showdown semi-final at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Bonzomatic?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Bonzomatic&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/HzUpd9le3t&#34;&gt;pic.twitter.com/HzUpd9le3t&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469924900257562627?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/NttSRS&#34;&gt;Shadertoy&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;ShadertoyのSoundcloud連携が機能していないため、音楽はNiko_14さんのものではなく、仮です。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;YouTubeのアーカイブ（Day2の1:41頃）です。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM?start=6086&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;VJっぽいバキバキとした絵の方向性やFFTを用いたサウンドリアクティブなシェーダーはこれまで挑戦したことのないジャンルだったので、新しい方向性を模索する良い経験になりました。&lt;/p&gt;

&lt;p&gt;Semi-Finalでは&lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt;さんに負けてしまったのですが、試合後のコメントによると反射の処理には&lt;a href=&#34;https://gam0022.net/blog/2021/06/08/unity-bible2/&#34;&gt;『Unityゲーム プログラミング・バイブル 2nd Generation』の自分の章&lt;/a&gt;を参考にしてくださったそうで、めちゃくちゃありがてぇ🙏となりました。&lt;/p&gt;

&lt;p&gt;Jugem-Tさんも実況による盛り上げありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;凄い画同士の殴り合いの中BGMもライブコーディングで生成してる(Niko_14氏)とんでもない光景になっててヤバい&lt;br&gt;&lt;br&gt;Shader Showdown準決勝 gam0022氏 vs Kamoshika氏&lt;br&gt;[LIVE]Tokyo Demo Fest 2021 Day2 &lt;a href=&#34;https://t.co/648ZNFJTxk&#34;&gt;https://t.co/648ZNFJTxk&lt;/a&gt; &lt;a href=&#34;https://twitter.com/YouTube?ref_src=twsrc%5Etfw&#34;&gt;@YouTube&lt;/a&gt;より &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/atG6c8hWiK&#34;&gt;pic.twitter.com/atG6c8hWiK&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jugem-T 𓆡作業中 (@Jugem_T) &lt;a href=&#34;https://twitter.com/Jugem_T/status/1469892859503734787?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;大変でしたが、楽しかったです。&lt;/p&gt;

&lt;p&gt;25分でできる範囲はかなり限られてくるので、詰め込める要素を取捨選択して、ミスをしないように実装するのは思っていたより難しく感じました。25分だとデバッグしている余裕はなくバグを生み出した瞬間に敗戦が濃厚になります。
距離関数も普段はコピペしているので暗記も大変でした。回転行列くらいは導出できるのですが、sdBoxは導出していたら時間がまったく足りません。&lt;/p&gt;

&lt;p&gt;正直に言うと、まさかここまでレベルの高い戦いになるとは思っておらず、参加者のみなさんが凄すぎてちょっと心が折れそうでした。&lt;/p&gt;

&lt;p&gt;とくにFinal（決勝）の&lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt; vs &lt;a href=&#34;https://twitter.com/phi16_&#34;&gt;phi16&lt;/a&gt; の戦いは印象深かったです。&lt;/p&gt;

&lt;p&gt;Kamoshikaさんは蝶、phi16さんはライブゲームと、両者とも &amp;ldquo;生命&amp;rdquo; を誕生させていました。偶然にもテーマが一致していてちょっと面白かったです。&lt;/p&gt;

&lt;p&gt;とにかく実装量がえげつなく、これをライブコーディングでやるんだ…と驚かされました。
競技者として参加したことで、25分間でこの量をミスなく実装する困難さは痛いほど理解していたので、なおさら驚かされました。&lt;/p&gt;

&lt;p&gt;両者ともミスなく作品を仕上げており、まさに決勝戦に相応しい素晴らしい戦いを見せていただきました🙏心の底から感動しました。&lt;/p&gt;

&lt;p&gt;世界レベルの実力者の方々と戦えて本当に光栄でした！ありがとうございます！&lt;/p&gt;

&lt;p&gt;Kamoshikaさん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;25 minutes live coding at Shader Showdown Final.&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/LiveCoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LiveCoding&lt;/a&gt; &lt;a href=&#34;https://t.co/WeVq82f50E&#34;&gt;pic.twitter.com/WeVq82f50E&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kamoshika (@kamoshika_vrc) &lt;a href=&#34;https://twitter.com/kamoshika_vrc/status/1470360600517971970?ref_src=twsrc%5Etfw&#34;&gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;phi16さん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;und&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://t.co/qluYGj653s&#34;&gt;pic.twitter.com/qluYGj653s&lt;/a&gt;&lt;/p&gt;&amp;mdash; phi16 (@phi16&lt;em&gt;) &amp;lt;a href=&amp;ldquo;&lt;a href=&#34;https://twitter.com/phi16&#34;&gt;https://twitter.com/phi16&lt;/a&gt;&lt;/em&gt;/status/1470104161320849409?ref_src=twsrc%5Etfw&amp;rdquo;&amp;gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;記録 TDF2021 ShaderShowdown &lt;a href=&#34;https://t.co/mMcSoYwh5U&#34;&gt;https://t.co/mMcSoYwh5U&lt;/a&gt;&lt;/p&gt;&amp;mdash; phi16 (@phi16&lt;em&gt;) &amp;lt;a href=&amp;ldquo;&lt;a href=&#34;https://twitter.com/phi16&#34;&gt;https://twitter.com/phi16&lt;/a&gt;&lt;/em&gt;/status/1470415119708753921?ref_src=twsrc%5Etfw&amp;rdquo;&amp;gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;YouTubeのアーカイブ（Day2の4:27頃）です。&lt;/p&gt;

&lt;p&gt;Finalでは私も実況者の一人として参加しています。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM?t=16030&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;おつかれさまでした！&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/h2yXCGGBYa&#34;&gt;pic.twitter.com/h2yXCGGBYa&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469999619409350657?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;練習&#34;&gt;練習&lt;/h1&gt;

&lt;p&gt;ライブコーディングの練習中の作品です。&lt;/p&gt;

&lt;p&gt;Quarter-FinalのIFS+ボリュームレンダリングのアプローチは練習中に決めました。&lt;/p&gt;

&lt;p&gt;トンネルのIFSのモデリングもよく見ると面影が残っています。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;情報量を追加（エンコード耐久テスト）&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Raymarching&lt;/a&gt; &lt;a href=&#34;https://t.co/uBg43zGOk6&#34;&gt;pic.twitter.com/uBg43zGOk6&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1453405601971666944?ref_src=twsrc%5Etfw&#34;&gt;October 27, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Diamond Variation 🔷 &lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Raymarching&lt;/a&gt; &lt;a href=&#34;https://t.co/IAEhBgdW5s&#34;&gt;pic.twitter.com/IAEhBgdW5s&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1453768374312263683?ref_src=twsrc%5Etfw&#34;&gt;October 28, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/Shadertoy?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shadertoy&lt;/a&gt; にポートしました。&lt;br&gt;&lt;br&gt;&amp;quot;Diamond Tunnel&amp;quot; by gam0022&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt;&lt;a href=&#34;https://t.co/oyyz8mop2x&#34;&gt;https://t.co/oyyz8mop2x&lt;/a&gt; &lt;a href=&#34;https://t.co/DXnqCAKY1Z&#34;&gt;pic.twitter.com/DXnqCAKY1Z&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1476576224768331776?ref_src=twsrc%5Etfw&#34;&gt;December 30, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tokyo Demo Fest 2021のGLSL Graphics Compo優勝作品の解説</title>
      <link>https://gam0022.net/blog/2021/12/20/tdf2021-glsl/</link>
      <pubDate>Mon, 20 Dec 2021 12:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/12/20/tdf2021-glsl/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;http://qiita.com/advent-calendar/2021/klab&#34;&gt;KLab Engineer Advent Calendar 2021&lt;/a&gt;の20日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;12月11日～12日にオンラインで開催された&lt;a href=&#34;https://tokyodemofest.jp/&#34;&gt;Tokyo Demo Fest 2021&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
リアルタイムに映像や音楽を生成するプログラムを「デモ」と言い、デモを鑑賞したり完成度を競ったりして楽しむイベントを「デモパーティ」と言います。
「デモシーン」はデモやデモパーティを中心としたコンピューターのサブカルチャーです。&lt;/p&gt;

&lt;p&gt;今年のTDFでは、『Alien Spaceship』という作品を発表しました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/_F0Pxq7TKqs&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Released &amp;quot;Alien Spaceship&amp;quot; at GLSL Graphics compo, &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021&lt;br&gt;&lt;br&gt;It&amp;#39;s running on &lt;a href=&#34;https://twitter.com/hashtag/GLSLSandbox?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSLSandbox&lt;/a&gt; &lt;br&gt;Only 1Pass Shader! No post-effects used&lt;a href=&#34;https://twitter.com/hashtag/GLSLSandbox?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSLSandbox&lt;/a&gt; で動作します。&lt;br&gt;1パスのシェーダーのみの制約で実装しており、ポストエフェクトは未使用です。 &lt;a href=&#34;https://t.co/lJBQQjjHMR&#34;&gt;pic.twitter.com/lJBQQjjHMR&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469977106612649985?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/_F0Pxq7TKqs&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/fl3SRB&#34;&gt;Shadertoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=90438&#34;&gt;Pouet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glslsandbox.com/e#77788.0&#34;&gt;GLSL Sandbox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TDFのGLSL Graphics Compoにて、&lt;a href=&#34;https://tokyodemofest.jp/tdf2021-results.txt&#34;&gt;本作品が1位&lt;/a&gt;に選ばれました！&lt;/p&gt;

&lt;p&gt;この記事では『Alien Spaceship』の利用技術と制作の裏側について解説します。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;glsl-graphics-compoとは&#34;&gt;GLSL Graphics Compoとは？&lt;/h1&gt;

&lt;p&gt;デモシーンの文化に馴染みのない方に向けて、簡単にGLSL Graphics Compoの概要や制約について説明します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://glslsandbox.com/&#34;&gt;GLSL sandbox&lt;/a&gt;はWeb上でGLSLのフラグメントシェーダーを編集・実行できるWebGLで実装されたサービスです。作品を公開したり共有もできます。&lt;/p&gt;

&lt;p&gt;GLSL Graphics CompoはGLSL Sandbox上で動作するGLSLのシェーダーによるグラフィックスを競うコンポです。
コンポはコンペティションの意味で、参加者投票によって順位が決まります。&lt;/p&gt;

&lt;h2 id=&#34;glslシェーダーだけで映像をつくる&#34;&gt;GLSLシェーダーだけで映像をつくる&lt;/h2&gt;

&lt;p&gt;そもそもGLSLシェーダー、つまり &lt;strong&gt;プログラミングのソースコードだけで映像をつくる&lt;/strong&gt; 行程を一般的には想像しづらいかもしれません。&lt;/p&gt;

&lt;p&gt;まずは次の図を見ていただけると、具体的にイメージを掴めるかもしれません。
GLSLのコードからコメントや改行・空白文字を取り除き、処理の内容で色分けしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/minify-text.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/minify-text.png&#34; alt=&#34;GLSLのコードの処理&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この7756文字のGLSLのシェーダーに映像のすべてが実装されています。&lt;/p&gt;

&lt;p&gt;見てのとおり &lt;strong&gt;シーンのモデリング、ライティング、カメラワーク、演出のシーケンスがすべて含まれています。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;変数名や関数名を1文字に短縮したり、デバッグ用のコードの削除はしていないので、まだまだ文字数を削る余地はあります。
今回は文字数をそこまで意識してコーディングせずに、可読性を重視しました。&lt;/p&gt;

&lt;p&gt;GLSL sandboxでは音楽を再生できないので、YouTubeの音楽は後付けです。Shadertoy標準楽曲「Most Geometric Person」を使わせていただきました。&lt;/p&gt;

&lt;h2 id=&#34;レイマーチング&#34;&gt;レイマーチング&lt;/h2&gt;

&lt;p&gt;GLSL sandbox用のGLSLのフラグメントシェーダーで記述できるのは、フルスクリーンのMeshを描画する2D処理のみです。&lt;/p&gt;

&lt;p&gt;入力は描画対象のピクセルの座標、出力はピクセルの画素値の単純な2D処理です。
また、時間やマウス座標を入力にすることで、アニメーションもできます。&lt;/p&gt;

&lt;p&gt;3Dを描画するためには、GLSLコードの中に3Dのカメラや3Dのシーンの形状を定義する必要があります。&lt;/p&gt;

&lt;p&gt;2DのGLSLのシェーダーで3D空間を描画するためのテクニックとして、レイマーチングがよく使われます。&lt;/p&gt;

&lt;p&gt;レイマーチングは、距離関数の長さだけひたすらレイを進める処理をくり返し、距離関数が0になったら衝突したと判定する単純なアルゴリズムです。
つまり、レイトレーシングの交差判定のアルゴリズムのひとつです。
レイマーチングは、描画する形状を距離関数という数式によってプロシージャルに定義できるため、3Dのモデリングなしに3Dシーンを描画できます。&lt;/p&gt;

&lt;p&gt;レイマーチングの詳細については、過去に勉強会のスライドや書籍で紹介しています。&lt;/p&gt;

&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/rS2j757JUrqeWL&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/shohosoda9/threejs-58238484&#34; title=&#34;シェーダだけで世界を創る！three.jsによるレイマーチング&#34; target=&#34;_blank&#34;&gt;シェーダだけで世界を創る！three.jsによるレイマーチング&lt;/a&gt; &lt;/strong&gt; de &lt;strong&gt;&lt;a href=&#34;https://www.slideshare.net/shohosoda9&#34; target=&#34;_blank&#34;&gt;Sho Hosoda&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;

&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B097GBR2N3&amp;linkId=ad2164f51c3a4574701f9097c0eb7fde&#34;&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;alien-spaceshipの技術解説&#34;&gt;Alien Spaceshipの技術解説&lt;/h1&gt;

&lt;p&gt;前置きが長くなりましたが、ここからレイマーチング経験者に向けた技術解説をします。&lt;/p&gt;

&lt;p&gt;技術的なポイントとしては次の3点だと考えています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;宇宙船の船内のような具体的な対象を目指したモデリング&lt;/li&gt;
&lt;li&gt;リアルタイムなグローバルイルミネーションのあるライティング&lt;/li&gt;
&lt;li&gt;長尺のタイムラインのシーケンス&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;モデリング&#34;&gt;モデリング&lt;/h2&gt;

&lt;p&gt;全編を通してプリミティブとしてはBoxとSphere（卵）の2種類しか使っていません。&lt;/p&gt;

&lt;h3 id=&#34;前半のhallwayシーン&#34;&gt;前半のHallwayシーン&lt;/h3&gt;

&lt;p&gt;壁の光る部分はBoxをSkewしたり、床はBoxにDisplacement Mapでディテールを加えています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1164.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1164.jpg&#34; alt=&#34;party1164.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;壁のskew&#34;&gt;壁のSkew&lt;/h4&gt;

&lt;p&gt;壁の &lt;strong&gt;く&lt;/strong&gt; の字の折り曲がった形状には、BoxをSkewで変形させています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;p.x -= W - 0.5 * abs(p.y);// Skewで変形
opUnion(m, sdBox(p, vec3(a * 1.7, H, 0.24)), SOL, roughness, 0.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;床のdisplacement-map&#34;&gt;床のDisplacement Map&lt;/h4&gt;

&lt;p&gt;床のDisplacement Mapは次のような数式で実装しています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hをsdBoxの第2引数のサイズに加算すると、Displacement Mapになる
float h = 0.1 * floor(2. * sin(p.x)) + 0.2 * floor(sin(2. * p.z));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sinから滑らかなカーブを得て、それをfloorで階段状に離散化しているだけです。&lt;/p&gt;

&lt;p&gt;pは事前にabs(p.x)により左右ミラーしています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/floor_graph.png&#34; alt=&#34;床の断面&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;扉の台形波&#34;&gt;扉の台形波&lt;/h4&gt;

&lt;p&gt;扉の台形のギザギザの関数は&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta先生&lt;/a&gt;のコードをお借りしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/3dd3WB&#34;&gt;Energy Lab by kaneta&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float smoothPulse(float start, float end, float period, float smoothness, float t) {
    float h = abs(end - start) * 0.5;
    t = mod(t, period);
    return smoothstep(start, start + h * smoothness, t) - smoothstep(end - h * smoothness, end, t);
}

float y(float x) {
    return smoothPulse(0.0, 0.6, 1.0, 0.5, x);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/smoothPulse.png&#34; alt=&#34;扉の台形波&#34; /&gt;&lt;/p&gt;

&lt;p&gt;床のEmissiveや扉を開けたときのEmissiveの模様のパターンもsmoothPulse関数を用いました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party2085.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party2085.jpg&#34; alt=&#34;party2085.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/smoothPulsePattern.png&#34; alt=&#34;smoothPulsePattern.png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Floor Emissive Pattern
float py = smoothPulse(0.0, 0.6, 1.0, 0.5, 0.25 * p.y);
float emi = smoothPulse(0.2, 0.25, 1.0, 0.5, py + p.x / 2.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shadertoyに簡単なサンプルを用意しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/7ttXWf&#34;&gt;smoothPulse Pattern&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;hallwayシーンまとめ&#34;&gt;Hallwayシーンまとめ&lt;/h4&gt;

&lt;p&gt;天井についても、係数を調整しながら箱を並べることで、狙った形状をモデリングしていきました。
特殊なことは何もしていませんが、sdBoxの評価回数が増えると負荷が高くなるので、なるべくsdBoxの数を減らすように意識しました。
レイマーチングでは、座標をmodで繰り返すと特定の軸に対して無限にオブジェクトを配置できます（opRep）。
前述の左右のミラー化もsdBoxの評価回数を減らすための工夫のひとつです。&lt;/p&gt;

&lt;p&gt;ほぼopRepとSkewとDisplacement Mapのテクニックの繰り返しで地道にモデリングしているだけです。&lt;/p&gt;

&lt;p&gt;ライティングの問題とモデリングの問題を切り分けるためにシンプルなレイマーチングの描画モードも用意しました。&lt;/p&gt;

&lt;p&gt;よく見ると強引にSkewとDisplacement Mapをしたために、よく見るとアーティファクトが発生しています。
最終的なライティングでは暗い箇所となってほとんど目立たなかったので、今回はそのままにしました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/debug-scene.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/debug-scene.png&#34; alt=&#34;debug-scene.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;後半のalienの巣のシーン&#34;&gt;後半のAlienの巣のシーン&lt;/h3&gt;

&lt;p&gt;IFS（Iterated Function Systems）をつかっています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party6370.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party6370.jpg&#34; alt=&#34;party6370.jpg&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party7186.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party7186.jpg&#34; alt=&#34;party7186.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;IFSでは狙った形をモデリングすることは困難なので、パラメーターを延々と調整しながら、理想的な見た目になるまで試行錯誤を繰り返しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// IFSのパラメーター
vec4 ifs = vec4(875, 482, 197, 545) / vec2(1200, 675).xyxy;

// IFSでモデリング
p = pos;
p -= vec3(0, H, 16. * 3.5);

for (int i = 0; i &amp;lt; 5; i++) {
    p = abs(p) - ifs.w;
    rot(p.xz, -4. * ifs.x);
    p = abs(p) - ifs.z;
    rot(p.xy, -4. * ifs.y);
}

opUnion(m, sdEgg(p, 0.1), SOL, 0.0, 0.0);
opUnion(m, sdBox(p, vec2(1, 0.01).xyy), SOL, roughness, 0.0);
opUnion(m, sdBox(p - vec2(0.001, 0).yxy, vec2(1, 0.01).xyy), VOL, 2.4 * saturate(cos(beatTau / 2. + 10. * p.x)), 2.4);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ライティング-グローバルイルミネーション&#34;&gt;ライティング（グローバルイルミネーション）&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1895.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/party1895.jpg&#34; alt=&#34;party1895.jpg&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;全編を通してグローバルイルミネーション（GI）や、少しラフな反射（roughness = 0.05くらい）をしています。&lt;/p&gt;

&lt;p&gt;グラフィックスエンジニアなら性癖に刺さるポイントだと思います。&lt;/p&gt;

&lt;p&gt;GIをリアルタイムに計算するのは技術的にはとても難しい課題です。&lt;/p&gt;

&lt;p&gt;今回は&lt;a href=&#34;https://twitter.com/Virgill74&#34;&gt;Virgillさん&lt;/a&gt;が開発したMadtracingを用いてGIを計算しました。&lt;/p&gt;

&lt;p&gt;Madtracingは&lt;a href=&#34;https://www.pouet.net/prod.php?which=77102&#34;&gt;End of time by Alcatraz &amp;amp; Altair&lt;/a&gt;というデモで使われた手法です。&lt;/p&gt;

&lt;p&gt;Madtracing解説用のシェーダーがShadertoyに公開されています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/Xt3cWS&#34;&gt;EOT - Grid scene by Virgill&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;パストレーシングと同じように表面のroughnessに応じてセカンダリレイを飛ばしてGIを計算します。&lt;/p&gt;

&lt;p&gt;通常のパストレーシングでは物体の表面にヒットしてからセカンダリレイを複数回飛ばすと思いますが、
Madtracingではレイマーチングのステップ中にセカンダリレイを近傍のオブジェクトのroughnessに応じて飛ばします。&lt;/p&gt;

&lt;p&gt;これによってボリューム感やBloom感のあるライティングを実現できます。その代償として、少々負荷が高い印象です。&lt;/p&gt;

&lt;p&gt;今回のデモでは、Madtracingを自分の使いやすい形に少しだけフォークして利用しました。&lt;/p&gt;

&lt;p&gt;まず、マテリアルのフォーマット（map関数の返り値）を以下のように定義しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec4 m = vec4(1, VOL, 0, 0);
// x: Distance
// y: MaterialType (VOL or SOL)
// z: Roughness in (0-1), Emissive when z&amp;gt;1
// w: ColorPalette
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MadtracingからAA処理を削除して、AA処理はプライマリレイの生成に移動しました。これで少し負荷削減とシンプル化ができました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Ref. EOT - Grid scene by Virgill
// https://www.shadertoy.com/view/Xt3cWS
void madtracer(vec3 ro1, vec3 rd1, float seed) {
    scol = vec3(0);
    float t = 0., t2 = 0.;
    vec4 m1, m2;
    vec3 rd2, ro2, nor2;
    for (int i = 0; i &amp;lt; 160; i++) {
        m1 = map(ro1 + rd1 * t);
        // t += m1.y == VOL ? 0.25 * abs(m1.x) + 0.0008 : 0.25 * m1.x;
        t += 0.25 * mix(abs(m1.x) + 0.0032, m1.x, m1.y);
        ro2 = ro1 + rd1 * t;
        nor2 = normal(ro2);
        rd2 = mix(reflect(rd1, nor2), hashHs(nor2, vec3(seed, i, iTime)), saturate(m1.z));
        m2 = map(ro2 + rd2 * t2);
        // t2 += m2.y == VOL ? 0.25 * abs(m2.x) : 0.25 * m2.x;
        t2 += 0.25 * mix(abs(m2.x), m2.x, m2.y);
        scol += .007 * (pal(m2) * step(1., m2.z) + pal(m1) * step(1., m1.z));

        // force disable unroll for WebGL 1.0
        if (t &amp;lt; -1.) break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;絶対に実行されないbreak-によるコンパイル時間削減&#34;&gt;「絶対に実行されないbreak」によるコンパイル時間削減&lt;/h3&gt;

&lt;p&gt;madtracer関数に、謎の &lt;code&gt;if (t &amp;lt; -1.) break;&lt;/code&gt; があることに気がついたでしょうか？&lt;/p&gt;

&lt;p&gt;tはレイの進んだ距離で、絶対にマイナス値にはなりません。つまり絶対に実行されないbreak処理です。
普通に考えれば不要な処理ですが、これはGLSLコンパイル時間削減のハックです。&lt;/p&gt;

&lt;p&gt;breakを追加することで、GLSLコンパイラによってforがunrollされずにloopとして処理されて、コンパイル時間を大きく削減できます。&lt;/p&gt;

&lt;p&gt;ChromeデフォルトのWebGLのANGLE有効時にはかなり効果的で、自分の環境ではコンパイル時間を32.9秒から1.7秒に削減できました。&lt;/p&gt;

&lt;p&gt;コンポ提出当日はずっとコンパイル時間の削減に工数を費やしていて、提出2.5時間前くらいに気がついたので、もっと早く気がついていればという気持ちです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; が終わったので、&lt;br&gt;コンパイル時間を32.9秒から1.7秒に削減する&lt;br&gt;「絶対に実行されないbreak」の実例を貼っておきます。&lt;br&gt;&lt;br&gt;breakを追加することで、GLSLコンパイラによってforがunrollされずにloopに処理されて、コンパイル時間を大きく削減できます。&lt;a href=&#34;https://t.co/SC7A9WAkll&#34;&gt;https://t.co/SC7A9WAkll&lt;/a&gt; &lt;a href=&#34;https://t.co/XRakPPq0TU&#34;&gt;pic.twitter.com/XRakPPq0TU&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1470408956866883584?ref_src=twsrc%5Etfw&#34;&gt;December 13, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;同様のテクニックとして、&lt;code&gt;N + min(0, iFrame)&lt;/code&gt; をループ回数にする手法があります。&lt;a href=&#34;https://twitter.com/AruGL&#34;&gt;Danilさん&lt;/a&gt;に教えていただきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;maybe you know usual trick with loop N+min(0,iFrame) it also can speedup compiling&lt;a href=&#34;https://t.co/XPfP9CZms0&#34;&gt;https://t.co/XPfP9CZms0&lt;/a&gt;&lt;/p&gt;&amp;mdash; Danil (@AruGL) &lt;a href=&#34;https://twitter.com/AruGL/status/1466751715038879755?ref_src=twsrc%5Etfw&#34;&gt;December 3, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;コードにすると、こういう感じです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for(int i = 0; i &amp;lt; 160 + min(0, iFrame); i++) {
    // ループ中の処理
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ShadertoyなどのWebGL2.0環境であれば、この方法で同じコンパイル時間削減の効果を得られます。&lt;/p&gt;

&lt;p&gt;WebGL1.0の場合はダイナミックループをサポートしていないので、WebGL1.0で動くGLSLSandboxでは &lt;code&gt;N + min(0, iFrame)&lt;/code&gt; のハックは使えません。&lt;/p&gt;

&lt;p&gt;GLSLSandbox用なら、&lt;code&gt;絶対に実行されないbreak&lt;/code&gt; のハックを使うと良いでしょう。&lt;/p&gt;

&lt;h2 id=&#34;タイムラインのシーケンス&#34;&gt;タイムラインのシーケンス&lt;/h2&gt;

&lt;p&gt;タイムラインのシーケンス管理のために次の簡単なマクロを実装しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Timeline
float prevEndTime = 0., t = 0.;
#define TL(beat, end) if (t = beat - prevEndTime, beat &amp;lt; (prevEndTime = end))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使い方は簡単で、TLの引数に現在時刻と境界値（区間の終了タイミング）を指定します。
単位は区別していないので、時間単位でもビート単にでも統一されていてばOKです。&lt;/p&gt;

&lt;p&gt;グローバル変数tに現在区間の相対的な時間が自動的に設定されるため、処理をスッキリと書けます。&lt;/p&gt;

&lt;p&gt;ifの条件の中にカンマを複数の式を書けるのは今回はじめて知りました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// カメラワーク制御の実装例

// 0～ 4*8ビート目までの処理
TL(beat, 4. * 8.) setCamera(vec4(600, 250. + t * 3., 600, 243. - t * 6.), 3.);

// 4*8～4*10ビート目までの処理
else TL(beat, 4. * 10.) setCamera(vec4(600, 307, 600, 44. + t * 4.), 3.);

// 4*10～4*12ビート目までの処理
else TL(beat, 4. * 12.) setCamera(vec4(494, 322, 695, 216), 2.4 + 0.2 * t);

// 4*12～4*14ビート目までの処理
else TL(beat, 4. * 14.) setCamera(vec4(600, 481. + 10. * t, 600, 59), 3.);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今回はカットごとにカメラを完全に切り替えていたので、このような仕組みでうまくカメラワークを実装できました。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;kanetaさんのsmoothPulse関数や、VirgillさんのMadtracing以外にも、数え切れないほどたくさんの解説記事とシェーダーを参考にしたり、たくさんの作品に影響を受けました。
たくさんの方々に感謝します。ありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;ここからは技術的なこと以外のポエムをつらつらと書きます。&lt;/p&gt;

&lt;h2 id=&#34;glsl-graphics-compo初優勝&#34;&gt;GLSL Graphics Compo初優勝！&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;2018年のPC Demo Compo&lt;/a&gt;に引き続き、Tokyo Demo Festでのコンポ優勝は2回目です。&lt;/p&gt;

&lt;p&gt;これまでGLSL Graphics Compoはずっと3位で、なかなか優勝できなかったので、ようやく心残りを解消できました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;I won the GLSL Graphics compo at &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021!&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; 2021 の GLSL Graphics compo で優勝しました！めちゃくちゃ嬉しいです！&lt;br&gt;&lt;br&gt;&amp;quot;Alien Spaceship&amp;quot; by &lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/KQaQo1NI0R&#34;&gt;pic.twitter.com/KQaQo1NI0R&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1469994430950445057?ref_src=twsrc%5Etfw&#34;&gt;December 12, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;GLSL Graphics compo 1位のトロフィーを受け取りました🏆&lt;br&gt;&lt;br&gt;今年のトロフィーは例年よりもずっと重厚感があります。&lt;br&gt;&lt;br&gt;副賞の光るキーボードもありがとうございました。&lt;br&gt;家にある光るキーボードは3台目ですが、大切にします🙏&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/vC3ce68i7S&#34;&gt;pic.twitter.com/vC3ce68i7S&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1472229449433481220?ref_src=twsrc%5Etfw&#34;&gt;December 18, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;トロフィーの素材や厚みが例年よりも高級感があって、個人的にもなんだか嬉しい気持ちです（笑）。&lt;/p&gt;

&lt;p&gt;GUNCY&amp;rsquo;Sさんによる副賞のRazer BlackWidow V3 Green Switchもありがとうございます。&lt;/p&gt;

&lt;h2 id=&#34;気軽にtdfにエントリーしてほしい&#34;&gt;気軽にTDFにエントリーしてほしい&lt;/h2&gt;

&lt;p&gt;GLSL Graphics CompoはTDF独自のコンポで、海外のパーティでは見たことのない形式ですが、個人的にはとても好きです。&lt;/p&gt;

&lt;p&gt;2016年のTDFに初参加したとき、一晩でGLSLSandboxのシェーダーを書いて、GLSL Graphics Compoにエントリーした記憶は今でも鮮明に覚えています。
自分のシェーダーが巨大なスクリーンに映し出されたとき、オーディエンスの歓声が聞こえて本当に嬉しかったです。
この体験がなければデモシーンやシェーダーを続けていないような気がします。勇気を出してエントリーして良かったと本当に思います。&lt;/p&gt;

&lt;p&gt;デモを1本完成させるのは本当に大変ですが、GLSL Graphics Compoなら気軽に参加できることがメリットだと思います。&lt;/p&gt;

&lt;p&gt;気軽に参加できる数少ないコンポですが、近年のGLSL Graphics Compoのレベルはインフレを続けて、上位勢はかなりガチな作品を出してくるなという印象があります。&lt;/p&gt;

&lt;p&gt;本来のGLSL Graphics Compoは数秒から10秒程度の短いグラフィックス作品の部門だと自分は認識しています。
&lt;a href=&#34;https://nanka.hateblo.jp/entry/2018/12/13/080322&#34;&gt;Traveler 2&lt;/a&gt;やAlien Spaceshipのような長尺のデモっぽい作品がGLSL Graphics Compoに増えることで、もし他の参加者が萎縮してしまったらとても不本意な気持ちです。&lt;/p&gt;

&lt;p&gt;GLSL Graphics Compoは順位や周りを気にせず、1晩クオリティの雑なシェーダーでも構わず気軽にエントリーできる雰囲気にして、新規参入者が増える未来を望んでいます。&lt;/p&gt;

&lt;h2 id=&#34;オンラインパーティの体験&#34;&gt;オンラインパーティの体験&lt;/h2&gt;

&lt;p&gt;今回のTDF初のオンライン開催でした。&lt;/p&gt;

&lt;p&gt;TDFのオーガナイザーの方々の努力のおかげで、実際のデモパーティにかなり近い体験を再現できていたのではないかと思います。&lt;/p&gt;

&lt;p&gt;Day2のYouTubeの視聴回数が3000回を超えているので、例年のオフラインパーティよりもたくさんの人に見てもらえたなど、オンラインのメリットも感じました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/2s9KfMn1J9M&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/bp37xTVNRrM&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;ですが、やはり正直に言うと「オンラインだと物足りないなぁ…」というのが正直な感想でした。
とくにオーディエンスの反応や会場の熱気を直接感じられないのはとても寂しかったです。またオフラインでデモパーティできる日が本当に待ち遠しいです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;またオフラインでデモパーティできる日が待ち遠しい… &lt;a href=&#34;https://t.co/WsyEHySE28&#34;&gt;https://t.co/WsyEHySE28&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1470764587834568715?ref_src=twsrc%5Etfw&#34;&gt;December 14, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;shader-showdown&#34;&gt;Shader Showdown&lt;/h2&gt;

&lt;p&gt;TDF初の試みであるShader Showdownは本当に激熱でした。&lt;/p&gt;

&lt;p&gt;とくに決勝戦の &lt;a href=&#34;https://twitter.com/phi16_&#34;&gt;phi16&lt;/a&gt; vs. &lt;a href=&#34;https://twitter.com/kamoshika_vrc&#34;&gt;Kamoshika&lt;/a&gt; の戦いは一生忘れないくらい印象に残りました。&lt;/p&gt;

&lt;p&gt;Shader Showdownについては、また別の記事で書きたいと思います。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TokyoDemoFestのShader Showdownは、世界的なDemoparty「Revision」と同じレギュレーションで開催します。&lt;br&gt;試合の放映はパーティー当日12/11-12となります。乞うご期待……！ &lt;a href=&#34;https://t.co/IlVue5npWz&#34;&gt;pic.twitter.com/IlVue5npWz&lt;/a&gt;&lt;/p&gt;&amp;mdash; Tokyo Demo Fest 2021 (2021/12/11-12) (@TokyoDemoFest) &lt;a href=&#34;https://twitter.com/TokyoDemoFest/status/1452275618997886976?ref_src=twsrc%5Etfw&#34;&gt;October 24, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;その他&#34;&gt;その他&lt;/h1&gt;

&lt;p&gt;本編では言及しなかったけれども一応書いておきたいことを箇条書きでつらつら書きます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;今年のTDFでは、KLabはゴールドスポンサーとして協賛

&lt;ul&gt;
&lt;li&gt;協賛できて良かった&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;なぜGLSL Graphics Compoに出したの？

&lt;ul&gt;
&lt;li&gt;音楽を作る能力と余裕があれば、IntroとしてPC Demo Compoに出したかったが、間に合わなかった&lt;/li&gt;
&lt;li&gt;sadakkeyさん多忙&lt;/li&gt;
&lt;li&gt;来年は音楽も勉強したい（毎年言っている気もする）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;計画的にデモを作りたい

&lt;ul&gt;
&lt;li&gt;TDF直後には、他の人や作品に感化されて、溢れるモチベーションとやる気があるはずなのに&lt;/li&gt;
&lt;li&gt;結局毎年締切ギリギリまで着手できない&lt;/li&gt;
&lt;li&gt;だんだん徹夜もつらくなってきた&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;着想点

&lt;ul&gt;
&lt;li&gt;グローバルイルミネーションをやりたかった&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.magnum.graphics/guest-posts/area-lights-with-ltcs/&#34;&gt;Area Lights with LTCs&lt;/a&gt;も調査はした

&lt;ul&gt;
&lt;li&gt;BRDFなどに依存したルックアップテーブルが必要で、1Pass実装にフォールバックが不可能っぽいので諦めた&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;作業日記&#34;&gt;作業日記&lt;/h1&gt;

&lt;p&gt;ネタ供養🙏です。&lt;/p&gt;

&lt;h2 id=&#34;2021-11-07&#34;&gt;2021-11-07&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-07-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-07-v1-1.png&#34; alt=&#34;2021-11-07-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-16&#34;&gt;2021-11-16&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-1.png&#34; alt=&#34;2021-11-16-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-2.png&#34; alt=&#34;2021-11-16-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-16-v1-3.png&#34; alt=&#34;2021-11-16-v1-3.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この頃はIFSを弄っていた。&lt;/p&gt;

&lt;h2 id=&#34;2021-11-17&#34;&gt;2021-11-17&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-1.png&#34; alt=&#34;2021-11-17-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-17-v1-2.png&#34; alt=&#34;2021-11-17-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-18&#34;&gt;2021-11-18&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v1-1.png&#34; alt=&#34;2021-11-18-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-18-v2-1.png&#34; alt=&#34;2021-11-18-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-19&#34;&gt;2021-11-19&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-1.png&#34; alt=&#34;2021-11-19-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ボロノイでザラザラとした床にする案&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-2.png&#34; alt=&#34;2021-11-19-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-3.png&#34; alt=&#34;2021-11-19-v1-3.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-4.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-19-v1-4.png&#34; alt=&#34;2021-11-19-v1-4.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-20&#34;&gt;2021-11-20&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-20-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-20-v1-1.png&#34; alt=&#34;2021-11-20-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-21&#34;&gt;2021-11-21&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-1.png&#34; alt=&#34;2021-11-21-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v1-2.png&#34; alt=&#34;2021-11-21-v1-2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-21-v2-1.png&#34; alt=&#34;2021-11-21-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-11-22&#34;&gt;2021-11-22&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v1-1.png&#34; alt=&#34;2021-11-22-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-11-22-v2-1.png&#34; alt=&#34;2021-11-22-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-12-02&#34;&gt;2021-12-02&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v1-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v1-1.png&#34; alt=&#34;2021-12-02-v1-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v2-1.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2021-12-20-tdf2021-glsl-compo/2021-12-02-v2-1.png&#34; alt=&#34;2021-12-02-v2-1.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2021-12-03&#34;&gt;2021-12-03&lt;/h2&gt;

&lt;p&gt;締切当日はコンパイル時間の削減をがんばっていた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メガデモ勉強会2021で発表しました</title>
      <link>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</link>
      <pubDate>Mon, 15 Feb 2021 13:26:18 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</guid>
      <description>&lt;p&gt;昨日の2/14（バレンタインデー）に開催された&lt;a href=&#34;https://connpass.com/event/200294/&#34;&gt;The Tokyo Demo Fest team presents: メガデモ勉強会2021&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;私は「64KBのWebGLデモを実装する技術とデモ制作から得た『学びと発見』」というタイトルで発表を行いました。&lt;/p&gt;

&lt;p&gt;発表スライドはこちらです。&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRd-L7WcWWzcoE9zNpBsJdeMjJf9HelDg1Pto8cFGJTjinejpjZ1mGmzWCZPANJZ0QOCObuVOIdPuy-/embed?start=false&amp;loop=false&amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; の発表資料です！&lt;br&gt;&lt;br&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決について解説しました。&lt;br&gt;&lt;br&gt;レイマーチングはいいぞ！&lt;a href=&#34;https://t.co/QWHOXHmZqu&#34;&gt;https://t.co/QWHOXHmZqu&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1360889255669633024?ref_src=twsrc%5Etfw&#34;&gt;February 14, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決方法について解説しました。&lt;/p&gt;

&lt;p&gt;発表の締めとして「CGを学ぶことで世界の解像度を上げるのが楽しい」「レイマーチングはCG入門に最適」という持論について語りました。&lt;/p&gt;

&lt;h1 id=&#34;質疑応答と補足&#34;&gt;質疑応答と補足&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;質問1: シェーダーを分割することで容量がどのくらい増えるか？

&lt;ul&gt;
&lt;li&gt;マルチパスを前提のエンジン設計にしたので、シェーダー分割してもTypeScriptのコード量は増えない&lt;/li&gt;
&lt;li&gt;重複コードはzlib（pnginator.rb）で圧縮されるため、シェーダーの圧縮後のコードもほとんど増えない&lt;/li&gt;
&lt;li&gt;前半と後半で2分割したときは45byteだけ増えた（&lt;a href=&#34;https://github.com/gam0022/resimulated/pull/112&#34;&gt;PR&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問2: シェーダーの数と行数について

&lt;ul&gt;
&lt;li&gt;サウンドシェーダーは1ファイル。グラフィックス用のシェーダーは合計10ファイル&lt;/li&gt;
&lt;li&gt;サウンドシェーダーは行数が1800行ほどだが、zlibで効率よく圧縮できるので、最終的なファイル容量にはあまり影響しなかった&lt;/li&gt;
&lt;li&gt;グラフィックス用のシェーダーは最大（宇宙空間のレイマーチング）で700行、最小（Bloomのポストエフェクト）で10行ほど&lt;/li&gt;
&lt;li&gt;用途によって幅があるが、レイマーチング用のシェーダーだと平均して400行くらい&lt;/li&gt;
&lt;li&gt;Shadertoyと同じようにCommonのシェーダーの仕組みも用意したが、重複したシェーダーはzlibで圧縮されるため、容量削減の効果は低かった&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問3: ディレクションについて

&lt;ul&gt;
&lt;li&gt;制作前に打ち合わせをしてBPMは決めていた

&lt;ul&gt;
&lt;li&gt;音楽と絵の同期はBPMで行っているので重要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;方向性は絵が先行&lt;/li&gt;
&lt;li&gt;尺については音楽が先行&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足1: Bloomのポストエフェクトはエンジンのビルトイン機能にした

&lt;ul&gt;
&lt;li&gt;縮小バッファーを利用するマルチパスのBloomにしたので、ビルトインにしたほうがサイズを小さく効率よく実装できそうだったから&lt;/li&gt;
&lt;li&gt;フォント描画用のテクスチャ生成機能などShadertoyにはない仕様も何個か実装した&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足2: OpenGLよりWebGLの方がGLSLのコンパイル時間が長い

&lt;ul&gt;
&lt;li&gt;WebGLのデモではなく、OpenGLのexeによるデモにすれば、GLSLのコンパイル時間を短縮できる&lt;/li&gt;
&lt;li&gt;Windows版のChromeおよびFirefoxでは、ANGLEを経由してDirect3D上でWebGLを実現しているため、ANGLEを経由する分だけGLSLコンパイルに時間のかかるケースが多い（&lt;a href=&#34;https://twitter.com/gaziya5/status/1361134297315348482&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chrome.exe --use-angle=gl&lt;/code&gt; というオプション付きでChromeを起動すると、ANGLEを経由せずにWebGLを利用できる（&lt;a href=&#34;https://twitter.com/gaziya5/status/1350418640093413377&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;かなり久しぶりに日本のデモシーンの人たちとワイワイできて楽しかったです！&lt;/p&gt;

&lt;p&gt;最後のTokyoDemoFestは2018年の12月なので、もう2年以上も前なんですよね。時間が経つのは早いです。&lt;/p&gt;

&lt;p&gt;discord上の懇親会では「どうすればライブコーディングを普及できるのか？一般人でも理解できるような実況が必要という仮説」「物理的な会場のクラブの体験とVRの違い」など興味深いお話を聞けて面白かったです。&lt;/p&gt;

&lt;p&gt;素晴らしいイベントを企画・開催してくださったTDFのオーガナイザーのみなさん、本当にありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;関連記事&#34;&gt;関連記事&lt;/h1&gt;

&lt;p&gt;過去の関連登壇や記事のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2020/04/30/revision2020/&#34;&gt;Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/03/16/demoscene-study-session/&#34;&gt;メガデモ勉強会!2018で発表しました&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2016/02/16/glsl-tech/&#34;&gt;GLSL シェーダテクニック勉強会 #GLSLTechで登壇しました&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;この勉強会も5年前のバレンタインデーだったので何かの運命を感じました&lt;/li&gt;
&lt;li&gt;私がレイマーチングを始めてから5年以上も経過しているのもちょっと驚きでした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました</title>
      <link>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</link>
      <pubDate>Sun, 13 Sep 2020 20:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-09-13-cgworld-vol266/Collage_Fotor.jpg&#34; alt=&#34;CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました&#34; /&gt;&lt;/p&gt;

&lt;p&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;/p&gt;

&lt;p&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;/p&gt;

&lt;p&gt;この記事をきっかけにCGWORLD読者の方々にもデモシーンに興味をもっていただき、国内のデモシーンが盛り上がっていくことを願っています。&lt;/p&gt;

&lt;p&gt;もちろん自分の活動を知っている方々もお手に取っていただければとても嬉しいです！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;br&gt;&lt;br&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;a href=&#34;https://t.co/BPf1txlSxU&#34;&gt;https://t.co/BPf1txlSxU&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/demoscene?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#demoscene&lt;/a&gt; &lt;a href=&#34;https://t.co/XXpCh1xiFw&#34;&gt;pic.twitter.com/XXpCh1xiFw&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ #CEDEC2020 9/4登壇, CGWORLD 10月号 (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1301514617588518915?ref_src=twsrc%5Etfw&#34;&gt;September 3, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;購入方法&#34;&gt;購入方法&lt;/h1&gt;

&lt;p&gt;Amazonのアフェリエイトリンクを貼っておきます。&lt;/p&gt;

&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B08FP5NM5P&amp;linkId=8ed32da93c5253b64ba074583462b34a&#34;&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;Twitter上の反響を認知している範囲でメモしておきます。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;すごい、、表紙に「デモシーン」の文字があるぅ、、！&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt;&lt;/p&gt;&amp;mdash; Setsuko (@setsuko_h) &lt;a href=&#34;https://twitter.com/setsuko_h/status/1303997649582874625?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CGWORLD vol.266「デモシーンを支えるプロシージャル技術」を買ってきて読んだ。ディファードレンダリングか。まさに俺が手を付けようとしてるとこだね。これとエフェクトを何とかしないと勝負にはならないな。&lt;/p&gt;&amp;mdash; gaziya (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1303907439134220288?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;がむさん…！ &lt;a href=&#34;https://t.co/0SV02Jq91M&#34;&gt;pic.twitter.com/0SV02Jq91M&lt;/a&gt;&lt;/p&gt;&amp;mdash; さだきち : sadakkey (@sadakkey) &lt;a href=&#34;https://twitter.com/sadakkey/status/1304006171674640386?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;余談&#34;&gt;余談&lt;/h1&gt;

&lt;p&gt;ついに商業誌デビュー！と思ったら、よく考えたら2007年にWindows100%のフリーゲーム紹介コーナーに自作ゲームがちょっとだけ掲載されたのを思い出しました（当時は中学生）。&lt;/p&gt;

&lt;p&gt;今回は4ページしっかりと担当できましたし、CGWORLDという映像業界において圧倒的な知名度のある雑誌に寄稿する機会をいただけて、本当に嬉しいです。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説</title>
      <link>https://gam0022.net/blog/2020/04/30/revision2020/</link>
      <pubDate>Thu, 30 Apr 2020 12:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/04/30/revision2020/</guid>
      <description>&lt;p&gt;4月10日～4月13日に世界最大のデモパーティ&lt;a href=&#34;https://2020.revision-party.net/start&#34;&gt;Revision 2020&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;Revision 2020内で開催されたコンペのうち、&lt;a href=&#34;https://2020.revision-party.net/competitions/pc-competitions&#34;&gt;PC 64K Intro&lt;/a&gt;という64KBの容量制約のある部門で『RE: SIMULATED by gam0022 &amp;amp; sadakkey』という作品を発表しました。&lt;/p&gt;

&lt;p&gt;Tokyo Demo Fest 2018に続き、私（&lt;a href=&#34;https://twitter.com/gam0022&#34;&gt;@gam0022&lt;/a&gt;）が映像を、さだきちさん（&lt;a href=&#34;https://twitter.com/sadakkey&#34;&gt;@sadakkey&lt;/a&gt;）が音楽を制作しました。&lt;/p&gt;

&lt;p&gt;……なんと、本作品が参加者投票により1位に選ばれました！
日本人のチームがPC 64K Intro部門で優勝するのは Revision 史上初です。とても嬉しいです！&lt;/p&gt;

&lt;p&gt;本記事では、技術解説をメインに、『RE: SIMULATED by gam0022 &amp;amp; sadakkey』を紹介したいと思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34; alt=&#34;resimulated-collage&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;作品へのリンク&#34;&gt;作品へのリンク&lt;/h1&gt;

&lt;p&gt;WebGLとWebAudioによる64K Introなので、最新のChromeと高性能なGPUがあれば、ブラウザ上で動作します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/webgl/64k-intro_resimulated.html&#34;&gt;64KB HTML version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://neort.io/art/bqa4pgs3p9f6qoqnmujg&#34;&gt;NEORT version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高スペックのPCを持っていない方は、YouTubeの動画をご覧ください。&lt;/p&gt;

&lt;p&gt;フラクタルをつかった映像のビットレートの高い作品ですが、4K解像度を選ぶことである程度は綺麗な状態で見れます。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/tirAdWbceak&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;こちらはpouet（デモシーンのコミュニティサイト）のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=85260&#34;&gt;RE: SIMULATED by Gam0022 &amp;amp; Sadakkey :: pouët.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;技術解説&#34;&gt;技術解説&lt;/h1&gt;

&lt;p&gt;ソースコードはすべてGitHubに公開しているので、興味がある方はぜひ見てください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated&#34;&gt;gam0022/resimulated: 1st place at Revision 2020 (PC 64K Intro)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;サウンド編についてはさだきちさんが解説されています。あわせてご覧ください！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.klab.com/jp/blog/creative/2020/revision-2020-pc-64k-intro.html&#34;&gt;Revision 2020 のPC 64K INTRO 優勝作品のサウンドについて&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;キーワードとしては、以下の技術が使われています。&lt;/p&gt;

&lt;p&gt;TypeScript, WebGL, WebAudio, webpack, pnginator.rb, Raymarching, GLSL Sound&lt;/p&gt;

&lt;h2 id=&#34;シンプルなwebglエンジン-chromatiq&#34;&gt;シンプルなWebGLエンジン『Chromatiq』&lt;/h2&gt;

&lt;p&gt;64KBの容量制約があるため、Unityやthree.jsといった既存のゲームエンジンやフレームワークを利用せずに、描画用のWebGLエンジンと制作用のツール（エディタ機能）を自作する必要がありました。&lt;/p&gt;

&lt;p&gt;OpenGLやDirectXを使わずに、WebGLを選択した理由は以下です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WebGLでブラウザ上で動かせれば、手元のPCで動かしてもらえる可能性が高いと考えた

&lt;ul&gt;
&lt;li&gt;自分の作品は映像のビットレートが高く、動画だと綺麗にならない&lt;/li&gt;
&lt;li&gt;手元のPCで実行して綺麗な状態で見てもらいたい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Webフロントエンドの技術をキャッチアップしたかった&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そこで、64K Intro向けに&lt;strong&gt;ファイルサイズの最小化を目指したシンプルなWebGLエンジン『Chromatiq』&lt;/strong&gt;を開発しました。&lt;/p&gt;

&lt;p&gt;WebGLエンジンとは言うものの、本当にシンプルで最小限な機能しか &amp;ldquo;現段階では&amp;rdquo; 実装していません。&lt;/p&gt;

&lt;p&gt;なるべく作品に依存した機能は用意したくなかったので、汎用的な設計になっています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;マルチパスのImageShaderによるレンダリング（viewport square）&lt;/li&gt;
&lt;li&gt;ビルドインのBloomのポストエフェクト

&lt;ul&gt;
&lt;li&gt;どんな作品でも利用できそうなので、これだけビルドインにした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TypeScriptからuniformをアニメーションするためのインターフェース&lt;/li&gt;
&lt;li&gt;Shadertoyと互換性のあるGLSL Sound&lt;/li&gt;
&lt;li&gt;オーディオファイルの再生（mp3 / ogg）

&lt;ul&gt;
&lt;li&gt;DAWによる音楽の再生用の機能&lt;/li&gt;
&lt;li&gt;今回は先にDAWで作曲し、後からGLSLに移植する作戦にした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;フォントをレンダリングするためのcanvasからのテクスチャ生成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;イメージとしてはGLSLエディタを排除したスタンドアローンなShadertoyが近いかもしれません。&lt;/p&gt;

&lt;p&gt;ソースコードは&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/chromatiq.ts&#34;&gt;こちら&lt;/a&gt;です。単一ファイルのTypeScriptで実装しました。&lt;/p&gt;

&lt;p&gt;圧縮後のコードサイズを気にして、変な感じの実装になっているので、微妙に読みづらいかもしれません。&lt;/p&gt;

&lt;p&gt;例えば、フィールド参照の this を頭につけるとコードサイズが増えるため、コンストラクタの中で動的にインスタンスメソッドを定義することで、this の利用を最小限にしたり、
クラス外から値を参照・設定する必要があるデータのみ、フィールドとして定義する方針とています。enumもコードサイズが増えるので禁止にしました。&lt;/p&gt;

&lt;p&gt;製作の終盤から容量が余裕そうなことが判明したので、途中からファイルサイズを考慮するのを止め、mini化の中途半端感は否めないです。
このあたりは、次のデモに向けて改良していきたいと考えています。&lt;/p&gt;

&lt;p&gt;uniform名は基本的にはShadertoyと一致させているのですが、テクスチャのサンプラーはShadertoyを踏襲せずに、直前のパスを参照する &lt;code&gt;iPrevPass&lt;/code&gt; を定義しました。
これによってGLSLを書き換えずにエフェクトの順番を入れ替えたり、気軽にパスを増やしてエフェクトをチェインしやすくしました。
このあたりの仕様も、作品の需要に応じて変更していく可能性は高いです。&lt;/p&gt;

&lt;h2 id=&#34;ファイル圧縮のためのビルドプロセス&#34;&gt;ファイル圧縮のためのビルドプロセス&lt;/h2&gt;

&lt;p&gt;圧縮には&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;と&lt;a href=&#34;https://gist.github.com/gasman/2560551&#34;&gt;pnginator.rb&lt;/a&gt;を利用しています。&lt;/p&gt;

&lt;p&gt;ビルドプロセスを図にしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/build-process.svg&#34; alt=&#34;build-process&#34; /&gt;&lt;/p&gt;

&lt;p&gt;webpackですべてのファイルをbundle.jsという単一のJavaScriptに固めてから、pnginator.rbで自己解凍形式のPNGにしています。&lt;/p&gt;

&lt;p&gt;TypeScriptのminifyは完全にwebpack任せです。&lt;/p&gt;

&lt;p&gt;PNGでは画像データをzlib圧縮するため、画像データではなくても、例えば今回のようなプログラムのソースコードでちゃんと圧縮できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/364c7f76f2787e385161&#34;&gt;GLSLのminifyも検証&lt;/a&gt;はしていて、webpackのLoaderを開発する予定もあったのですが、容量が余裕だったのでGLSLの圧縮はPNG（zlib）だけになりました。&lt;/p&gt;

&lt;p&gt;また、開発用にしか必要ないコードの削除もwebpackの&lt;a href=&#34;https://webpack.js.org/plugins/define-plugin/&#34;&gt;define-plugin&lt;/a&gt;で実現できました。&lt;/p&gt;

&lt;p&gt;webpackとpnginator.rbを組み合わせる手法は、&lt;a href=&#34;https://twitter.com/FMS_Cat&#34;&gt;FMS_Catさん&lt;/a&gt;の&lt;a href=&#34;https://github.com/FMS-Cat/until/&#34;&gt;Until&lt;/a&gt;を参考にしました。&lt;/p&gt;

&lt;p&gt;当初はnode.jsでGLSLのホットリロード機能付きのWebサーバを開発しようと技術検証していたのですが、
要件は&lt;a href=&#34;https://github.com/webpack/webpack-dev-server&#34;&gt;webpack-dev-server&lt;/a&gt;ですべて実現可能だったので、webpackを採用しました。&lt;/p&gt;

&lt;p&gt;PRごとに圧縮後のファイルサイズを確認するようにしたら、圧縮後のファイルサイズについて知見が貯まりました（例）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コードの自動フォーマットをかけると、圧縮効率が上がってファイルサイズが減る&lt;/li&gt;
&lt;li&gt;コードをコピペすると圧縮効率が高くなるので、実は無理にコードを共通化する意味は実は薄い&lt;/li&gt;
&lt;li&gt;似たよな構造になるようにコードを意識すると圧縮効率が良くなる&lt;/li&gt;
&lt;li&gt;関数の順番を入れ替えただけで微妙にサイズが減ったりと謎が多い&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;制作用のエディタ機能の紹介&#34;&gt;制作用のエディタ機能の紹介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34; alt=&#34;chromatiq-editor&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;製作のイテレーションを高速化するため、必要なエディタ機能は一通り実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;再生位置のシーク機能

&lt;ul&gt;
&lt;li&gt;再生・一時停止・停止・フレームのコマ送り・時間の表示単位の秒とビートの切り替え&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;GLSLやTypeScriptのホットリロード機能&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタ&lt;/li&gt;
&lt;li&gt;カメラの自由移動&lt;/li&gt;
&lt;li&gt;デバッグ用に特定のパスの表示&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;エディタ機能は容量制約に影響しないので、既存のライブラリを積極的に利用しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ボタン用のアイコンのために、&lt;a href=&#34;https://fontawesome.com/&#34;&gt;fontawesome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタのために、&lt;a href=&#34;https://github.com/dataarts/dat.gui&#34;&gt;dat.gui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;カメラの自由移動のために、&lt;a href=&#34;https://threejs.org/&#34;&gt;three.js&lt;/a&gt;の&lt;a href=&#34;https://threejs.org/docs/#examples/en/controls/OrbitControls&#34;&gt;OrbitControls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated#1-get-started&#34;&gt;リポジトリ&lt;/a&gt;をcloneして、 &lt;code&gt;npm run start&lt;/code&gt; すれば、エディタ機能が使えますので、興味がある人はお試しください。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:gam0022/resimulated.git
cd resimulated
npm install

# 制作用のエディタを起動
npm run start

# 提出用のビルド（dist\resimulated.html）を生成
npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;uniformのパラメータのインスペクタ&#34;&gt;uniformのパラメータのインスペクタ&lt;/h3&gt;

&lt;p&gt;GLSL上で以下のようなuniformを宣言するだけで、そのままインスペクタに表示されるような仕組みを実装しました。&lt;/p&gt;

&lt;p&gt;コメントでは左から順に &lt;code&gt;初期値 min max カテゴリー名&lt;/code&gt; を指定しています。初期値は必須ですが、それ以外は省略可能としました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;uniform float gEmissiveIntensity;     // 6.0 0 20 emissive
uniform float gEmissiveSpeed;         // 1 0 2
uniform float gEmissiveHue;           // 0.33947042613522904 0 1
uniform float gEmissiveHueShiftBeat;  // 0 0 1
uniform float gEmissiveHueShiftZ;     // 0 0 1
uniform float gEmissiveHueShiftXY;    // 0 0 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;uniform宣言をすると、自動的にインスペクタにパラメータが追加されます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor-emissive.png&#34; alt=&#34;chromatiq-editor-emissive&#34; /&gt;&lt;/p&gt;

&lt;p&gt;私の作品では、フラクタルやIFSといったパラメータの細かな調整が重要になる表現を多用しているため、気軽にパラメータを増やして、気軽に値を調整できるようにしました。&lt;/p&gt;

&lt;p&gt;値の当たりをつけた後に、パラメータのアニメーションを&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/index.common.ts#L142-L569&#34;&gt;TypeScriptのコード&lt;/a&gt;に落とし込むワークフローにしました。&lt;/p&gt;

&lt;p&gt;これは、インスペクタを動かしている様子の動画です。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;三谷先生に便乗して、MengerSponge をカットしてみました。&lt;br&gt;断面が星みたいになって面白いですね⭐️ &lt;a href=&#34;https://t.co/mCqFnfbjBF&#34;&gt;https://t.co/mCqFnfbjBF&lt;/a&gt; &lt;a href=&#34;https://t.co/QF73xfFL1y&#34;&gt;pic.twitter.com/QF73xfFL1y&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1253296266424930304?ref_src=twsrc%5Etfw&#34;&gt;April 23, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画の保存機能&#34;&gt;動画の保存機能&lt;/h3&gt;

&lt;p&gt;処理落ちなしに4K解像度で動画を出力したかったので、以下の機能を実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;映像の連番PNG保存機能&lt;/li&gt;
&lt;li&gt;サウンドの wav 保存機能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;.png と .wav を ffmpeg で .mp4 に変換してYouTubeにアップロードしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ffmpeg.exe -r 60 -i chromatiq%04d.png -i chromatiq.wav -c:v libx264 -preset slow -profile:v high -coder 1 -pix_fmt yuv420p -movflags +faststart -g 30 -bf 2 -c:a aac -b:a 384k -profile:a aac_low -b:v 68M chromatiq_68M.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;YouTube用のffmpegのエンコード設定については、以下を参考にしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://support.google.com/youtube/answer/1722171?hl=ja&#34;&gt;アップロードする動画におすすめのエンコード設定&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;映像ビットレート 2160p（4k）53～68 Mbps&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/mikoim/27e4e0dc64e384adbcb91ff10a2d3678&#34;&gt;YouTube recommended encoding settings on ffmpeg (+ libx264)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/sasaki_0222/status/1248910333835530241&#34;&gt;解像度とビットレードについて by sasaki_0222&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;映像について&#34;&gt;映像について&lt;/h2&gt;

&lt;p&gt;映像の3D描画は基本的に全部レイマーチングです。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンはMandelboxをベースにしました。&lt;/p&gt;

&lt;p&gt;後半の宇宙空間とグリーティングのシーンでは、宇宙空間はレイマーチング、惑星の上のグリーティングの文字はAABBとして解析的に衝突判定をするハイブリッドなレイトレをしています。&lt;/p&gt;

&lt;p&gt;パスの構成は、最終的にこうなりました。&lt;/p&gt;

&lt;p&gt;1パス目と2パス目を分離したのは、シェーダーのコンパイル時間の短縮のためです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1パス目: 前半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;2パス目: 後半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;3パス目: テキストの描画&lt;/li&gt;
&lt;li&gt;4～13パス目: Bloomのポストエフェクト&lt;/li&gt;
&lt;li&gt;14パス目: ポストエフェクトとトーンマッピング&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;惑星のバリエーション生成の仕組み&#34;&gt;惑星のバリエーション生成の仕組み&lt;/h3&gt;

&lt;p&gt;後半のグリーティングでは、自分が特に尊敬しているデモグループをイメージした惑星が合計14パターン登場します。&lt;/p&gt;

&lt;p&gt;様々なバリエーションの惑星を効率的に生成するための仕組みを実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;地形の高さマップの自動生成&lt;/li&gt;
&lt;li&gt;テクスチャの色のグラデーションの自動生成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;地形の高さマップの自動生成&#34;&gt;地形の高さマップの自動生成&lt;/h4&gt;

&lt;p&gt;2DのValue Noiseを重ね合わせたfbm（Fractal Brownian Motion）で地形の高さマップを生成しました。&lt;/p&gt;

&lt;p&gt;さらに、fbm関数をネストして（fbmのUV計算にfbmをつかって）、歪んだような不思議な雰囲気の地形も生成できるようにしました。&lt;/p&gt;

&lt;p&gt;左がfbmのネストよる歪みなしで、右がfbmのネストによる歪みありです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34; alt=&#34;fbm-shift&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fbmの各種パラメーター（振幅や周波数、Y方向のスケール、歪み用のfbmの強度）は、乱数ではなく、配列で直接指定することで、イメージ通りの結果に調整できるようにしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fbmAmp, fbmFreq, fbmYScale, fbmShift
vec4[PLANETS_PAT_MAX * PLANETS_NUM_MAX] planetFbmParams = vec4[](
    // MIX_A
    vec4(0.3, 17.0, 1.0, 0.01), vec4(0.05, 10.0, 1.05, 0.0), vec4(0.05, 10.0, 1.05, 0.01),
    vec4(0.05, 10.0, 4.05, 0.02), vec4(0.05, 10.0, 2.05, 00.1), vec4(0.0),
    // MIX_B
    vec4(0.0, 10.0, 1.0, 0.2), vec4(0.0, 10.0, 1.0, 0.01), vec4(0.0, 10.0, 1.0, 0.03),
    vec4(0.05, 10.0, 1.0, 00.2), vec4(0.06, 10.0, 1.0, 0.03), vec4(0.05, 10.0, 1.0, 0.03));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このようなfbmをネストしたシンプルな関数で高さマップを生成しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 惑星の高さマップ（height map）を生成する関数
// pは球体のUV, id は惑星のID
float hPlanetsMix(vec2 p, int id) {
    p.y *= planetFbmParams[id].z;
    return fbm(p + 
        planetFbmParams[id].w * fbm(p, 4.0 * planetFbmParams[id].y), planetFbmParams[id].y);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;テクスチャの色のグラデーションの自動生成&#34;&gt;テクスチャの色のグラデーションの自動生成&lt;/h4&gt;

&lt;p&gt;iqのColor Palettesを使いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iquilezles.org/www/articles/palettes/palettes.htm&#34;&gt;Color Palettes - Inigo Quilez :: fractals, computer graphics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec3 pal(in float t, in vec3 a, in vec3 b, in vec3 c, in vec3 d) {
    return a + b * cos(TAU * (c * t + d));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pal 関数の使い方は簡単で、&lt;code&gt;a, b, c, d&lt;/code&gt; を任意に指定すれば、&lt;code&gt;t&lt;/code&gt; を変化することでグラデーションを生成できます。&lt;/p&gt;

&lt;p&gt;今回は &lt;code&gt;a, b, c&lt;/code&gt; は定数、&lt;code&gt;d&lt;/code&gt; は惑星ごとに乱数で決定しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;a, b, c&lt;/code&gt; や乱数のseed値はインスペクタで値を調整しながら、イメージ通りのグラデーションが生成されるまで試行錯誤しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;t&lt;/code&gt; は地形の高さマップにマッピングしました。&lt;/p&gt;

&lt;h3 id=&#34;無数の小惑星のランダムな配置&#34;&gt;無数の小惑星のランダムな配置&lt;/h3&gt;

&lt;p&gt;宇宙空間がスカスカすぎて寂しかったので、無数の小惑星をランダムに配置しようとしたら、予想外に苦戦しました。&lt;/p&gt;

&lt;p&gt;レイマーチングだと空間をmodすることで物体を無限に複製することは簡単なのですが、それでは規則的な配置にしかならず、かなり不自然になってしまいます。&lt;/p&gt;

&lt;p&gt;gazさんのシェーダーを参考にして、空間をgridに分割して、gridごとに乱数を生成して、乱数で確率的に物体を間引く手法を採用しました。&lt;/p&gt;

&lt;p&gt;また、アーティファクトの回避するために、rayの長さを制限する工夫も必要でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;もう忘れてるよ。自分で読み解いてしまったじゃないか。xy平面を通常のmod()で分割。z軸の奥行のみgridをseedに乱数を使い間引きしてる。z軸だけ空間移動のスピード、回転を変えてる。アーティファクト対策で、min(map(p), 1.0)を使いrayの長さを制限。effectにビルボードを使い発光を演出。&lt;/p&gt;&amp;mdash; gaz (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1247671912521596928?ref_src=twsrc%5Etfw&#34;&gt;April 7, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;最終的に、ランダムな位置と大きさをもつ小惑星の距離関数はこうなりました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float dGomi(vec3 p) {
    // アーティファクト対策のための固定長の距離
    float d = 1.0;

    // グリット（4m四方の立方体）の計算
    vec3 g = vec3(floor(p / 4.0));

    // 座標の繰り返し
    p = mod(p, 4.0) - 2.0;

    // 確率 rate に応じて球体を配置
    vec3 rand = hash33(g);
    float rate = (gPlanetsId != PLANETS_EARTH) ? 0.08 : 0.01;
    if (rand.x &amp;lt; rate) {
        p -= (rand - 0.5);
        d = sdSphere(p, 0.1 * rand.y);
    }

    // fbmで表面の凹凸のディテールを加える
    // レイが接近したときだけに計算するのは、LODによる負荷対策
    // fbmの計算はかなり高負荷なので、LODをしないと激重になる
    if (d &amp;lt; 0.5) {
        vec2 uv = uvSphere(normalize(p));
        uv.x += dot(rand, vec3(1.0));
        d -= remapTo(rand.z, 0.01, 0.08) * fbm(uv, 5.0);
    }

    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;音楽について&#34;&gt;音楽について&lt;/h2&gt;

&lt;p&gt;基盤となるGLSLサウンド用のシーケンサーの実装は私が、それ以外のオシレーターの関数やメロディの実装はさだきちさんが担当しました。&lt;/p&gt;

&lt;p&gt;音楽もやはり容量制約のためにGLSLで実装する必要があり、さだきちさんにはコーディングによる作曲をお願いしました。
さだきちさんはプログラミングもGLSLも未経験だったので、それらの習得から始まりました。
かなり無茶なお願いだったにも関わらず、かっこいいトランスミュージックを提供してくれたさだきちさんには感謝しかありません。ありがとうございます！&lt;/p&gt;

&lt;p&gt;私が担当したGLSLサウンド用のシーケンサーはGLSLサウンド上で実装されており、GLSLサウンドを鳴らす仕組みについては、AMAGIさん（&lt;a href=&#34;https://twitter.com/amagitakayosi&#34;&gt;@amagitakayosi&lt;/a&gt;）の記事を参考に、Shadertoy互換のGLSLサウンドの再生機能を実装しました。ありがとうございます！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.amagi.dev/entry/veda-sound&#34;&gt;VEDA 2.4: GLSLで音楽を演奏できるようになったぞ！！！ - マルシテイア&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;サウンド用のシーケンサーの利用例&#34;&gt;サウンド用のシーケンサーの利用例&lt;/h3&gt;

&lt;p&gt;これはベースのパートの波形を生成するGLSLの関数です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec2 bass1(float beat, float time) {
// 1つのパターンのビート数
#define BASS1_BEAT_LEN 8

// パターンの種類
#define BASS1_DEV_PAT 10

// 楽曲全体の長さのパターン数
#define BASS1_DEV_LEN 32

    // パターンの定義
    int[BASS1_BEAT_LEN * NOTE_DIV * BASS1_DEV_PAT] notes = int[](
        // パターン0
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),

        // パターン1
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),

        // パターン2
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(48, 47, 43, 40),

        // パターン3
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34),

        // パターン4
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 36, 36, 36),

        // パターン5
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34), S(0, 36, 36, 36),

        // パターン6
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 43, 43, 43), S(0, 55, 57, 69),

        // パターン7
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31),

        // パターン8
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 43, 45, 57),

        // パターン9
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(0, 31, 31, 31));

    // パターンの進行
    int[BASS1_DEV_LEN / DEV_PACK] development = int[](
        D(0, 0, 0, 0, 0, 0, 0, 0), D(1, 1, 1, 2, 3, 4, 5, 6),
        D(7, 0, 7, 8, 7, 0, 9, 0), D(0, 0, 0, 0, 0, 0, 0, 0));

    SEQUENCER(beat, time, BASS1_BEAT_LEN, BASS1_DEV_PAT, BASS1_DEV_LEN,
        notes, development, bass)

    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターン（2小節分のノートナンバーの並び）の定義と進行は、それぞれ配列で指定できるようにしています。&lt;/p&gt;

&lt;p&gt;音の長さは下記の4種類に対応しました。
ノートナンバーに0を指定すれば、同じ長さの休符になります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;O: 全音符&lt;/li&gt;
&lt;li&gt;F: 4分音符&lt;/li&gt;
&lt;li&gt;E: 8分音符&lt;/li&gt;
&lt;li&gt;S: 16分音符&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GLSLのコンスタントバッファのサイズには上限があり、サウンド用のシェーダー全体で要素数が4096個まででしか配列を宣言できません。&lt;/p&gt;

&lt;p&gt;そこで、&lt;code&gt;O, F, E, S&lt;/code&gt; を関数マクロとし、16分音符を最小単位として各音符を16bit（うち、ノートナンバーが8bit、音の長さが8bit）ずつパッキングしています。
GLSLのintは32bitなので、int配列の1要素に16分音符なら2つ、8分音符なら1つ入るような設計です。&lt;/p&gt;

&lt;p&gt;また、パターン進行の &lt;code&gt;D&lt;/code&gt; もマクロにしていて、要素数の節約のために4bitずつパッキングをしています。&lt;/p&gt;

&lt;p&gt;続いて、&lt;code&gt;bass&lt;/code&gt; は時間とノートナンバーを入力として、波形を出力するオシレーターのGLSL関数です。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;SEQUENCER&lt;/code&gt; は、時間、パターンの定義の配列、パターンの進行の配列、オシレーターの関数を指定することで、パートごとの波形を生成して &lt;code&gt;vec2 ret&lt;/code&gt; に代入する関数マクロです。
GLSLでは関数を引数とするような高階関数は実現できませんが、関数マクロで擬似的に実現しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define SEQUENCER(beat, time, beatLen, devPat, devLen, notes, development, toneFunc)  \
    int indexOffset = development[int(                                                \
        mod(beat / float(beatLen * DEV_PACK), float(devLen / DEV_PACK)))];            \
    indexOffset =                                                                     \
        (indexOffset &amp;gt;&amp;gt; (4 * int(mod(beat / float(beatLen), float(DEV_PACK))))) &amp;amp; 15; \
    indexOffset *= beatLen * NOTE_VDIV;                                               \
                                                                                      \
    for (int i = 0; i &amp;lt; beatLen * NOTE_VDIV;) {                                       \
        int index = i + indexOffset;                                                  \
        int shift = (index % 2 == 1) ? 16 : 0;                                        \
        int div = ((notes[index &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;gt;&amp;gt; 8) &amp;amp; 255;                          \
        int len = NOTE_VDIV * NOTE_VDIV / div;                                        \
        for (int j = 0; j &amp;lt; len; j++) {                                               \
            tmpIndexes[i + j] = i;                                                    \
        }                                                                             \
        i += len;                                                                     \
    }                                                                                 \
                                                                                      \
    float indexFloat = mod(beat * float(NOTE_VDIV), float(beatLen * NOTE_VDIV));      \
    int index = int(indexFloat);                                                      \
    int shift = (index % 2 == 1) ? 16 : 0;                                            \
    int note = (notes[(index + indexOffset) &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;amp; 255;                    \
    float localTime =                                                                 \
        beatToTime((indexFloat - float(tmpIndexes[index])) / float(NOTE_VDIV));       \
    float amp = (note == 0) ? 0.0 : 1.0;                                              \
    vec2 ret = vec2(toneFunc(float(note), localTime) * amp);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターンの定義・進行のマクロはこちらです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 1ビートを最大何分割するか。16分音符に対応するなら4
#define NOTE_VDIV 4

// 1ビートのpackingを考慮した分割数。32bitのintに16bitずつ詰めているので
// 4 / (32 / 16) = 2
#define NOTE_DIV 2

// 展開用の配列のpacking数。32bitのintに4bitずつ詰めているので
// 32 / 4 = 8
#define DEV_PACK 8

#define MAX_BEAT_LEN 8
int[MAX_BEAT_LEN * NOTE_VDIV] tmpIndexes;

#define O(a)                                                                      \
    (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16),     \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define F(a) (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define E(a, b) (a | 8 &amp;lt;&amp;lt; 8) | ((a | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (b | 8 &amp;lt;&amp;lt; 8) | ((b | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define S(a, b, c, d) \
    (a | 16 &amp;lt;&amp;lt; 8) | ((b | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (c | 16 &amp;lt;&amp;lt; 8) | ((d | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define D(a, b, c, d, e, f, g, h) \
    (a) | (b &amp;lt;&amp;lt; 4) | (c &amp;lt;&amp;lt; 8) | (d &amp;lt;&amp;lt; 12) | (e &amp;lt;&amp;lt; 16) | (f &amp;lt;&amp;lt; 20) | (g &amp;lt;&amp;lt; 24) | (h &amp;lt;&amp;lt; 28)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;re-simulated-の意味&#34;&gt;『RE: SIMULATED』の意味&lt;/h1&gt;

&lt;p&gt;タイトルの『RE: SIMULATED』には2つの意味を込めました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;前作『WORMHOLE』の64K Introとしての「再現」&lt;/li&gt;
&lt;li&gt;SIMULATED REALITY&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-前作-wormhole-の64k-introとしての-再現&#34;&gt;1. 前作『WORMHOLE』の64K Introとしての「再現」&lt;/h2&gt;

&lt;p&gt;一昨年のTokyo Demo Fest 2018のCombined Demo Compoでも、さだきちさんとチームを組んで『WORMHOLE』という作品を制作しました（&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;記事&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;前半のシーンが顕著ですが、『WORMHOLE』と表現や演出が酷似していると思います。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;フラクタルの形状変化&lt;/li&gt;
&lt;li&gt;光の色の変化&lt;/li&gt;
&lt;li&gt;シーン転換前の激しい点滅&lt;/li&gt;
&lt;li&gt;シーン転換後のホワイトイン&lt;/li&gt;
&lt;li&gt;パーティのロゴの登場&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;『WORMHOLE』はUnityで制作したので、60.7 MB（zip圧縮で 23.18MB）というファイルサイズでした。&lt;/p&gt;

&lt;p&gt;前作では、Unityを利用したことで賛否両論があったので、ツールに頼らなくても同様のビジュアルを再現できることを証明する意図がありました。&lt;/p&gt;

&lt;p&gt;また、64K Introなどの容量制限のある部門への参加が個人的にも憧れだったという理由もあります。&lt;/p&gt;

&lt;p&gt;今回は自作のシステムで作品を制作することでファイルサイズは26KBになりました。&lt;/p&gt;

&lt;p&gt;同じ表現を「再現」しつつも、容量を &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2334&lt;/sub&gt; まで圧縮する試みのコンセプトは達成できました。&lt;/p&gt;

&lt;p&gt;まさか、コンポで優勝するという結果まで「再現」してしまうのは予想外でした（笑）&lt;/p&gt;

&lt;h2 id=&#34;2-simulated-reality&#34;&gt;2. SIMULATED REALITY&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%BC%E3%83%86%E3%83%83%E3%83%89%E3%83%BB%E3%83%AA%E3%82%A2%E3%83%AA%E3%83%86%E3%82%A3&#34;&gt;Simulated Reality&lt;/a&gt;という裏設定もありました。&lt;/p&gt;

&lt;p&gt;作品の最後に「RE: SIMULATED」の文字が&lt;/p&gt;

&lt;p&gt;&lt;code&gt;RE: SIMULATED&lt;/code&gt; → &lt;code&gt;RE&lt;/code&gt; → &lt;code&gt;REALITY&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;と変化して、REALITYに変化するタイミングで「地球」がフラッシュバックするのは、Simulated Realityの暗喩です。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンは電子的な仮想空間という設定で、シーン転換時に球体を中心に空間が歪んで圧縮するのは、宇宙誕生の爆発であるビッグバンの暗喩です。&lt;/p&gt;

&lt;p&gt;この世界は上位存在によって電子的にシミュレーションされた仮想現実で、最後に自分たちが住む地球を見つけるというストーリーでした（あくまで裏設定だったので、見た人に通じなくても良い）。&lt;/p&gt;

&lt;p&gt;できれば現実と見分けがつかないようなリアルなグラフィックで表現できたら良かったのですが、力量不足でした……。&lt;/p&gt;

&lt;h1 id=&#34;おわりに&#34;&gt;おわりに&lt;/h1&gt;

&lt;p&gt;Webフロントエンドは久しぶりで、node.jsとwebpackは初めてだったので、新しい技術を学ぶ良い機会となりました。&lt;/p&gt;

&lt;p&gt;昔はjQueryが必要だったDOMのセレクターやHTTPアクセスが、標準のAPI（&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Document/querySelector&#34;&gt;querySelector&lt;/a&gt;や&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Fetch_API/Using_Fetch&#34;&gt;Fetch&lt;/a&gt;）になっていて驚きました。&lt;/p&gt;

&lt;p&gt;TypeScript（ECMascript）に苦手意識がありましたが、最近はかなり使いやすい言語になったなぁと認識を改めました。
演算子オーバーロードがないのだけは、3Dプログラミングには必須のベクトル計算の実装の可読性が落ちて苦しい気持ちになったので、早くサポートして欲しいと感じました。&lt;/p&gt;

&lt;p&gt;また、64K Introのエントリーは今回が初めてということで、どのくらいのコンテンツが詰め込めるか感覚がつかめず、容量を半分以上も余らせてしまいました。
次の機会には64KBギリギリまで使って、もっと映像としても洗練させて、さらにCoolな作品を発表したいです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;実は26KBしか使いきれなかったので、次回は64KBギリギリまで使えるように精進します💪 &lt;a href=&#34;https://t.co/uxF2M5DZmg&#34;&gt;pic.twitter.com/uxF2M5DZmg&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1249677712815321088?ref_src=twsrc%5Etfw&#34;&gt;April 13, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;例年のRevisionの64K Introの作品と比較すると、かなり未熟なので、もっと精進して最高のデモを作りたいという気持ちです。&lt;/p&gt;

&lt;p&gt;ともあれ、このたびは優勝作品に選んでいただき、とても光栄に思います。&lt;/p&gt;

&lt;p&gt;世界中の尊敬するデモチームの方々からいただいたお祝いのコメントも嬉しかったです。わーい！&lt;/p&gt;

&lt;p&gt;最後に、世界的に大変な状況の中、オンラインでの開催のためにご尽力いただいた皆様に、心より感謝申し上げます。
とても楽しく充実した3日間を過ごせました。来年はドイツでお会いしましょう！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>近未来教育フォーラム2019でシェーダーライブコーディングをしました</title>
      <link>https://gam0022.net/blog/2019/11/29/dhw/</link>
      <pubDate>Fri, 29 Nov 2019 10:36:17 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/11/29/dhw/</guid>
      <description>&lt;p&gt;2019/11/28にデジタルハリウッド大学で開催された&lt;a href=&#34;https://www.dhw.co.jp/forum/program.html&#34;&gt;近未来教育フォーラム&lt;/a&gt;の
「The Real Time Live &amp;amp; Reception リアルタイムグラフィックスの世界とVTuberが牽引する新たな人類」というイベントに登壇しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/FL1NE&#34;&gt;@FL1NE&lt;/a&gt;さんと一緒にデモシーンについて話しました。
私は簡単なシェーダーライブコーディングをしながらプログラミングによる形状のモデリングについて解説しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/o_ob/status/1200067621799903238&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding_init.jpg&#34; alt=&#34;シェーダーライブコーディング（初期）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_/status/1199999036964474886&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding.jpg&#34; alt=&#34;シェーダーライブコーディング（完成）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;レポート-2020-05-09追記&#34;&gt;レポート（2020/05/09追記）&lt;/h2&gt;

&lt;p&gt;当日の様子のレポートが公開されました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dhw.co.jp/forum/report/report01.html&#34;&gt;近未来教育フォーラム2019 -In Real Time- 公演レポート&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;シェーダーライブコーディングによる作品&#34;&gt;シェーダーライブコーディングによる作品&lt;/h2&gt;

&lt;p&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;/p&gt;

&lt;p&gt;通常の3DCGでは、ツールでモデリングした3Dモデルを読み込んで表示すると思いますが、デモシーンの一部の部門には容量制限があるので、
WORMHOLEではシェーダーによるプログラミングによってプロシージャルにモデリングを行いました。&lt;/p&gt;

&lt;p&gt;発表時間が限られていたので、ハラハラ・ドキドキでしたが、なんとか意図通りの形になって良かったです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200006025878749184?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Gam師のレイマーチング始まってる。 &lt;a href=&#34;https://t.co/MHLrFmbLpL&#34;&gt;pic.twitter.com/MHLrFmbLpL&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1199999036964474886?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画&#34;&gt;動画&lt;/h3&gt;

&lt;p&gt;YouTube配信のアーカイブが残っています。&lt;/p&gt;

&lt;p&gt;34:46〜が自分のシェーダーライブコーディングでした。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/j0yRASXFvlQ?start=2086&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;songofsaya-さんによる解説&#34;&gt;songofsaya_ さんによる解説&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_&#34;&gt;@songofsaya_&lt;/a&gt; さんがTwitterで解説をしてくださっていました。ありがとうございます！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;四角形のパイプと書いたけど、再帰性があるからおそらくメンガーだろうなーと思っていたらメンガーでした。&lt;br&gt;そしてGam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります。 &lt;a href=&#34;https://t.co/VFqKT2jVoq&#34;&gt;pic.twitter.com/VFqKT2jVoq&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1200008658916007938?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Gam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;正解です！&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;発表資料はFL1NEさんが作ってくれました。自分はライブコーディングのところを担当しました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;b3019de333a449a481ff2df647d2d098&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;感想&#34;&gt;感想&lt;/h2&gt;

&lt;p&gt;当日は&lt;a href=&#34;https://www.sli.do/&#34;&gt;sli.do&lt;/a&gt;で来場者の声がリアルタイムに見えるようになっていました。&lt;/p&gt;

&lt;p&gt;sli.doや懇親会で、メガデモとシェーダーについて「楽しそう！」「自分でも作ってみたい」といった好意的な感想をいただけました！&lt;/p&gt;

&lt;p&gt;シェーダやレイマーチングや3DCGに少しでも興味を持っていただけたのなら嬉しい限りです。ありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;メガデモとシェーダーについて&lt;br&gt;「楽しそう！」「自分でも作ってみたい」&lt;br&gt;といった好意的な感想をいただけて嬉しい限りです☺️&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt; &lt;a href=&#34;https://t.co/BCkGVOiAdv&#34;&gt;pic.twitter.com/BCkGVOiAdv&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200068188043501568?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>レイトレ合宿7でレイマーチング対応のGPUパストレーサーを実装しました！</title>
      <link>https://gam0022.net/blog/2019/09/18/rtcamp7/</link>
      <pubDate>Wed, 18 Sep 2019 10:15:43 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/09/18/rtcamp7/</guid>
      <description>&lt;p&gt;9月7日(土)～9月8日(日)に猪苗代湖で開催された&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;自作のレンダラーでこんな画像を &lt;strong&gt;60秒の制限時間&lt;/strong&gt; でレンダリングして4位をいただきました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.jpg&#34; alt=&#34;本番のレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに4K解像度（3840x2160）です！&lt;/p&gt;

&lt;p&gt;事前に本番環境で動作確認できなかったこともあり、よく見ると意図しないアーティファクトが発生しているのですが、許容レベルに収まったのはラッキーでした。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイトレ合宿とは&#34;&gt;レイトレ合宿とは&lt;/h1&gt;

&lt;p&gt;レイトレ合宿は完全自作のレイトレーサーを走らせて画像の美しさを競うイベントです。&lt;/p&gt;

&lt;p&gt;参加者はレンダラーを自作する必要がある！というだけで面白いイベントなのですが、レンダリングの制限時間が毎年どんどん短縮されているのも注目ポイントです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sites.google.com/site/rendering1h/&#34;&gt;第1回のレンダリング合宿&lt;/a&gt;では制限時間が1時間だったのですが、第7回となる今年は60秒制限でした。&lt;/p&gt;

&lt;p&gt;この制限時間はレンダラーを起動してから画像を保存するまでの時間なので、シーンの読み込みからレンダリングをすべて含めて60秒で完了させなくてはなりません。&lt;/p&gt;

&lt;p&gt;そのため、参加者はあらゆる手段をつかって、レンダラーの高速化に本気で取り組む必要があります。&lt;/p&gt;

&lt;p&gt;パストレーシングの高速化のアプローチとしては、サンプリングを効率化する、BVHなどの構造をつかってシーンとの交差判定を効率化する、ノイズを軽減するためにデノイズを行う、などが挙げられます。&lt;/p&gt;

&lt;p&gt;パストレーシングを使わないといけないルールは無いのですが、近年のレイトレ合宿ではパストレーシングが人気です。
今年のレイトレ合宿では、Stochastic Progressive Photon Mappingを実装した&lt;a href=&#34;https://github.com/tabochans&#34;&gt;tabochan&lt;/a&gt;さん以外は全員パストレーシングだったと記憶しています。&lt;/p&gt;

&lt;p&gt;また、複数コアのCPU・複数のGPUを利用したり、メモリのキャッシュ効率を上げてマシンスペックを最大限に活かし切るというのも、実はかなり難しい課題だったりします。私は今年は複数のGPUをうまく使えませんでした…&lt;/p&gt;

&lt;p&gt;参加者はプロダクションレンダラーの開発者やコンピュータグラフィック分野の研究者などのプロの人から、私のように趣味でレンダラーを開発している人まで様々です。&lt;/p&gt;

&lt;p&gt;レイトレ合宿の参加者のレベルが年々向上していて、特に今年は技術的にもアートセンスにも秀でた作品が多い中、4位と上位に食い込めて本当に嬉しかったです！&lt;/p&gt;

&lt;h1 id=&#34;前回までのレイトレ合宿の参加レポート&#34;&gt;前回までのレイトレ合宿の参加レポート&lt;/h1&gt;

&lt;p&gt;ちなみに私は今年で4回目の参加になります。過去の参加レポートはこちらです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/25/rtcamp6-part2/&#34;&gt;レイトレ合宿6 参加報告 Part2（当日編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/18/rtcamp6-part1/&#34;&gt;レイトレ合宿6 参加報告 前編（準備編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/10/02/rtcamp5/&#34;&gt;レイトレ合宿5‽に参加して、Rustでパストレーシングを実装しました！ | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.hatenablog.com/entry/raytracingcamp4&#34;&gt;レイトレ合宿4!? に参加しました！ - gam0022のブログ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redflash-renderer&#34;&gt;Redflash Renderer&lt;/h1&gt;

&lt;p&gt;Redflash というGPUレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;Redflash は NVIDIA® OptiX 6.0 上で実装したパストレーシングによる物理ベースレンダラーで、ポリゴンと &lt;strong&gt;レイマーチング&lt;/strong&gt; が混在したシーンを一貫した描画ができます。&lt;/p&gt;

&lt;p&gt;GitHubにソースコードを公開しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/redflash&#34;&gt;https://github.com/gam0022/redflash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こちらはアーティファクトなしの想定のレンダリング結果です。レンダリングは30分です。クリックすると非圧縮形式の画像になります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030_1920x1080.jpg&#34; alt=&#34;想定したレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;別視点からのレンダリング結果も紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34; alt=&#34;別視点からのレンダリング結果1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.jpg&#34; alt=&#34;別視点からのレンダリング結果2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.jpg&#34; alt=&#34;別視点からのレンダリング結果3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;自作レンダラーの紹介スライドです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;ba3966aad908467e8b21249e828c26d0&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;レイトレ合宿の参加者にとっては常識だと思われる箇所の説明を省略してしまったので、ここから簡単に補足解説をします。&lt;/p&gt;

&lt;h2 id=&#34;neeとmisによるサンプリングの効率化&#34;&gt;NEEとMISによるサンプリングの効率化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.003.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この2つは「パストレーシングのサンプリングを効率化する」ための非常に有名なテクニックです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Next Event Estimation (Direct Light Sampling)&lt;/li&gt;
&lt;li&gt;Multiple Importance Sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next Event EstimationはよくNEEと省略されて呼ばれます。
光源が小さいシーンでは、BSDFによる重点的サンプリングだけではなかなか光源にヒットしません。
そのため、短い計算時間ではノイズだらけの結果になってしまいます。
また、BSDFの分布と光源の方向が異なる場合、むしろBSDFによる重点的サンプリングによって悪化するケースもありえます。
そこで、光源の表面上の点を明示的にサンプリングして光転送経路を生成することで、効率的なサンプリングを行うテクニックがNEEです。&lt;/p&gt;

&lt;p&gt;Multiple Importance SamplingはよくMISと省略されて呼ばれます。
MISは複数のサンプリング戦略を組み合わせることでサンプリングの効率を向上するテクニックです。
具体的には「BSDFによる重点的サンプリング」と「NEEによるライトのサンプリング」の2つの戦略の結果を適切なウェイトで組み合わせることで、サンプリングの効率を向上します。
それぞれのサンプリング戦略が得意な部分だけウェイトを大きくすることで、分散を抑えて効率的にサンプリングができるようになります。
例えば、光源が大きくてroughnessが大きいような「BSDFによる重点的サンプリング」が得意なケースなら「BSDFによる重点的サンプリング」の重みを大きくして、
逆に光源が小さくてroughnessが小さいような「NEEによるライトのサンプリング」が得意なケースなら「NEEによるライトのサンプリング」の重みを大きくします。&lt;/p&gt;

&lt;p&gt;NEEやMISについては、レイトレ合宿の参加者でもある &lt;a href=&#34;https://twitter.com/Shocker_0x15&#34;&gt;@Shocker_0x15&lt;/a&gt; さんが日本語で詳しく記事を書かれています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/path_tracing/&#34;&gt;パストレーシング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/MIS/&#34;&gt;多重重点的サンプリング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;optixとレイマーチングの統合&#34;&gt;OptiXとレイマーチングの統合&lt;/h2&gt;

&lt;p&gt;OptiXには独自のプリミティブを定義する仕組みがあるため、OptiXとレイマーチングの統合はそこまで苦労しませんでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IntersectionProgram&lt;/code&gt; と &lt;code&gt;BoundingBoxProgram&lt;/code&gt; としてレイマーチングによる交差判定とAABBの定義をCUDAで実装するだけでできました。&lt;/p&gt;

&lt;p&gt;詳細はレイトレ合宿アドベントカレンダーの記事で既に紹介しているので、気になる方は読んでみてください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;衝突判定の高速化&#34;&gt;衝突判定の高速化&lt;/h2&gt;

&lt;p&gt;BVHの構築はOptiXが自動でやってくれるので、ポリゴンの衝突判定は特に高速化しませんでした。
なんとOptiX 6.0ではRTXに対応しているので、RTX 2070ではハードウェアをつかって高速化な衝突判定ができました！（が、本番環境はRTX非対応でした…）&lt;/p&gt;

&lt;p&gt;一方でレイマーチングの衝突判定については自力で行う必要がありました。
シーン全体を1個の距離関数で表現したため、BVHなどの構造では衝突判定の高速化が難しいためです。&lt;/p&gt;

&lt;h3 id=&#34;距離関数の軽量化&#34;&gt;距離関数の軽量化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.008.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レイマーチングでは1本をレイを飛ばすごとに数百回も距離関数を評価する必要があります（今回のレンダリング結果は300回）。&lt;/p&gt;

&lt;p&gt;レイマーチングの負荷は距離関数の複雑さに比例するので、距離関数の軽量化は効果が大きい最適化でした。&lt;/p&gt;

&lt;p&gt;今回はMandelboxという伝統的なフラクタル図形を距離関数として用いたのですが、
メジャーなMandelboxの実装では &lt;code&gt;sphereFold&lt;/code&gt; という操作で分岐があったりとGPUには高負荷なものでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sphereFold&lt;/code&gt; のどちらの分岐に入るかはMandelboxのパラメータによって決まるので、
一部のパラメータを削除したり、パラメータの範囲を狭めることで分岐を削除して処理を簡略化しました。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチングの衝突判定の精度のlod&#34;&gt;レイマーチングの衝突判定の精度のLOD&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.009.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 1/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まず速度面では、カメラに近い部分は細部まで正確に衝突判定をする必要がありますが、遠い部分は大雑把でも問題にならないため、LODが有効でした。&lt;/p&gt;

&lt;p&gt;品質面でもLODが必要でした。
Mandelboxの距離関数は厳密には Distance Estimator（距離推定器）と呼ばれるものです。
通常の距離関数は表面までの距離をぴったりと計算できるのに対して、
Distance Estimatorは有限のイテレーション回数では表面に漸近しても、距離0になりません。&lt;/p&gt;

&lt;p&gt;そのため、適当な距離 eps で衝突とみなして計算を打ち切る必要があります。
また、eps を小さくすると、より細かい detail まで可視化できるのですが、
遠景まで同じ eps で処理すると高周波成分が現れて、まるでMipMap OFFのような汚い結果となります。&lt;/p&gt;

&lt;p&gt;このようにレイマーチングの高速化と品質向上の2つの目的ために、衝突判定の精度のLODが必要でした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.010.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 2/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LODはカメラからの距離に応じて動的に eps を決定することで実現しました。&lt;/p&gt;

&lt;p&gt;レイマーチングではレイを漸近的に進めるため、レイが進んだ距離を必ず計算する必要があります。
このとき &lt;code&gt;レイが進んだ距離 = カメラからの距離&lt;/code&gt; となるため、eps は簡単に決定できます。&lt;/p&gt;

&lt;p&gt;具体的にはレイが進んだ距離に定数を乗算したものを eps として扱うようにしました。&lt;/p&gt;

&lt;p&gt;今回の提出シーンのように同じレイマーチングのオブジェクトの近影〜遠景がひとつのカットで混在していても、綺麗に描画できるようになりました。&lt;/p&gt;

&lt;p&gt;また、カメラを近づけると実質無限に細部が現れるようになりました（フラクタル図形の特徴）。&lt;/p&gt;

&lt;h3 id=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34;&gt;1回のlaunchでなるべくたくさんサンプリングする戦略&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.011.jpeg&#34; alt=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OptiXでパストレーシングを実装する場合、通常は1回のlaunchでパストレーシングの1サンプリングを行うように実装するかと思います。&lt;/p&gt;

&lt;p&gt;ところが、launchにも多少のオーバーヘッドがあるため、手元のPCで実験した結果では、
&lt;code&gt;sample_per_launch&lt;/code&gt; （1回のlaunchごとのサンプリング回数）を大きくすれば大きくするほど60秒あたりのサンプリング回数を増やすことができました。&lt;/p&gt;

&lt;p&gt;そこで、最初の4サンプリングでマシンの性能をベンチマークして時間切れにならない最大の sample_per_launch を決定するような戦略をとりました。&lt;/p&gt;

&lt;h2 id=&#34;deep-learning-denoising&#34;&gt;Deep Learning Denoising&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.012.jpeg&#34; alt=&#34;Deep Learning Denoising&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディープラーニングをつかったデノイザーの性能が驚異的に良くて驚きました。&lt;/p&gt;

&lt;p&gt;左が10spp（sample per pixel）の結果で、右がデノイズした結果です。&lt;/p&gt;

&lt;p&gt;かなり少ないサンプリング数でも非常に綺麗にデノイズができました。
特にLucy像の拡散面の部分などは効果が絶大でした。&lt;/p&gt;

&lt;p&gt;Deep Learning DenoisingはOptiXの標準機能を利用しただけなので、詳細については私は理解していません。&lt;/p&gt;

&lt;p&gt;レンダリング結果とnormalとalbedoのバッファを与えてやると、綺麗にデノイズした結果を出力してくれました。&lt;/p&gt;

&lt;p&gt;速度面でも優秀で4K解像度でも&lt;a href=&#34;https://github.com/gam0022/redflash/pull/34&#34;&gt;1.4秒程度&lt;/a&gt;でデノイズが完了しました。&lt;/p&gt;

&lt;p&gt;まだリアルタイムレンダリングには速度的には使いづらいかもしれませんが、これまでの Bilateral Filter や Non-local Means Filter を遥かに凌駕する性能なので、改めてレンダリング技術とディープラーニングの親和性の高さを実感しました。&lt;/p&gt;

&lt;p&gt;これからの時代はグラフィックエンジニアもディープラーニングも勉強しなくては！と思いました。&lt;/p&gt;

&lt;h3 id=&#34;rt-buffer-gpu-local-による最適化&#34;&gt;RT_BUFFER_GPU_LOCAL による最適化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.013.jpeg&#34; alt=&#34;RT_BUFFER_GPU_LOCAL による最適化&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Deep Learning Denoising用にalbedoとnormalのバッファを生成したところ、合計で5枚もバッファが必要になりました。
バッファの読み書きもそれなりに重たい処理なので、対策を行いました。
createBuffer の第1引数に &lt;code&gt;RT_BUFFER_INPUT_OUTPUT&lt;/code&gt; を指定したところ、なんと13.6%くらい高速化しました。&lt;/p&gt;

&lt;p&gt;ディスプレイにバッファを同期するかのオプションのようでした。
ウィンドウにバッファを表示する場合はこのオプションをつけると描画結果が同期されなくなってしまいますが、
CUIモードで起動するときには同期は不要なので、このオプションを有効にすることで大幅に性能向上できました。&lt;/p&gt;

&lt;h1 id=&#34;反省-スケジュール面が厳しすぎた&#34;&gt;反省：スケジュール面が厳しすぎた&lt;/h1&gt;

&lt;p&gt;ここまでがレンダラーの紹介でした。ここからは振り返りを書こうと思います。&lt;/p&gt;

&lt;p&gt;最大の反省点はスケジュール面が厳しすぎたことでした…&lt;/p&gt;

&lt;p&gt;OptiXのキャッチアップを含めて約一ヶ月で開発したのですが、流石に無理なスケジュールだったと思います。&lt;/p&gt;

&lt;p&gt;8月は仕事のプロジェクトの追い込み時期とCEDECの登壇準備が重なって、なかなかレンダラー開発の時間を捻出できず、
睡眠時間と生活を削りすぎたため、体力的にも精神的にもかなり限界でした…&lt;/p&gt;

&lt;p&gt;そろそろ若さで無茶をカバーできない年齢になってきたので、締め切り直前になって慌てて開発するのではなく、
日頃から継続的にレンダラーを開発することが大事だろうと思います。&lt;/p&gt;

&lt;h1 id=&#34;余談-シーン作成はunity&#34;&gt;余談：シーン作成はUnity&lt;/h1&gt;

&lt;p&gt;時間がなくてシーン編集機能を実装できなかったので、
Unityで事前に距離関数のパラメータ調整や光源の配置を行ってシーンのイメージを固めてから、後からパラメータを自作レンダラーに移植しました。&lt;/p&gt;

&lt;p&gt;結果的には納得できるシーンを作成できたので、作戦は成功だったと思います。&lt;/p&gt;

&lt;p&gt;UnityのHDRPでレイマーチングを行うのには&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;@kanetaaaaa&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/kaneta1992/RaymarchingInHDRP/&#34;&gt;RaymarchingInHDRP&lt;/a&gt;を利用させていただきました。&lt;/p&gt;

&lt;p&gt;カッコいいシーンを大量に作れたので、ついスクリーンショットをたくさん撮影してしまいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unity HDRP + Raymarching by &lt;a href=&#34;https://twitter.com/kanetaaaaa?ref_src=twsrc%5Etfw&#34;&gt;@kanetaaaaa&lt;/a&gt; を試してみました！&lt;br&gt;カッコいいシーンが無限に作れてしまう😍&lt;br&gt;これは凄いです🙏&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#raymarching&lt;/a&gt;&lt;a href=&#34;https://t.co/EK6JsHpTBZ&#34;&gt;https://t.co/EK6JsHpTBZ&lt;/a&gt; &lt;a href=&#34;https://t.co/ZueP2hfzet&#34;&gt;pic.twitter.com/ZueP2hfzet&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1163876089489285120?ref_src=twsrc%5Etfw&#34;&gt;August 20, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;今後やりたいこと&#34;&gt;今後やりたいこと&lt;/h1&gt;

&lt;h2 id=&#34;シーン編集機能がほしい&#34;&gt;シーン編集機能がほしい&lt;/h2&gt;

&lt;p&gt;現状はGUIでカメラ操作だけができます。&lt;/p&gt;

&lt;p&gt;シーン編集に関して、上で紹介したようなUnityからパラメータを移植する方法だと最終的なルックの確認のイテレーションの高速化がしずらいので、
Redflash自体にシーン編集機能を実装したいと思っています。&lt;/p&gt;

&lt;p&gt;距離関数を定義したCUDAファイルのホットリロード機能を実装したり、 CallableProgramをつかって距離関数を差し替え可能にしたいです。&lt;/p&gt;

&lt;p&gt;他にも距離関数やマテリアルのパラメータをインスペクタで編集するなどは最低限欲しいなと思っています。&lt;/p&gt;

&lt;p&gt;あとはオブジェクトの配置などをマニピュレーターでできるようにしたいですが、どうしても実装工数がかかるので、どういう感じが良いのか思案しているところです。
DCCツールから直接シーンを出力する形式だと、距離関数の扱いに困るため、なかなか難しい問題です。&lt;/p&gt;

&lt;h2 id=&#34;リファクタリング&#34;&gt;リファクタリング&lt;/h2&gt;

&lt;p&gt;CallableProgramでBSDFを入れ替えられるようにしたり、ファイルを適切に分割したりして、もう少しコードをリファクタリングしたいです。&lt;/p&gt;

&lt;h2 id=&#34;pngのエンコード時間の短縮&#34;&gt;PNGのエンコード時間の短縮&lt;/h2&gt;

&lt;p&gt;PNGの保存には &lt;a href=&#34;https://github.com/nothings/stb/blob/master/stb_image.h&#34;&gt;stb_image&lt;/a&gt; を使わせていただきました。&lt;/p&gt;

&lt;p&gt;ただし、4K解像度となるとPNGの保存に1.7秒前後の時間が必要でした。&lt;/p&gt;

&lt;p&gt;制限時間が短くなると、PNGの保存やGPUの初期化に要する時間が相対的に増えて、レンダリングに使える時間がどんどん短くなってしまいます。&lt;/p&gt;

&lt;p&gt;そのため、PNGの保存やGPU初期化の高速化は、来年以降のレイトレ合宿では重要な課題になるだろうと予想しています。&lt;/p&gt;

&lt;h2 id=&#34;複数gpu対応&#34;&gt;複数GPU対応&lt;/h2&gt;

&lt;p&gt;OptiXをつかっても複数のGPUをうまく使ってくれなかったので、独自の仕組みで対応が必要のようでした。&lt;/p&gt;

&lt;p&gt;単純な解決策として、プロセスを複数起動して最後にレンダリング結果をマージする方法が考えられますが、ちゃんと検証をしたいです。&lt;/p&gt;

&lt;h2 id=&#34;フルスクラッチgpuレンダラー&#34;&gt;フルスクラッチGPUレンダラー&lt;/h2&gt;

&lt;p&gt;去年まではGPUインスタンス勢は1人だけだったのですが、今年は7人（レンダラーが動かなかった人も含む）もいました。&lt;/p&gt;

&lt;p&gt;GPU勢にも、私のようにOptiXなどのレイトレーシング用のフレームワークを使う勢と、フルスクラッチ実装勢で別れていました。&lt;/p&gt;

&lt;p&gt;フルスクラッチ勢からは「OptiXでは作法がきっちり決められているのがなんとなく嫌だった」「GPU向けのBVH実装をしてみたかった」といった意見を聞きました。&lt;/p&gt;

&lt;p&gt;たしかにRTXなどの登場によって交差判定がハードウェアに移りつつある今だからこそ、勉強する価値はあるのかもしれません。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;今年は忙しいからレイトレ合宿に参加できるか怪しいと思っていましたが、なんとかちゃんとレンダラーを提出できて良かったです。&lt;/p&gt;

&lt;p&gt;思えば「レイマーチングとポリゴンが混在したシーンをパストレーシングしたい」というのは3年前のレイトレ合宿4のときに本当は実現したいテーマでした。&lt;/p&gt;

&lt;p&gt;当時はレイトレ初心者だったので、ナイーブなパストレーシングで精一杯で高速化方法が分からず、
普通にレイマーチングを組み合わせたら激重になってしまい、5時間くらいかけないとまともな絵が出ない状態でした。
結局、パストレーシングを諦めて疑似手法でAOやシャドウを計算してなんとか見れる絵を提出しました…&lt;/p&gt;

&lt;p&gt;3年間で学んだ知識でようやくやりたいことを実現できて本当に良かったです。過去の自分に勝利できました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿は自身の成長や糧となる機会を与えてくれる、とても良い合宿勉強会だなと改めて感じました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿を毎年主催してくださっている&lt;a href=&#34;https://twitter.com/q_cinnamon&#34;&gt;q&lt;/a&gt;さんと&lt;a href=&#34;https://twitter.com/h013&#34;&gt;hole&lt;/a&gt;さん、その他の参加者のみなさん、本当にありがとうございました！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した</title>
      <link>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</link>
      <pubDate>Mon, 05 Aug 2019 12:10:23 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;アドベントカレンダーの記事です。&lt;/p&gt;

&lt;p&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;レイとオブジェクトの交差判定をレイマーチングで行い、ライティングをパストレーシングをするという、レイマーチングとパストレーシングのハイブリッドなレンダリングを実現しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;NVIDIA® OptiX上で&lt;br&gt;『レイマーチング×パストレーシング』&lt;br&gt;を実装できた😉 &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/FKbuHiXqmP&#34;&gt;pic.twitter.com/FKbuHiXqmP&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155489034354843649?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;実装の方針&#34;&gt;実装の方針&lt;/h1&gt;

&lt;p&gt;Optixは、CUDA基盤上で動作する、NVIDIA製のGPUレイトレーシング用フレームワークです。&lt;/p&gt;

&lt;p&gt;Optixではユーザ独自のプリミティブを定義できるため、この機能をつかってレイマーチングで衝突判定を行う距離関数のプリミティブを定義しました。&lt;/p&gt;

&lt;p&gt;独自のプリミティブの定義に必要なProgram（Optix用語でPTXアセンブリにコンパイルされたCUDA C関数を指す）は次の2つです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bounding Box&lt;/li&gt;
&lt;li&gt;Intersection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Optixの公式サンプルプロジェクトに optixPathtracing（パストレーシングの実装例）があったので、これにレイマーチングのプリミティブを追加する形で実装しました。&lt;/p&gt;

&lt;p&gt;パストレーシングの処理はサンプルコードの実装そのまま利用させていただきました。&lt;/p&gt;

&lt;h2 id=&#34;bounding-box&#34;&gt;Bounding Box&lt;/h2&gt;

&lt;p&gt;Bounding Boxを定義するProgramです。&lt;/p&gt;

&lt;p&gt;レイマーチングのオブジェクトのBounding BoxはC++側から値を渡すようにしました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rtDeclareVariable&lt;/code&gt; でCPUからGPUへ送るバッファの宣言（GLSLのunifromと同じ）ができます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;optix_world.h&amp;gt;

rtDeclareVariable(float3, center, , );
rtDeclareVariable(float3, size, , );

RT_PROGRAM void bounds(int, float result[6])
{
    optix::Aabb* aabb = (optix::Aabb*)result;
    aabb-&amp;gt;m_min = center - size;
    aabb-&amp;gt;m_max = center + size;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;intersection&#34;&gt;Intersection&lt;/h2&gt;

&lt;p&gt;衝突判定をするProgramです。&lt;/p&gt;

&lt;p&gt;ごくごく普通のレイマーチングです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;rtDeclareVariable(int, lgt_instance, , ) = {0};
rtDeclareVariable(float3, texcoord, attribute texcoord, );
rtDeclareVariable(int, lgt_idx, attribute lgt_idx, );

RT_PROGRAM void intersect(int primIdx)
{
    const float EPS = 1e-2;
    float t = 0.0, d = 1e100;
    float3 p = ray.origin;

    for (int i = 0; i &amp;lt; 50; i++)
    {
        d = map(p);
        t += d;
        p = ray.origin + t * ray.direction;
        if (abs(d) &amp;lt; EPS)
        {
            break;
        }
    }

    if (abs(d) &amp;lt; EPS &amp;amp;&amp;amp; rtPotentialIntersection(t))
    {
        shading_normal = geometric_normal = calcNormal(p, map);
        texcoord = make_float3(p.x, p.y, 0);
        lgt_idx = lgt_instance;
        rtReportIntersection(0);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;法線計算&#34;&gt;法線計算&lt;/h3&gt;

&lt;p&gt;法線計算は四面体によるアプローチを用いました。&lt;/p&gt;

&lt;p&gt;通常は6回の距離関数の評価が必要なところ、4回の評価だけで法線を計算できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://iquilezles.org/www/articles/normalsSDF/normalsSDF.htm&#34;&gt;normals for an SDF | http://iquilezles.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://setchi.hatenablog.com/entry/2018/12/17/095532&#34;&gt;#TokyoDemoFest 2018 の GLSL Graphics Compo で2位入賞しました - setchi’s blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map関数を差し替え可能にするためにマクロをつかって実装しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;const float EPS_N = 1e-4;
#define calcNormal(p, dFunc) normalize(\
    make_float3( EPS_N, -EPS_N, -EPS_N) * dFunc(p + make_float3( EPS_N, -EPS_N, -EPS_N)) + \
    make_float3(-EPS_N, -EPS_N,  EPS_N) * dFunc(p + make_float3(-EPS_N, -EPS_N,  EPS_N)) + \
    make_float3(-EPS_N,  EPS_N, -EPS_N) * dFunc(p + make_float3(-EPS_N,  EPS_N, -EPS_N)) + \
    make_float3( EPS_N,  EPS_N,  EPS_N) * dFunc(p + make_float3( EPS_N,  EPS_N,  EPS_N)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;距離関数&#34;&gt;距離関数&lt;/h3&gt;

&lt;p&gt;以前にブログで紹介したIFSによるMengerSpongeの距離関数をCUDA Cに移植しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/25/unity-raymarching/&#34;&gt;Unity×レイマーチングによる映像制作の実践手法 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Swizzle Operationを手動展開するのがしんどかったです…&lt;/p&gt;

&lt;p&gt;ベクトル版のabsやmaxは自分で定義すれば解決しますが、Swizzle OperationをCUDA C上で再現する方法は私には分かりませんでした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CUDA C言語、absやmaxにベクトル型のオーバーロードが無いし、Swizzle Operationも無いからストレスで発狂して精神が崩壊した🤬🤪🤮 &lt;a href=&#34;https://t.co/mRPmQTTcsb&#34;&gt;pic.twitter.com/mRPmQTTcsb&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155465784807657472?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = make_float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        // z = abs(z);
        z.x = abs(z.x);
        z.y = abs(z.y);
        z.z = abs(z.z);
        z.w = abs(z.w);

        // if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.y)
        {
            float x = z.x;
            z.x = z.y;
            z.y = x;
        }

        // if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.x &amp;lt; z.z)
        {
            float x = z.x;
            z.x = z.z;
            z.z = x;
        }

        // if (z.y &amp;lt; z.z) z.yz = z.zy;
        if (z.y &amp;lt; z.z)
        {
            float y = z.y;
            z.y = z.z;
            z.z = y;
        }

        z *= scale;
        // z.xyz -= offset * (scale - 1.0);
        z.x -= offset.x * (scale - 1.0);
        z.y -= offset.y * (scale - 1.0);
        z.z -= offset.z * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    // return (length(max(abs(z.xyz) - make_float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
    return (length(make_float3(max(abs(z.x) - 1.0, 0.0), max(abs(z.y) - 1.0, 0.0), max(abs(z.z) - 1.0, 0.0))) - 0.05) / z.w;
}

float map(float3 p)
{
    float scale = 100;
    return dMenger((p - center) / scale, make_float3(1, 1, 1), 3.1) * scale;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;c-からprogramの利用&#34;&gt;C++からProgramの利用&lt;/h2&gt;

&lt;p&gt;Programを利用するには以下のようなC++のコードを書けばOKです。&lt;/p&gt;

&lt;p&gt;ProgramとGPUに送る情報のバッファを指定しているだけです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Context        context = 0;
Program        pgram_raymarching_intersection = 0;
Program        pgram_raymarching_bounding_box = 0;

// レイマーチングのオブジェクトの GeometryInstance を生成します
GeometryInstance createRaymrachingObject(
    const float3&amp;amp; center,
    const float3&amp;amp; size)
{
    Geometry raymarching = context-&amp;gt;createGeometry();
    raymarching-&amp;gt;setPrimitiveCount(1u);
    raymarching-&amp;gt;setIntersectionProgram(pgram_raymarching_intersection);
    raymarching-&amp;gt;setBoundingBoxProgram(pgram_raymarching_bounding_box);

    raymarching[&amp;quot;center&amp;quot;]-&amp;gt;setFloat(center);
    raymarching[&amp;quot;size&amp;quot;]-&amp;gt;setFloat(size);

    GeometryInstance gi = context-&amp;gt;createGeometryInstance();
    gi-&amp;gt;setGeometry(raymarching);
    return gi;
}

// ジオメトリのセットアップをします
// ※レイマーチングに直接関係ないコードは省略しています
void loadGeometry()
{
    // Set up Raymarching programs
    const char *ptx = sutil::getPtxString( SAMPLE_NAME, &amp;quot;optixRaymarching.cu&amp;quot; );
    pgram_raymarching_bounding_box = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;bounds&amp;quot; );
    pgram_raymarching_intersection = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;intersect&amp;quot; );

    // create geometry instances
    std::vector&amp;lt;GeometryInstance&amp;gt; gis;

    // Raymarcing
    gis.push_back(createRaymrachingObject(
        make_float3(278.0f, 120.0f, 278.0f),
        make_float3(100.0f, 100.0f, 100.0f)));
    setMaterial(gis.back(), diffuse, &amp;quot;diffuse_color&amp;quot;, white);

    // Create geometry group
    GeometryGroup geometry_group = context-&amp;gt;createGeometryGroup(gis.begin(), gis.end());
    geometry_group-&amp;gt;setAcceleration( context-&amp;gt;createAcceleration( &amp;quot;Trbvh&amp;quot; ) );
    context[&amp;quot;top_object&amp;quot;]-&amp;gt;set( geometry_group );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;optixの環境構築-windows&#34;&gt;Optixの環境構築（Windows）&lt;/h1&gt;

&lt;p&gt;OptixのWindows用の環境構築の流れは&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;必要なツールを事前にインストール&lt;/li&gt;
&lt;li&gt;CamkeでVisualStudioのソリューションファイルを生成&lt;/li&gt;
&lt;li&gt;VisualStudioでビルド&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;という感じでした。&lt;/p&gt;

&lt;p&gt;morishigeさんのQiitaの記事が大変参考になりました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/morishige/items/d4a99c88b925ac31ff3d&#34;&gt;Nvidia OptiX 入門（環境構築編）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CmakeとOptixとCUDAのバージョンの組み合わせが肝のようで、Cmakeのバージョンを変えながら何回かトライしたところ、この組み合わせでCmakeビルドに成功しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;✍️ &lt;br&gt;CUDA 10.1&lt;br&gt;OptiX SDK 6.0.0&lt;br&gt;Visual Studio 2017&lt;br&gt;Cmake 3.8.2&lt;br&gt;&lt;br&gt;freeglut / GLFW / GLEW は Nuget の最新版をインストール&lt;a href=&#34;https://t.co/OtsR6bnxmk&#34;&gt;https://t.co/OtsR6bnxmk&lt;/a&gt;&lt;br&gt;&lt;br&gt;Cmakeの設定はスクショ通り &lt;a href=&#34;https://t.co/cpBM4y2Vy1&#34;&gt;pic.twitter.com/cpBM4y2Vy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1150906026528391168?ref_src=twsrc%5Etfw&#34;&gt;July 15, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;CmakeでVisual Studioのバージョンを選択する際、誤って64bit版ではなく32bit版を選択してしまい、Cmake自体は成功するもののソリューションがビルドできないことがありました。&lt;/p&gt;

&lt;p&gt;Cmakeの過去のバージョンはGitHubからインストールできます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kitware/CMake/releases&#34;&gt;Releases · Kitware/CMake&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプルコードの改造&#34;&gt;サンプルコードの改造&lt;/h2&gt;

&lt;p&gt;サンプルコードの改造方法はNVIDIA Developer Forumsにあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devtalk.nvidia.com/default/topic/1049151/optix/how-can-i-modify-a-simple-example-/&#34;&gt;How can I modify a simple example? - NVIDIA Developer Forums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Adding a new example is very simple:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Copy one of the optixIntro_01 (this is effectively optixHello) to optixIntro_10 folders,&lt;/li&gt;
&lt;li&gt;rename it,&lt;/li&gt;
&lt;li&gt;rename the project name in its copied CMakeLists.txt,&lt;/li&gt;
&lt;li&gt;add your new subdirectory in the CMakeLists.txt one folder above,&lt;/li&gt;
&lt;li&gt;rebuild the solution with CMake GUI. Done.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your new project appears and would do the same thing as the example you copied it from.
Now change it as you like.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;p&gt;以下の記事が大変参考になりました。ありがとうございます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memo.render.jp/optix&#34;&gt;optix - uimac実装メモ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/gameworks/content/gameworkslibrary/optix/optix_quickstart.htm&#34;&gt;OptiX QuickStart（公式チュートリアル）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Unity×レイマーチングによる映像制作の実践手法</title>
      <link>https://gam0022.net/blog/2019/06/25/unity-raymarching/</link>
      <pubDate>Tue, 25 Jun 2019 09:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/06/25/unity-raymarching/</guid>
      <description>&lt;p&gt;6/19に開催された&lt;a href=&#34;https://techplay.jp/event/733454&#34;&gt;UnityエンジニアによるShader勉強会！&lt;/a&gt;で「Unity×レイマーチングによる映像制作の実践手法」という発表をしました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;daf8218b7458460087137b6f23e938b3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;この記事は、発表内容をブログ向けに編集・要約したものになります。スライドだけでは伝わりにくい箇所を文章でフォローしました。&lt;/p&gt;

&lt;p&gt;発表当日の様子は前回の記事にまとめました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/&#34;&gt;UnityエンジニアによるShader勉強会！に登壇しました | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表の題材-wormhole&#34;&gt;発表の題材『WORMHOLE』&lt;/h1&gt;

&lt;p&gt;TokyoDemoFest2018で発表した『WORMHOLE』という映像作品を題材とした発表です。&lt;/p&gt;

&lt;p&gt;WORMHOLEの映像はUnityと&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング&lt;/a&gt;を組み合わせて制作しました。&lt;/p&gt;

&lt;p&gt;以下の記事で利用したテクニックは既に解説していましたが、今回は &lt;strong&gt;汎用的に役立ちそうなテクニック&lt;/strong&gt; に焦点を絞って、前回は説明しきれなかった部分を掘り下げて解説しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;Tokyo Demo Fest 2018のDemo Compo優勝作品の解説（グラフィック編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回の発表では &lt;strong&gt;「形状」「質感」「演出」&lt;/strong&gt; の3つをテーマとして、WORMHOLEに用いたテクニックの解説を行いました。&lt;/p&gt;

&lt;h1 id=&#34;形状-モデリング&#34;&gt;形状（モデリング）&lt;/h1&gt;

&lt;p&gt;1つ目のテーマは &lt;strong&gt;「形状」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、形状を決める作業をモデリングと呼びます。
複雑なトンネルの形状を40行ほどの距離関数でモデリングする方法を解説しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.011.jpeg&#34; alt=&#34;トンネルの距離関数の設計アプローチ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;トンネルは既存のフラクタル図形をアレンジして設計しました。
IFSと呼ばれる手法でMengerSpongeと呼ばれる有名なフラクタル図形を定義（図の左）して、IFSのパラメータを変化によって形状をアレンジ（図の中央）し、さらにfoldRotateという操作を加えるとトンネルの形状（図の右）が完成します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.012.jpeg&#34; alt=&#34;IFS（Iterated function system）とは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IFS&lt;/strong&gt; は自身の縮小コピーを重ね合わせることでフラクタル図形を作るテクニックです。
IFSはIterated Function Systemの略で、その名前の通りforループの中で、fold、拡大や縮小、平行移動といった操作を繰り返して距離関数をつくります。
forループで空間を操作してから、最後にBoxの距離関数を return します。&lt;/p&gt;

&lt;p&gt;ループの中でスケールと位置を変化させながら空間を折りたたみをして、Boxが出現する座標空間を再帰的に繰り返すことで、Boxを再帰的に配置するイメージです。&lt;/p&gt;

&lt;p&gt;foldの部分はかなり難解なので、1行ずつコメントアウトしながら変化を確認すると理解が深まると思います。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.013.jpeg&#34; alt=&#34;IFS（Iterated function system）のアレンジ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この関数では平行移動はOffset、拡大縮小はScaleという名前のパラメータにしました。&lt;/p&gt;

&lt;p&gt;このOffsetとScaleを変化させることで、フラクタル図形をアレンジできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.014.jpeg&#34; alt=&#34;foldRotateとは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;foldRotate&lt;/strong&gt; （別名: &lt;strong&gt;polarMod&lt;/strong&gt; ）はある軸を中心として一定の角度で回転しながら空間を折りたたみする操作です。
この回転の角度を変化させると、任意の図形を多角形の柱のような形に変形できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;三角柱を作りたいときは、360° を N = 3 で割った θ = 120° ずつ回転します。&lt;/li&gt;
&lt;li&gt;元の形が立方体なので、N = 4 のときは変化がありませんが、元の図形の4分の1が繰り返されています。&lt;/li&gt;
&lt;li&gt;N = 6 にすれば6角柱ができます。&lt;/li&gt;
&lt;li&gt;N = 8 にすれば8角柱になります。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WORMHOLEのトンネルには8角柱のfoldRotateを利用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.018.jpeg&#34; alt=&#34;最終的なコード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここまで使ったIFSによるMengerSpongeの距離関数とfoldRotateを組み合わせた最終的な距離関数のコードがこちらです。
なんと、わずか40行のコードで複雑な形状を定義できました！
非常に短いコードだけで複雑なモデリングができるのが距離関数の強みです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float3 _MengerOffset;
float _MengerScale;
float _MengerFold;

// IFSによるMengerSpongeの距離関数
float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        z = abs(z);

        if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.y &amp;lt; z.z) z.yz = z.zy;

        z *= scale;
        z.xyz -= offset * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    return (length(max(abs(z.xyz) - float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
}

// 2Dの回転行列の生成
float2x2 rotate(in float a) {
    float s = sin(a), c = cos(a);
    return float2x2(c, s, -s, c);
}

// 回転のfold
// https://www.shadertoy.com/view/Mlf3Wj
float2 foldRotate(in float2 p, in float s) {
    float a = PI / s - atan2(p.x, p.y);
    float n = PI2 / s;
    a = floor(a / n) * n;
    p = mul(rotate(a), p);
    return p;
}

// 最終的な距離関数
inline float DistanceFunction(float3 pos) {
    // 回転foldの適用
    pos.yx = foldRotate(pos.yx, _MengerFold);

    return dMenger(pos, _MengerOffset, _MengerScale);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;シェーダー全体: &lt;a href=&#34;https://github.com/gam0022/unity-demoscene/blob/master/Assets/Demoscene/Projects/2019-06-02-KLabTechMeetup4/Tunel.shader&#34;&gt;Tunel.shader&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;距離関数のfoldについてブログ記事を書いたので、もっと詳しく知りたい方はご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold（折りたたみ）による形状設計 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;質感-ライティング&#34;&gt;質感（ライティング）&lt;/h1&gt;

&lt;p&gt;2つ目のテーマは &lt;strong&gt;「質感」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、質感はライティング処理によって計算されます。
WORMHOLEではディファードレンダリングを採用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.021.jpeg&#34; alt=&#34;ディファードレンダリングを採用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングは2つのパスでシーンを描画するレンダリング手法です。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;G-Bufferパス&lt;/strong&gt; でNormalやDepthなどのライティングに必要な情報を詰め込んだGバッファを生成します。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lightingパス&lt;/strong&gt; でGバッファの情報を元にライティングを計算して、最終的なレンダリング結果を生成します。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これがディファードレンダリングの流れです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.022.jpeg&#34; alt=&#34;ディファードレンダリングを採用した3つの理由&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングを採用した理由は3つあります。&lt;/p&gt;

&lt;p&gt;1つ目の理由は &lt;strong&gt;距離関数とポリゴンが混在したシーンであっても一貫したライティングができる&lt;/strong&gt; 点です。レイマーチングの結果をGバッファに書き込む &lt;strong&gt;G-Bufferパス&lt;/strong&gt; のシェーダーを実装すれば、Gバッファ上では距離関数もポリゴンもどちらもスクリーンスペースの2Dのデータとなり、両者を区別する必要がないので、一貫したライティングができます。
&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんが開発している&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching&lt;/a&gt;というレイマーチング用のシェーダーのテンプレートを用いると、このようなシェーダーを少ない手間で書くことができます。
WORMHOLEでもuRaymarchingを利用しています。&lt;/p&gt;

&lt;p&gt;2つ目の理由は、Unityが標準で用意している &lt;strong&gt;Lightingパス&lt;/strong&gt; を利用することで、自分でライティング処理を実装しなくてもUnityの全種類の光源やReflectionProbeに対応できる点です。
もしフォワードレンダリングでレイマーチングをする場合にはライティング処理を自力で実装する必要があるので、ライティング処理を実装しなくて済むのはディファードレンダリングの強みと言えると思います。&lt;/p&gt;

&lt;p&gt;3つ目の理由は、ディファードレンダリングの特性上、光源が数が多いシーンであっても現実的な処理負荷でライティングを計算できる点です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.023.jpeg&#34; alt=&#34;ディファードレンダリングのライティングをカスタマイズ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一方でディファードレンダリングにはデメリットもあります。
シーン全体を同じ &lt;strong&gt;Lightingパス&lt;/strong&gt; で処理するということは、
裏を返すとマテリアルごとのライティングのカスタマイズが難しくなります。&lt;/p&gt;

&lt;p&gt;このような場合、StencilやGバッファにマテリアルIDの情報を埋め込んで、
Lightingパスの中でマテリアルを判定してライティングを切り替えることが正攻法となりますが、Lightingパスの修正となると、プロジェクト全体への影響も大きいですし、手間もかかってしまいます。&lt;/p&gt;

&lt;p&gt;WORMHOLEではEmissiveを活用してこの問題を解決しました。
Emissiveは自発光（自分が放つ光の強さ）のパラメーターですが、Emissive以外のパラメータを0にすると、Emissiveの色がそのまま最終的なピクセルの色として画面に出力されます。
この性質を利用して、独自のライティング結果をEmissiveに書き込むことで、自由にライティングをカスタマイズできます。&lt;/p&gt;

&lt;h1 id=&#34;演出-テキストのアニメーション&#34;&gt;演出（テキストのアニメーション）&lt;/h1&gt;

&lt;p&gt;3つ目のテーマは &lt;strong&gt;「演出」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;演出と言ってもたくさんの要素があると思いますが、今回の発表ではテキストのアニメーション演出をシェーダーで実装する話をします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.028.jpeg&#34; alt=&#34;TextMeshProとは？&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProはSDFをつかって高品質にフォントをレンダリングするためのAssetです。&lt;/p&gt;

&lt;p&gt;SDFはSigned Distance Fieldのことで、左のように文字の輪郭までの距離を画素値にした画像です。
SDFを使うとフォントを拡大してもジャギが目立たないため、フォントのレンダリングに適しています。&lt;/p&gt;

&lt;p&gt;また、勘の良い方はお気づきかと思いますが、SDFはレイマーチングの距離関数と全く同じ概念です。
距離関数の入力が3Dなのか2Dなのかというのと、コードで表現されるか、テクスチャで表現されるかという違いはありますが、本質的には同じものです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p29.gif&#34; alt=&#34;TextMeshProの描画の仕組み&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProの描画の仕組みについて説明します。&lt;/p&gt;

&lt;p&gt;まずCPUで1文字ずつMeshを生成します。
オレンジ色で示されたTextMeshProの文字をワイヤーフレーム表示を見ると、1文字ずつMeshが存在することが分かります。&lt;/p&gt;

&lt;p&gt;SDFテクスチャのUV情報はMeshの頂点データとして埋め込まれています。
次にこのMeshを描画するフラグメントシェーダーをつかってSDFテクスチャをフェッチしてフォントの内外判定をしてフォントをレンダリングします。&lt;/p&gt;

&lt;p&gt;このように TextMeshProではシェーダーをつかってフォントをレンダリングしています。&lt;/p&gt;

&lt;p&gt;つまり、 &lt;strong&gt;シェーダーを書けば、TextMeshProのレンダリングを 自由にカスタマイズできます！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.031.jpeg&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ方法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ方法を紹介します。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TextMeshProのシェーダーをコピーします。どのシェーダーをコピーしても良いのですが、Mobileと書いてあるものは実装がシンプルなのでオススメです。&lt;/li&gt;
&lt;li&gt;好きなようにシェーダーをカスタマイズします。色を決定する部分や、SDFテクスチャをフェッチする部分を改造するのが良いかと思います。&lt;/li&gt;
&lt;li&gt;TextMeshProのインスペクタから改造したシェーダーを設定すれば、完了です。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p32.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ例を2つ紹介します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;【左】色を決定する部分のシェーダーを書き換えて、sin関数で模様と動きをつけて、ブラウン管風のエフェクトと追加しました。&lt;/li&gt;
&lt;li&gt;【右】2種類のSDFテクスチャをブレンドすることで、平成と令和をモーフィングさせました。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p33.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはWORMHOLEのオープニング部分のエフェクトです。文字をパラパラと出現させたり消失させたりしています。&lt;/p&gt;

&lt;p&gt;これがシェーダーの差分のコードです。
SDFテクスチャをフェッチするUVをこのように時間でclampすることで、フォントを引き伸ばす効果を加えました。
わずか3行くらいの差分ですが、面白いエフェクトができたかなと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;        // PIXEL SHADER
        fixed4 PixShader(pixel_t input) : SV_Target
        {
-           half d = tex2D(_MainTex, input.texcoord0.xy).a * input.param.x;
+           half2 uv = input.texcoord0.xy;
+           uv.y = clamp(uv.y, 0.0, 0.5 + 0.5 * sin(_Time.y));
+           half d = tex2D(_MainTex, uv).a * input.param.x;
            half4 c = input.faceColor * saturate(d - input.param.w);

        #ifdef OUTLINE_ON
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TextMeshProとカスタムシェーダーを組み合わせる方法についてはQiitaに記事を投稿しているので、詳しく知りたい方は、こちらをご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/f3b7a3e9821a67a5b0f3&#34;&gt;[Unity] カスタムシェーダーでTextMeshProに独創的な演出を加える | Qiita&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;番外編-unity-timelineを活用した演出&#34;&gt;番外編: Unity Timelineを活用した演出&lt;/h2&gt;

&lt;p&gt;番外編のテキスト以外の演出の話として、Unity Timelineの活用についても紹介しました。&lt;/p&gt;

&lt;p&gt;シェーダーだけでなくUnity Timelineも利用することで、演出制作の効率を高めました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.037.jpeg&#34; alt=&#34;Unity Timelineの活用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オレンジ色の枠で囲まれているのがTimeline Windowです。&lt;/p&gt;

&lt;p&gt;演出の品質を高めるためには、演出の試行錯誤のイテレーションが必要です。
このイテレーションを高速に回すために、リアルタイムに編集結果をプレビューできる点や、自由に再生時間をシークできる点が本当に良かったです。&lt;/p&gt;

&lt;p&gt;Timelineの主な利用箇所です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Animation Track

&lt;ul&gt;
&lt;li&gt;レイマーチング用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;li&gt;ポストエフェクト用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TextMeshPro専用のCustom Track

&lt;ul&gt;
&lt;li&gt;TextMeshProのテキストを書き換えは標準のTrackでは実現できなかったので、Timelineのカスタムトラックを自作して実現しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chinemachine Track

&lt;ul&gt;
&lt;li&gt;カメラワークにはChinemachineというAssetのトラックを利用しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.041.jpeg&#34; alt=&#34;演出のまとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;シェーダーが不得意な（数式で表現しにくい）演出はTimelineも活用することで、効率的に演出を制作しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;規則的な（数式で表現ができる）動きはシェーダーが得意

&lt;ul&gt;
&lt;li&gt;音楽のBPMに合わせてチカチカ点滅させるのは、シェーダーが適しています。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;不規則な（数式で表現しにくい）動きはTimelineが得意

&lt;ul&gt;
&lt;li&gt;カメラワークはTimelineを利用したほうが効率的に演出が作れると思います。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p35.gif&#34; alt=&#34;まとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;リアルな質感も、複雑な形状も、カッコいい演出も、どれもシェーダーで実現できます。&lt;/p&gt;

&lt;p&gt;短いコードだけで多彩な表現ができるため、映像作成においては &lt;strong&gt;シェーダーは最強の道具&lt;/strong&gt; だと言えるでしょう。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UnityエンジニアによるShader勉強会！に登壇しました</title>
      <link>https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/</link>
      <pubDate>Thu, 20 Jun 2019 10:04:11 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/</guid>
      <description>&lt;p&gt;6/19に開催された&lt;a href=&#34;https://techplay.jp/event/733454&#34;&gt;UnityエンジニアによるShader勉強会！&lt;/a&gt;で「Unity×レイマーチングによる映像制作の実践手法」という発表をしました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;daf8218b7458460087137b6f23e938b3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（06/25追記）&lt;/strong&gt; 発表内容をブログ向けに編集・要約して別記事にまとめました。
スライドだけでは伝わりにくい箇所を文章でフォローしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/25/unity-raymarching/&#34;&gt;Unity×レイマーチングによる映像制作の実践手法 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表資料まとめ&#34;&gt;発表資料まとめ&lt;/h1&gt;

&lt;p&gt;発表者の資料のツイートをまとめました。&lt;/p&gt;

&lt;h2 id=&#34;kanetaaaaa-シェーダーライブコーディングのすすめ&#34;&gt;@kanetaaaaa 「シェーダーライブコーディングのすすめ」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;先日の資料を元にシェーダーライブコーディング入門の記事を書きました🤔&lt;br&gt;普段シェーダーを使ってる人の遊び道具になって欲しいです！&lt;br&gt;懇親会時に作ったシェーダーで使用したテクニックもいくつか追加で紹介しています！！&lt;a href=&#34;https://t.co/MgDFAatZre&#34;&gt;https://t.co/MgDFAatZre&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141485526815346688?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の資料のために眺めるだけでレイマーチングを完全に理解できるかもしれないシェーダーを作りました🤔&lt;a href=&#34;https://t.co/Hia4I0Dgii&#34;&gt;https://t.co/Hia4I0Dgii&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://t.co/kIuU4USxRJ&#34;&gt;pic.twitter.com/kIuU4USxRJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141307706139004934?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;gam0022-unity-レイマーチングによる映像制作の実践手法&#34;&gt;@gam0022「Unity×レイマーチングによる映像制作の実践手法」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です！&lt;br&gt;モデリングと演出とライティングを全部シェーダーで実装しました！&lt;a href=&#34;https://t.co/lwg0xVcm3J&#34;&gt;https://t.co/lwg0xVcm3J&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity3D?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3D&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/HLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#HLSL&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1141307844999778304?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログも更新しました🙏&lt;br&gt;全員の発表資料をまとめ！もあります。&lt;a href=&#34;https://t.co/TdiHF5jILF&#34;&gt;https://t.co/TdiHF5jILF&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity3D?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3D&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/HLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#HLSL&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1141541272877850624?ref_src=twsrc%5Etfw&#34;&gt;2019年6月20日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;archeleeds-unityで遊べる背景シェーダーを作る&#34;&gt;@archeleeds「Unityで遊べる背景シェーダーを作る」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;KLab Tech Meetup #4&lt;br&gt;「Unityで遊べる背景シェーダーを作る」のスライドです&lt;a href=&#34;https://t.co/YyVB6gEhVk&#34;&gt;https://t.co/YyVB6gEhVk&lt;/a&gt;&lt;br&gt;拙いですが何かの参考になれば 🙇‍♂️&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt;&lt;/p&gt;&amp;mdash; リゼ (@archeleeds) &lt;a href=&#34;https://twitter.com/archeleeds/status/1141376228558983168?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;setchi-fancyscrollview-x-shader&#34;&gt;@setchi「FancyScrollView x Shader」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;スクロールビューでもシェーダー芸がしたい！&lt;br&gt;KLab TECH Meetup ＃4 で発表したスライドおよびサンプルコードです。&lt;br&gt;&lt;br&gt;GitHub: &lt;a href=&#34;https://t.co/WFqznn2vVM&#34;&gt;https://t.co/WFqznn2vVM&lt;/a&gt;&lt;br&gt;Google Slides: &lt;a href=&#34;https://t.co/TR5KBVmDUJ&#34;&gt;https://t.co/TR5KBVmDUJ&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/madewithunity?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#madewithunity&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/gamedev?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#gamedev&lt;/a&gt; &lt;a href=&#34;https://t.co/zqECmup7Qi&#34;&gt;pic.twitter.com/zqECmup7Qi&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1141313091134562304?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログ更新しました &amp;gt; スクロールビューでもシェーダー芸がしたい！&lt;a href=&#34;https://t.co/5bNo2FlQqe&#34;&gt;https://t.co/5bNo2FlQqe&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/gamedev?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#gamedev&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1142779645751783425?ref_src=twsrc%5Etfw&#34;&gt;2019年6月23日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;20分シェーダーライブコーディング-by-kanetaaaaa&#34;&gt;20分シェーダーライブコーディング by @kanetaaaaa&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;昨日の勉強会の懇親会中に20分間のライブコーディングでシェーダーを作りました！&lt;br&gt;初めて人前でコーディングをしたんですが、めちゃくちゃ楽しかったです！！&lt;br&gt;&lt;br&gt;（当日動かなかったpmod修正済です&amp;hellip;）&lt;br&gt;差分&lt;br&gt;- q.x = abs(p.x ) - 10.;&lt;br&gt;+ q.x = abs(q.x ) - 10.;&lt;a href=&#34;https://t.co/LH3TT4YzSU&#34;&gt;https://t.co/LH3TT4YzSU&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://t.co/k61c3O2ZA1&#34;&gt;pic.twitter.com/k61c3O2ZA1&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141480732180619264?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;先日の &lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; の懇親会で行った20分のライブコーディング映像を公開しました！&lt;br&gt;実況解説は&lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt; さんと&lt;a href=&#34;https://twitter.com/songofsaya_?ref_src=twsrc%5Etfw&#34;&gt;@songofsaya_&lt;/a&gt;さんです&lt;br&gt;突発ながら面白い実況で場を盛り上げてくださって非常に楽しかったです！&lt;br&gt;動画でもこの空間の楽しさが伝わると思うので是非ご覧ください！&lt;a href=&#34;https://t.co/1CDeXMfJlT&#34;&gt;https://t.co/1CDeXMfJlT&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141987474824036353?ref_src=twsrc%5Etfw&#34;&gt;2019年6月21日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;これまでの人生で最高の勉強会でした！&lt;/p&gt;

&lt;p&gt;参加者も発表者もモチベーションがとても高く、終始ものすごい熱気に包まれていて、発表する側としても非常にやりやすかったです！&lt;/p&gt;

&lt;p&gt;勉強会のテーマがニッチすぎることから当初は参加枠を100名としていたのですが、告知開始から数時間後には満員となってしまったため、最終的に会場のキャパシティ上限の200名まで増枠することになりました。
これほど大人数の勉強会が実現されるとは思っておらず、世間のシェーダーへの関心の高さに驚きました。&lt;/p&gt;

&lt;p&gt;どの発表も尖った内容が満載だったのではないでしょうか。
シェーダーに対する理解がより深まり、興味が増したのであれば幸いです。&lt;/p&gt;

&lt;p&gt;ご参加いただいた皆さま、本当にありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/live-coding-original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/live-coding.jpg&#34; alt=&#34;懇親会中のライブコーディングの様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;懇親会中のライブコーディングの様子&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>先頭にコピペするだけ！Shadertoy → GLSL Sandbox / NEORT の移植用ヘッダーコードの紹介</title>
      <link>https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/</link>
      <pubDate>Mon, 04 Mar 2019 09:01:07 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/</guid>
      <description>&lt;p&gt;2021-11-16 backbufferとマウスの対応&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.shadertoy.com/&#34;&gt;Shadertoy&lt;/a&gt;のコードを&lt;a href=&#34;http://glslsandbox.com/&#34;&gt;GLSL Sandbox&lt;/a&gt;に一発で移植するコードを思いつきました。&lt;/p&gt;

&lt;p&gt;以下のコードをShadertoyのコードの先頭にコピペするだけで、元のコードには一切手を加えずにGLSL Sandbox用のコードに変換できます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// BEGIN: shadertoy porting template
// https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/
precision highp float;

uniform vec2 resolution;
uniform float time;
uniform vec2 mouse;
uniform sampler2D backbuffer;

#define iResolution resolution
#define iTime time
#define iMouse (vec4(mouse, 0.5, 0.5) * resolution.xyxy)
#define iChannel0 backbuffer
#define texture texture2D

void mainImage(out vec4 fragColor, in vec2 fragCoord);

void main(void) {
    vec4 col;
    mainImage(col, gl_FragCoord.xy);
    gl_FragColor = col;
}
// END: shadertoy porting template
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shadertoyのマルチパスやテクスチャ機能をつかったShaderの移植はできませんが、普通の1パスのShaderなら移植できると思います。&lt;/p&gt;

&lt;p&gt;ぜひ使ってみてください！&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;shadertoy-neort-の移植事例&#34;&gt;Shadertoy → NEORT の移植事例&lt;/h2&gt;

&lt;p&gt;最近、&lt;a href=&#34;https://neort.io/&#34;&gt;NEORT&lt;/a&gt;という国内産Shadertoyのようなサイトが登場しました。&lt;/p&gt;

&lt;p&gt;NEORTはGLSL Sandbox互換があるので、ご紹介した方法で一発でShadertoyから移植できました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;NEORTはじめました⛩️&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/creativecoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#creativecoding&lt;/a&gt; &lt;a href=&#34;https://t.co/acKyzwIU8S&#34;&gt;https://t.co/acKyzwIU8S&lt;/a&gt; &lt;a href=&#34;https://t.co/1AqphUQ5jv&#34;&gt;pic.twitter.com/1AqphUQ5jv&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1100564853985501184?ref_src=twsrc%5Etfw&#34;&gt;2019年2月27日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;解説&#34;&gt;解説&lt;/h2&gt;

&lt;p&gt;なぜこれでうまく移植できるのか、簡単に解説します。&lt;/p&gt;

&lt;h3 id=&#34;uniform名の違いの吸収&#34;&gt;uniform名の違いの吸収&lt;/h3&gt;

&lt;p&gt;まず以下のコードでShadertoyとGLSL Sandboxのuniform名の違いの吸収しています。&lt;/p&gt;

&lt;p&gt;単純に &lt;code&gt;#define&lt;/code&gt; のプリプロセッサで置換しているだけなので、特に不思議なことは無いと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;uniform vec2 resolution;
uniform float time;
uniform vec2 mouse;

#define iResolution resolution
#define iTime time
#define iMouse mouse
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;エントリーポイント名の違いの吸収&#34;&gt;エントリーポイント名の違いの吸収&lt;/h3&gt;

&lt;p&gt;Shadertoyのエントリポイントは &lt;code&gt;mainImage&lt;/code&gt; で、GLSL Sandboxは &lt;code&gt;main&lt;/code&gt; です。&lt;/p&gt;

&lt;p&gt;が、よく考えてみると、ShadertoyもWebGLで実装されているからにはGLSLのルールに従って &lt;code&gt;main&lt;/code&gt; が定義されているはずです。&lt;/p&gt;

&lt;p&gt;Shadertoyのソースコードを眺めてみると、&lt;code&gt;mainImage&lt;/code&gt; を呼び出す &lt;code&gt;main&lt;/code&gt; 関数をヘッダーとして挿入する実装になっています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void main(void) {
    vec4 col;
    mainImage(col, gl_FragCoord.xy);
    gl_FragColor = col;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この「mainImage を呼び出す main を定義する」というアイデアは&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta&lt;/a&gt;さんのこの作品からヒントをもらいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;早速2D版🤔のGLSLコード置いているので、ご自由にお使いください🤔&lt;a href=&#34;https://t.co/OJjTYlLy0c&#34;&gt;https://t.co/OJjTYlLy0c&lt;/a&gt; &lt;a href=&#34;https://t.co/NYN6zT77sM&#34;&gt;pic.twitter.com/NYN6zT77sM&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1099180997269106688?ref_src=twsrc%5Etfw&#34;&gt;2019年2月23日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;次はコンパイルエラーを避けるための前方宣言です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void mainImage(out vec4 fragColor, in vec2 fragCoord);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GLSLではC言語と同様に、別の関数から呼び出される前に関数を定義するか、前方宣言する必要があります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GLSL Compoに役立つ！GLSL Sandbox互換のVSCode拡張『Shader Toy』の紹介</title>
      <link>https://gam0022.net/blog/2018/12/24/vscode-glslsandbox/</link>
      <pubDate>Mon, 24 Dec 2018 23:59:59 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/12/24/vscode-glslsandbox/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://qiita.com/advent-calendar/2018/webgl&#34;&gt;WebGL Advent Calendar 2018&lt;/a&gt;の24日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;みなさんはGLSL Sandboxのシェーダーをローカルで編集したりgitで管理したいと思ったことはありませんか？&lt;/p&gt;

&lt;p&gt;VSCodeの拡張機能の『Shader Toy』をインストールすれば簡単に実現できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=stevensona.shader-toy&#34;&gt;Shader Toy - Visual Studio Marketplace
&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本拡張は&lt;a href=&#34;https://www.shadertoy.com/&#34;&gt;Shadertoy&lt;/a&gt;と&lt;a href=&#34;http://glslsandbox.com/&#34;&gt;GLSL Sandbox&lt;/a&gt;の互換性を備えており、
どちらのコードも修正なしにそのまま動作できます！&lt;/p&gt;

&lt;p&gt;WindowsとMacの両方に対応しています。&lt;/p&gt;

&lt;p&gt;次の画像は&lt;a href=&#34;https://nanka.hateblo.jp/entry/2018/12/13/080322&#34;&gt;Traveler2&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta&lt;/a&gt;（&lt;a href=&#34;http://tokyodemofest.jp/2018/&#34;&gt;Tokyo Demo Fest 2018&lt;/a&gt; GLSL Compo優勝作品）をVSCode上で動作させた様子です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/traveler2-win.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/traveler2-win.jpg&#34; alt=&#34;traveler2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;導入方法と使い方&#34;&gt;導入方法と使い方&lt;/h1&gt;

&lt;p&gt;導入方法と使い方は簡単です。&lt;/p&gt;

&lt;h2 id=&#34;導入方法&#34;&gt;導入方法&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/install.png&#34; alt=&#34;install&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;拡張機能のウィンドウを開く&lt;/li&gt;
&lt;li&gt;「shadertoy」で検索&lt;/li&gt;
&lt;li&gt;インストールボタンを押す&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;GLSLのコードを編集した状態でコマンドパレットから「Shader Toy: GLSL Preview」を開くだけです。&lt;/p&gt;

&lt;p&gt;GLSLのコードを認識しないときは、「Shader Toy: GLSL Preview」を閉じてから再実行すると認識できる場合があります。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;※以降の内容はポエム・個人的なメモです。あまり有益な情報はありませんのでご注意ください。&lt;/p&gt;

&lt;h1 id=&#34;glsl-sandbox互換の理由&#34;&gt;GLSL Sandbox互換の理由&lt;/h1&gt;

&lt;p&gt;ところで、『Shader Toy』という名前なのに、なぜGLSL Sandboxにも対応しているのでしょうか？&lt;/p&gt;

&lt;p&gt;元々は Shadertoy互換の拡張だったのですが、次のPull Requestで私がGLSL Sandbox互換を追加しました💪&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/stevensona/shader-toy/pull/37&#34;&gt;GLSLsandbox support by gam0022 · Pull Request #37 · stevensona/shader-toy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;拡張の名前から考えて、GLSL Sandbox互換の機能追加が受け入れられるか心配でしたが、爆速でマージしていただけました！
stevensonaさんありがとうございます🙏&lt;/p&gt;

&lt;h1 id=&#34;開発動機&#34;&gt;開発動機&lt;/h1&gt;

&lt;p&gt;Tokyo Demo Fest 2018のライブコーディングバトルの練習のために、
ローカル上で他人に見られないようにglslfanのコードを書きたいというのが開発の動機でした。&lt;/p&gt;

&lt;p&gt;ライブコーディングというのは、その場でコーディングを行うということです。
今回のライブコーディングバトルでは、4人の競技者が40分の制限時間内で、glslfan上でGLSLのシェーダーによる作品をつくりあげました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://glslfan.com/&#34;&gt;glslfan.com&lt;/a&gt;はdoxasさんが開発されているGLSL Sandbox互換のライブコーディングをリアルタイム配信するサイトです。
他人のシェーダコーディングをある程度リアルタイムに覗き見できることを特徴としています。
リアルタイムに配信する機能は素晴らしいのですが、ライブコーディングの練習をしている様子を一般公開したくなかったので、
ローカル上でGLSLのコードを編集できる環境を構築するために、「Shader Toy」拡張を改造しようと思いました。&lt;/p&gt;

&lt;h1 id=&#34;glsl-compo優勝者と準優勝者のお役に立てた&#34;&gt;GLSL Compo優勝者と準優勝者のお役に立てた&lt;/h1&gt;

&lt;p&gt;本家にPull Requestを送る前に&lt;a href=&#34;https://gist.github.com/gam0022/910bef95310f52995477dcb7bcc0467a&#34;&gt;改造版の拡張のインストール手順&lt;/a&gt;をTwitterで公開していました。&lt;/p&gt;

&lt;p&gt;その結果、GLSL Compoの1位と2位の方々に利用していただき、お役に立てたようで嬉しいです😆&lt;/p&gt;

&lt;p&gt;GLSL Compo1位のkanetaさんのツイート&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;法線求める時forでインライン展開押さえるのすご..&lt;br&gt;GLSL Grapherと&lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt;先生の拡張は僕もめっちゃ使いました!&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1074471599804301312?ref_src=twsrc%5Etfw&#34;&gt;2018年12月17日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;GLSL Compo2位のsetchiさんのツイート&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログ更新しました &amp;gt; &lt;a href=&#34;https://twitter.com/hashtag/TokyoFemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoFemoFest&lt;/a&gt; 2018 の GLSL Graphics Compo で2位入賞しました&lt;a href=&#34;https://t.co/XyntUxDCGD&#34;&gt;https://t.co/XyntUxDCGD&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1074469119481663489?ref_src=twsrc%5Etfw&#34;&gt;2018年12月17日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;VSCode 上で GLSL 環境を探していたときに、ちょうど gam0022 先生が GLSL Sandbox 互換の VSCode 拡張を公開していたのでありがたく使わせていただきました！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;ライブコーディングバトルで優勝できた&#34;&gt;ライブコーディングバトルで優勝できた&lt;/h1&gt;

&lt;p&gt;&lt;del&gt;本拡張をつかった練習の成果によって、&lt;/del&gt; ライブコーディングバトルで優勝しました😉&lt;/p&gt;

&lt;p&gt;こんな感じの作品をGLSLのシェーダーだけで40分でつくりました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;シェーダーライブコーディングバトルの優勝作品です！&lt;br&gt;ありがとうございました！&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/tdf2018?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tdf2018&lt;/a&gt;&lt;a href=&#34;https://t.co/MJwbIWFOMl&#34;&gt;https://t.co/MJwbIWFOMl&lt;/a&gt; &lt;a href=&#34;https://t.co/LVr2LYvUgi&#34;&gt;pic.twitter.com/LVr2LYvUgi&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1068782247711465472?ref_src=twsrc%5Etfw&#34;&gt;2018年12月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;（本当はを大会前日まで&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;PC Demo Compoの作品制作をしていたので&lt;/a&gt;、ライブコーディングの練習はほとんどできませんでした😇）&lt;/p&gt;

&lt;p&gt;競技中に私の画面が真っ白になってしまい、
実況者（&lt;a href=&#34;https://twitter.com/h_doxas&#34;&gt;@h_doxas&lt;/a&gt;さん、&lt;a href=&#34;https://twitter.com/amagitakayosi&#34;&gt;@amagitakayosi&lt;/a&gt;さん）に「仕込んでますよ」「隠してますよ」「いやらしいですね」
と解説されていたのですが、本当は原因不明のバグで苦しんでいて頭も真っ白でした😨
終盤にバグの原因を突き止めてなんとか逆転優勝できました。&lt;/p&gt;

&lt;p&gt;参加者4人の作品を並べた動画はこちらです。
左上が&lt;a href=&#34;https://twitter.com/FMS_Cat&#34;&gt;@FMS_Cat&lt;/a&gt;さん、右上が&lt;a href=&#34;https://twitter.com/gyabo&#34;&gt;@gyabo&lt;/a&gt;さん、左下が&lt;a href=&#34;https://twitter.com/notargs&#34;&gt;@notargs&lt;/a&gt;さん、そして右下が私&lt;a href=&#34;https://twitter.com/gam0022&#34;&gt;@gam0022&lt;/a&gt;の作品です。
どの作品もレベルが高くて、みんな凄すぎますね👏&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ライブコーティングバトルの最終成果物 &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/CpIWIhcqoH&#34;&gt;pic.twitter.com/CpIWIhcqoH&lt;/a&gt;&lt;/p&gt;&amp;mdash; kaiware style🌱 (@kaiware007) &lt;a href=&#34;https://twitter.com/kaiware007/status/1068777639333126144?ref_src=twsrc%5Etfw&#34;&gt;2018年12月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;IGN JAPAN様にライブコーディングバトルを含めたTDFの1日目の様子をご紹介いただきました。興味がある方は是非ご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jp.ign.com/event/31357/news/etokyo-demo-fest-2018&#34;&gt;eスポーツもゲーム開発もゲームエンジンも生み出したデモシーン！日本で唯一のデモシーンイベント「Tokyo Demo Fest 2018」レポ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;shadertoyとglsl-sandboxのマウスの違い&#34;&gt;ShadertoyとGLSL Sandboxのマウスの違い&lt;/h1&gt;

&lt;p&gt;開発する中でShadertoyとGLSL Sandboxのマウスの扱いの違いに苦しめられたので、後学のためにメモを残します。&lt;/p&gt;

&lt;p&gt;ShadertoyとGLSL Sandboxを相互に移植にする際などに参考にしてください。&lt;/p&gt;

&lt;p&gt;本拡張では以下のマウスの扱いの違いを考慮して実装しました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Shadertoy&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GLSL Sandbox&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;uniform定義&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;uniform vec4 iMouse;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;uniform vec2 mouse;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;解説（日本語）&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ピクセル座標系のマウス座標。&lt;br&gt;xy: 現在のマウス座標 (左クリック時に更新)&lt;br&gt;zw: マウスのクリック状態&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜1に正規化したマウス座標。&lt;br&gt;xy: 現在のマウス座標（毎フレーム更新）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Explanation（English）&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mouse pixel coords. &lt;br&gt;xy: current (if MLB down), &lt;br&gt;zw: click&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mouse normalized coords. &lt;br&gt;xy: current&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;xyの値域&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜解像度&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>Tokyo Demo Fest 2018のDemo Compo優勝作品の解説（グラフィック編）</title>
      <link>https://gam0022.net/blog/2018/12/12/tdf2018/</link>
      <pubDate>Wed, 12 Dec 2018 09:49:52 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/12/12/tdf2018/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;http://qiita.com/advent-calendar/2018/klab&#34;&gt;KLab Engineer Advent Calendar 2018&lt;/a&gt;の12日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;12月1日～12月2日に秋葉原で開催された&lt;a href=&#34;http://tokyodemofest.jp/2018/&#34;&gt;Tokyo Demo Fest 2018&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
コンピュータを用いて作成された楽曲や映像作品をデモと呼び、
デモに関心のある人々が一堂に会してコンペティションを行ったり、技術を共有したりといったイベントをデモパーティと呼びます。&lt;/p&gt;

&lt;p&gt;今年のTDFでは、さだきちさん（&lt;a href=&#34;https://twitter.com/sadakkey&#34;&gt;@sadakkey&lt;/a&gt;）とチームを組み、『WORMHOLE』（映像：gam0022 / サウンド：sadakkey）という作品を発表しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tdf2018_collage_original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tdf2018_collage.jpg&#34; alt=&#34;WORMHOLE by gam0022 &amp;amp; sadakkey&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Windows実行ファイル形式のデモ作品のコンペティションであるCombined Demo Compoにて、&lt;a href=&#34;http://tokyodemofest.jp/2018/results.txt&#34;&gt;本作品が1位&lt;/a&gt;に選ばれました！&lt;/p&gt;

&lt;p&gt;この記事では『WORMHOLE』の映像制作技術について解説します。
ソースコードを公開していますので、ご興味のある方はそちらもご確認いただければと思います（スターください！）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene&#34;&gt;https://github.com/gam0022/unity-demoscene&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;サウンド編についてはさだきちさんが解説されています。あわせてご覧ください！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://klabgames.creative.blog.jp.klab.com/archives/14415590.html&#34;&gt;Tokyo Demo Fest2018のDemo Compo優勝作品の解説〜サウンド編〜 : KLabGames Creative Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;作品の概要&#34;&gt;作品の概要&lt;/h1&gt;

&lt;p&gt;「ワームホールによる空間移動」をコンセプトとして、
不思議な球体がワームホールを介して非現実なデジタル空間と水平線の広がる自然空間を行き来する映像を制作しました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/NMNJV-Pbqtk&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;不思議な球体がトンネルを進んでいくと、周囲を明滅する光がだんだんとモノクロからカラフルに変わっていきます。
トンネルの最奥にあるワームホールへ近づくほど明滅はだんだんと激しくなっていき、ホワイトアウトとともにワームホールを越えると、球体は海上に出現します。
その後、球体はじわじわと歪んでいき、戦闘機へと形を変えます。&lt;/p&gt;

&lt;p&gt;変形中の不思議な球体の上には、私が尊敬するデモシーナーの名前を表示しました。
これはグリーティングと呼ばれるデモシーンにおける慣習です。&lt;/p&gt;

&lt;p&gt;戦闘機はパーティクルを放ちながら海上を進み、パーティクルが一瞬だけTDFのロゴを形作ります。
そして戦闘機は元の球体に変形し、突如現れたワームホールに吸い込まれるようにして冒頭のトンネルのシーンに戻っていきます。&lt;/p&gt;

&lt;p&gt;実装ならびに制作にはUnityを利用しました。
詳細は後述しますが、Timeline, TextMeshPro, Chinemachine, PostProcessingStack v2といったUnity 2018.2の新機能も活用しています。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レンダリング&#34;&gt;レンダリング&lt;/h1&gt;

&lt;p&gt;映像の大部分は&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング&lt;/a&gt;で描画し、パーティクルやグリーティングのテキストなどのレイマーチングが苦手とする部分はラスタライザで描画するというハイブリッドなレンダリング方式を採用しました。&lt;/p&gt;

&lt;p&gt;なお、今回は制作期間が短かったため、レイマーチングのシェーディングにはUnity標準のディファードレンダリングを利用することにしました。
ディファードレンダリングにすることで、Gバッファの書き込みまでを実装すれば、それ以降のライティングの処理をUnityの標準のディファードレンダリングのシェーダーに任せることができます。
簡単に言ってしまえば、Unityでサポートされる全種類のライトやGI機能に対応するライティング処理をあえて自分で実装しなくて済むという、工数削減のメリットがあります。&lt;/p&gt;

&lt;p&gt;Unityでディファードレンダリングによるレイマーチングを実現するにあたり、
&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching&lt;/a&gt;を利用させていただきました。
uRaymarchingは距離関数とGバッファに値を書き込む部分を実装すれば、簡単にレイマーチングができる便利なシェーダーテンプレートです。&lt;/p&gt;

&lt;p&gt;他にも、鏡面反射による周囲の映り込みに、Unity標準のReflectionProbeを配置して実現しています。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;uRaymarchingとReflectionProbeによる反射と組み合わせる検証&lt;br&gt;中&lt;br&gt;&lt;br&gt;毎フレームCubemapを生成するくらいならレイトレで反射を計算したほうが速いと思っていたが、この例ならCubemapの解像度は16x16でも十分だし、Cubemapの方がポリゴンとの混在が容易なので、現実的な方法だと思う。 &lt;a href=&#34;https://t.co/sSX7WmVCEd&#34;&gt;pic.twitter.com/sSX7WmVCEd&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1003274796895895554?ref_src=twsrc%5Etfw&#34;&gt;2018年6月3日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;full-screen-quadの実装方法&#34;&gt;Full Screen Quadの実装方法&lt;/h2&gt;

&lt;p&gt;uRaymarchingの話に関連して、Full Screen Quadの実装方法について紹介します。&lt;/p&gt;

&lt;p&gt;uRaymarchingではCommandBufferでフルスクリーンQuadを表示させていましたが、
スクリプトによる制御は最小限にしてEditorモードの挙動を安定させたかったので、別のアプローチをとってみました。&lt;/p&gt;

&lt;p&gt;EditorツールでBoudingBoxを巨大にしてFrustum Cullingを無効にしたQuadを静的生成しました。&lt;/p&gt;

&lt;p&gt;これによって時々レイマーチング部分が動かないトラブルを回避できました。
また、本作品のようにFull Screen Quadが必要なレイマーチングのワールドが複数存在して、
時間によって切り替わる表現のためには、MeshRendererのenableの切り替えで制御できる単純な仕組みの方が好都合でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unityで画面全体にレイマーチングをさせる最高のソリューションができた！&lt;br&gt;&lt;br&gt;CommandBufferを使う方法だとEditMode等の考慮が大変。&lt;br&gt;通常のQuadだとFrustum Cullingされて困る。&lt;br&gt;&lt;br&gt;そこで、BoudingBoxを拡張したQuadを事前生成して通常のMeshRendererで描画できるようにした。&lt;a href=&#34;https://t.co/Askoyvnq0X&#34;&gt;https://t.co/Askoyvnq0X&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1018214911367761920?ref_src=twsrc%5Etfw&#34;&gt;2018年7月14日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/pull/10&#34;&gt;RaymarchingQuadMeshCreator by gam0022 · Pull Request #10 · gam0022/unity-demoscene&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;トンネルのモデリング&#34;&gt;トンネルのモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tunnel_original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tunnel.jpg&#34; alt=&#34;tunnel&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トンネルはMenger spongeという有名なフラクタル図形をベースにしています。
回転のfoldのテクニックを利用して万華鏡のように見せたり、modをつかった図形の繰り返しのテクニックを適用しました。&lt;/p&gt;

&lt;p&gt;回転のfoldは次の記事で紹介しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold（折りたたみ）による形状設計 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上の4種類の画像はいずれも同じ距離関数によるトンネルの様子です。
パラメータを変化させることで形状や色などを演出に合わせて変更できるようにしました。&lt;/p&gt;

&lt;h1 id=&#34;海面のモデリング&#34;&gt;海面のモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/sea.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/sea.jpg&#34; alt=&#34;sea&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;海面は平面として衝突判定を行い、ノーマルマップだけで波が立っているように見せています。
こちらは以前にWebGLによって実装した『&lt;a href=&#34;https://gam0022.net/blog/2017/06/30/raymarching-kado/&#34;&gt;正解するカドの「カド」をレイマーチングでリアルタイム描画する | gam0022.net&lt;/a&gt;』と同じアプローチの軽量化方法です。&lt;/p&gt;

&lt;p&gt;ところで、上記の記事の作品と異なり、本作品ではLODを一切行っておりません。
カメラワーク的に海面に近づかないため、そもそもLODが必要なかったのと、
マーチングループ中でテクスチャのフェッチをするとUnityのシェーダーのコンパイルが激重になる現象を回避するためです。&lt;/p&gt;

&lt;p&gt;海面の質感は、Gバッファに書き込むパラメータの調整だけで再現しました。
ディファードレンダリングなので不透明オブジェクトとして当然ライティングされているのですが、どことなく海中を感じさせるような半透明の質感を擬似的に再現できたのではないかと思います。&lt;/p&gt;

&lt;h1 id=&#34;戦闘機のモデリング&#34;&gt;戦闘機のモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/plane.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/plane.jpg&#34; alt=&#34;plane&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;戦闘機は距離関数でモデリングしました。&lt;/p&gt;

&lt;p&gt;3つのBoxの大きさをcos/sin/abs等で調整しつつ、smoothminによるメタボールでBoxを融合することで、流線形のSFっぽい戦闘機をモデリングしました。&lt;/p&gt;

&lt;p&gt;また、フラグメントシェーダーの負荷軽減のために&lt;a href=&#34;http://i-saint.hatenablog.com/entry/2015/08/24/225254&#34;&gt;Object Space Raymarching&lt;/a&gt;を行いました。
Full Screen Quadを使わずに戦闘機と同じ大きさのSphereを配置し、Sphereのシェーダーでレイマーチングをしています。
上記の画像を拡大するとSphereのワイヤーフレームを確認できます。&lt;/p&gt;

&lt;h1 id=&#34;演出の実装&#34;&gt;演出の実装&lt;/h1&gt;

&lt;h2 id=&#34;textmeshproによるフォントのレンダリング&#34;&gt;TextMeshProによるフォントのレンダリング&lt;/h2&gt;

&lt;p&gt;フォントはプロシージャルではなくテクスチャを使用しています。
TextMeshProのEditorツールを利用して &lt;a href=&#34;https://www.fontspace.com/mixofx/azonix&#34;&gt;Azonix fontのデータ&lt;/a&gt;からSDFのフォントのアトラステクスチャを生成しました。&lt;/p&gt;

&lt;p&gt;生成したアトラステクスチャはTextMeshProのシェーダーでレンダリングしています。&lt;/p&gt;

&lt;p&gt;次のような簡単な文字の出現と消滅のエフェクトを、TextMeshProの標準シェーダーの一部を改造して実装しました。
この演出に関する解説を&lt;a href=&#34;https://qiita.com/advent-calendar/2018/unity2&#34;&gt;Unity #2 Advent Calendar 2018&lt;/a&gt;の19日目の記事で行いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/f3b7a3e9821a67a5b0f3&#34;&gt;[Unity] カスタムシェーダーでTextMeshProに独創的な演出を加える&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TextMeshPro シェーダー遊び その3&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/creativecoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#creativecoding&lt;/a&gt; &lt;a href=&#34;https://t.co/bUJvfyDhBr&#34;&gt;pic.twitter.com/bUJvfyDhBr&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1056398353569697792?ref_src=twsrc%5Etfw&#34;&gt;2018年10月28日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;animation-track-vs-custom-track&#34;&gt;Animation Track vs Custom Track&lt;/h2&gt;

&lt;p&gt;UnityのTimelineではトラックを自作することができます（以降、自作トラックのことをCustom Trackと書きます）。&lt;/p&gt;

&lt;p&gt;Custom Trackの実装はそれなりに工数がかかります。
たとえば、クリップのパラメータを1つでも増やすと複数箇所に変更が発生します。
工数が限られている場合や試行錯誤しながら色々なパータンを作る場合には、Animation Trackでは実現できないのかを事前に確認することをおすすめします。&lt;/p&gt;

&lt;p&gt;本作品でも、基本的にはAnimation Trackを利用し、アニメーションでは制御できないTextMeshProの文字列指定においてのみCustom Trackを利用する方針としました。&lt;/p&gt;

&lt;h2 id=&#34;パーティクル&#34;&gt;パーティクル&lt;/h2&gt;

&lt;p&gt;パーティクルはUnityのParticleSystemを利用しました。&lt;/p&gt;

&lt;p&gt;次の画像はポストエフェクトとSkyboxをOFFにした状態でパーティクルをワイヤーフレーム表示したものです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/particle_discard.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/particle_discard.png&#34; alt=&#34;particle_discard&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;パーティクルの形状は5種類でしたが、パーティクル用のモデルは1種類しか用意しませんでした。
四角形のQuadをフラグメントシェーダーでdiscardして形状を変化させました。
すべてのパーティクルを1マテリアルで表現できるので、全パーティクルを1ドローコールで描画できました。&lt;/p&gt;

&lt;p&gt;4種類のパーティクルが当時に登場する演出では、Custom Vertex Streamsを用いてランダム値をシェーダーに渡し、シェーダーで形状の切り替えを行いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://goisagi-517.hatenablog.com/entry/2018/05/15/011845&#34;&gt;【Unity】Shuriken Particle「Custom Vertex Streams」  - ゴイサギ日記&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ワームホールの実装&#34;&gt;ワームホールの実装&lt;/h2&gt;

&lt;p&gt;「ワームホールの中身だけ別の世界になる」演出にも戦闘機と同じObject Space Raymarchingの仕組みを利用しました。&lt;/p&gt;

&lt;p&gt;まずHoudiniでワームホールの八角形のポリゴンメッシュを作成しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/houdini.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/houdini.png&#34; alt=&#34;houdini&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この八角形のメッシュのシェーダーでObject Space Raymarchingを行えば、別の世界と繋がる演出ができます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/gate.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/gate.jpg&#34; alt=&#34;gate&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ところが、カメラの原点からレイを進めると、別世界が3Dの立体映像のように飛び出してしまうという罠にハマってしまいました。
この問題はレイを物体の表面から進めることで回避できました。&lt;/p&gt;

&lt;p&gt;ワームホールの内側は現在の世界（上の画像では海の世界）のレイマーチングのシェーダーを無効にしたかったので、Stencilを利用しようとしたのですが、
UnityのディファードレンダリングではStencilの利用が制限されていました。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/SL-Stencil.html&#34;&gt;ShaderLab: ステンシル - Unity マニュアル&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deferred レンダリングパスでレンダリングするオブジェクトのためのステンシル機能はいくらか制限されます。それらの 2 つのステージの間、シェーダーで定義されるステンシルステートは無視され、最終的なパスの間に考慮されるだけです。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;そこで、DepthテストとRenderQueueによる制御でStencilを代用しました。&lt;/p&gt;

&lt;h2 id=&#34;reflectionprobeの映り込みによる演出&#34;&gt;ReflectionProbeの映り込みによる演出&lt;/h2&gt;

&lt;p&gt;2回目のワームホール出現時（2:05〜）に海面が黒く侵食されていく演出があります。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/NMNJV-Pbqtk?start=125&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;これは、ワームホールの向こう側の景色がReflectionProbeに映り込み、Unityのライティング機能によって自動的に水面に反映された結果です。
意図的に演出したものではなく偶然の産物でしたが、気に入ったのでこのまま採用しました。&lt;/p&gt;

&lt;h2 id=&#34;揺らぎ&#34;&gt;揺らぎ&lt;/h2&gt;

&lt;!-- 直す --&gt;

&lt;p&gt;揺らぎは2箇所で利用しました。
単純でコストもかからない工夫ですが、効果は大きいと感じました。&lt;/p&gt;

&lt;p&gt;カメラにfbmノイズを加えて手ブレ感を出すことで臨場感が生まれました。&lt;/p&gt;

&lt;p&gt;それから、戦闘機をcos波で振り子のように左右に揺らしています。
戦闘機の動き自体はZ軸に直進するだけなのですが、機体の揺れとカメラワークによって旋回しているような雰囲気が出ているのではないでしょうか。&lt;/p&gt;

&lt;h1 id=&#34;音楽との同期方法&#34;&gt;音楽との同期方法&lt;/h1&gt;

&lt;h2 id=&#34;ビート単位でのシェーダー制御&#34;&gt;ビート単位でのシェーダー制御&lt;/h2&gt;

&lt;p&gt;シェーダーの入力をビートにし、演出を「ビート単位」で制御することで、映像と音楽を同期させました。
時間単位（秒単位）で制御するよりも、BPM変更に柔軟に対応できるというメリットがあります。&lt;/p&gt;

&lt;p&gt;秒数 &lt;code&gt;time&lt;/code&gt; を特定のBPM &lt;code&gt;bpm&lt;/code&gt; のビートに変換するには &lt;code&gt;beat = time * bpm / 60&lt;/code&gt; を計算します。&lt;/p&gt;

&lt;h2 id=&#34;カメラのカット切り替えやパーティクルの同期&#34;&gt;カメラのカット切り替えやパーティクルの同期&lt;/h2&gt;

&lt;p&gt;カメラのカットやパーティクルのエミットのタイミングといったシェーダーで制御していない部分は、
音楽に合わせてTimelineのクリップを手動で配置する必要がありました。&lt;/p&gt;

&lt;p&gt;こちらは音楽を120BPMで制作していただいたことで、かなり楽に解決できました。&lt;/p&gt;

&lt;p&gt;120BPMでは、1ビートが0.5秒となります。&lt;/p&gt;

&lt;p&gt;4分の4拍子であれば1小節の長さが2秒となるため、カメラのカット切り替えを2秒単位にすると音楽と映像が自然に同期します。
同様に、4分の3拍子であればカット切り替えを1.5秒単位にすればよいわけです。&lt;/p&gt;

&lt;p&gt;パーティクルは、エミット間隔を0.5秒ごとに設定することで音楽とタイミングを合わせています。&lt;/p&gt;

&lt;h1 id=&#34;来年の抱負&#34;&gt;来年の抱負&lt;/h1&gt;

&lt;p&gt;次はライティングに凝ってみたいです。&lt;/p&gt;

&lt;p&gt;物理ベースレンダリング（PBR）で攻めるのであれば今回のライティングはUnityに任せる作戦で正解だと思いますが、
非現実的なレンダリング（NPR）には対応できないので、ディファードレンダリングのライティングパスの独自実装などを調査したいです。&lt;/p&gt;

&lt;p&gt;他にも、Unityの新機能のScriptable Render Pipeline (SRP) や
High Definition Render Pipeline（HDRP）とレイマーチングを組み合わせる検証などもしてみたいです。&lt;/p&gt;

&lt;h1 id=&#34;おわりに&#34;&gt;おわりに&lt;/h1&gt;

&lt;p&gt;『WORMHOLE』の映像を作るための取り組みや手法について技術的な視点で解説しました。&lt;/p&gt;

&lt;p&gt;上記の通り、『WORMHOLE』の制作にはUnityの機能やライブラリを多く利用しています。
巨人の肩の上に立つことで表現の部分に注力でき、3週間弱という短い制作期間の中で完成度の高い作品に仕上げることができました。&lt;/p&gt;

&lt;p&gt;とはいえ、制作期間中は『WORMHOLE』を受け入れてもらえないのではと常に不安を感じていました。
デモシーンの世界ではゲームエンジンの機能に頼らない高度な実装力こそ評価されると思っていたからです。
そんな予想に反し、Unityで作成したデモ作品を高く評価していただけて大変光栄です。&lt;/p&gt;

&lt;p&gt;Unityには初心者～上級者まで様々なレベルの方を対象とした資料や教材があります。
『WORMHOLE』では使用しませんでしたが、たくさんのアセットも用意されています。
デモシーンに興味はあるもののハードルが高そうで踏みとどまっている方や、レンダリング技術の学習に挫折してしまった方に、Unityでもデモ作品を作成できることをお伝えしたいです。
また、日頃の業務でUnityを利用している方に、自分でも作れそうな身近なものとしてデモシーンに興味を持ってもらえれば嬉しいです。
『WORMHOLE』が新たなデモシーナーを生み出すきっかけとなれば幸いです。&lt;/p&gt;

&lt;p&gt;最後に、素晴らしいサウンドを生み出してくれたさだきちさんに感謝申し上げます。
チームでTDFに参加するのは今回が初めてでしたが、非常に良い経験をさせてもらいました。
自分の映像にかっこいい音楽が組み合わさった時の喜びや興奮は忘れられません！ありがとうございました！！&lt;/p&gt;

&lt;h1 id=&#34;関連情報&#34;&gt;関連情報&lt;/h1&gt;

&lt;h2 id=&#34;wormhole-を高画質で見るには&#34;&gt;『WORMHOLE』を高画質で見るには&lt;/h2&gt;

&lt;p&gt;下記の実行ファイルか動画ファイルをダウンロードしていただくと、エンコード前の綺麗な画質でご覧いただけます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://files.scene.org/view/parties/2018/tokyodemofest18/demo/wormhole.zip&#34;&gt;Windowsの実行ファイル&lt;/a&gt;（GTX1070以上のGPU推奨）&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1GxyxjOyGBRcofMVKILmJtlmYaMZ5XoGx/view&#34;&gt;動画ファイル&lt;/a&gt;（ブラウザ上だとエンコードされた状態で再生されるのでダウンロードしてください）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;wormhole-の感想をお待ちしております&#34;&gt;『WORMHOLE』の感想をお待ちしております！&lt;/h2&gt;

&lt;p&gt;pouet.netという世界中のデモ情報を集めたポータルサイトに作品を公開しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=79380&#34;&gt;pouet.net内の『WORMHOLE』のページ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作品の感想をYouTubeやpouet.netでいただけると泣いて喜びます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メガデモ勉強会!2018で発表しました</title>
      <link>https://gam0022.net/blog/2018/03/16/demoscene-study-session/</link>
      <pubDate>Fri, 16 Mar 2018 10:14:35 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/03/16/demoscene-study-session/</guid>
      <description>&lt;p&gt;3/10（土）に開催された&lt;a href=&#34;https://atnd.org/events/93843&#34;&gt;メガデモ勉強会! 2018&lt;/a&gt;で発表しました。&lt;/p&gt;

&lt;p&gt;発表タイトルは「もっと綺麗で写実的な絵作りをしたい！レイマーチング向けのシェーディング技術」です。&lt;/p&gt;

&lt;p&gt;発表の概要はこんな感じです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;レイマーチングのおさらい&lt;/li&gt;
&lt;li&gt;レイマーチングでいい感じにシェーディングするための理論と実践

&lt;ul&gt;
&lt;li&gt;写実的なレンダリングに不可欠な &lt;strong&gt;大域照明&lt;/strong&gt; を説明&lt;/li&gt;
&lt;li&gt;大域照明を構成する間接照明を近似する &lt;strong&gt;AO&lt;/strong&gt; を説明&lt;/li&gt;
&lt;li&gt;レイマーチングによるAO計算の実装を図で解説&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;レイマーチングによるマテリアル実装のベストプラクティスを紹介&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AOがどういう意味を持つのか、大域照明にどんな関係にあるのか、などを学んでいただけたら嬉しいです。
レイマーチングによるAO計算の動作原理を図で解説した日本語の資料は見たことが無いので、
この発表を聞いて「なるほどな」と思ってもらえれば幸いです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;74ea75d0686849238368f73150a7adba&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です😇 &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;a href=&#34;https://t.co/pxqSbH3DPl&#34;&gt;https://t.co/pxqSbH3DPl&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ😇 (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/972340970892111874?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;発表の紹介と感想&#34;&gt;発表の紹介と感想&lt;/h1&gt;

&lt;p&gt;自分以外の発表について、自分の感想を混じえながら紹介します。&lt;/p&gt;

&lt;h2 id=&#34;notargs-さんの-デモのためのunity講座&#34;&gt;@notargs さんの「デモのためのUnity講座」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日のメガデモ勉強会で発表した資料です&lt;a href=&#34;https://t.co/DStmEyNQ5a&#34;&gt;https://t.co/DStmEyNQ5a&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;/p&gt;&amp;mdash; のたぐすキャット (@notargs) &lt;a href=&#34;https://twitter.com/notargs/status/972345507111616512?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;去年の末に&lt;a href=&#34;https://gam0022.net/blog/2017/12/25/unity-demoscene/&#34;&gt;Unityによるデモを作成&lt;/a&gt;を試みていたところだったので、参考になる情報がたくさんありました。&lt;/p&gt;

&lt;p&gt;音響にエフェクトをかけるための&lt;code&gt;OnAudioFilterRead&lt;/code&gt;で入力を無視して波形を作れば、プロシージャルに音楽も作れますね。
良いことを知りました。&lt;/p&gt;

&lt;h2 id=&#34;soma-arc-さんの-鏡映によるフラクタルとglslによる描画&#34;&gt;@soma_arc さんの「鏡映によるフラクタルとGLSLによる描画」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; 「鏡映によるフラクタルとGLSLによる描画」で使用した資料を公開しました．本日はありがとうございました．&lt;a href=&#34;https://t.co/r3o3Rajbpn&#34;&gt;https://t.co/r3o3Rajbpn&lt;/a&gt;&lt;a href=&#34;https://t.co/wL36mO8d6e&#34;&gt;https://t.co/wL36mO8d6e&lt;/a&gt;&lt;/p&gt;&amp;mdash; 蘇摩 (@soma_arc) &lt;a href=&#34;https://twitter.com/soma_arc/status/972426826772434945?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;ずっと聞いてみたかった内容でした。資料も説明も上手で理解しやすかったです。&lt;/p&gt;

&lt;p&gt;以前にブログで紹介した&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold&lt;/a&gt;に近いものを感じました。&lt;/p&gt;

&lt;p&gt;foldでは平面の鏡を使いましたが、この発表では円形の鏡を使うイメージだと理解しました。&lt;/p&gt;

&lt;p&gt;円の鏡映では、まず円形の鏡を配置します。すると鏡同士で相互に反射するので、合わせ鏡のように、映り込んだ円がさらに再帰的に別の円の鏡に映り込みます。反射の再帰の深度に応じて色をつけると、単純な円から美しい模様が生成できると理解しました。&lt;/p&gt;

&lt;p&gt;円の外にテクスチャを置いた例や、2D -&amp;gt; 3D に拡張した球の鏡による例も紹介されていました。&lt;/p&gt;

&lt;h2 id=&#34;fl1ne-さんの-tokyodemofestとfrontl1neのご紹介&#34;&gt;@FL1NE   さんの「TokyoDemoFestとFRONTL1NEのご紹介」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; &lt;a href=&#34;https://t.co/NkgvYkD8eH&#34;&gt;https://t.co/NkgvYkD8eH&lt;/a&gt;&lt;/p&gt;&amp;mdash; ΓL1ИΞ@GDC2018 (@FL1NE) &lt;a href=&#34;https://twitter.com/FL1NE/status/972377117815009280?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Tokyo Demo Fest 2018 は10月〜11月に開催予定！&lt;/p&gt;

&lt;p&gt;Meet the Meatのパワーワード感がすごい！&lt;/p&gt;

&lt;h2 id=&#34;fms-cat-さんの-glslで音楽を作ります&#34;&gt;@FMS_Cat さんの「GLSLで音楽を作ります」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の勉強会で使ったサンプルコードおよびスライドです。 &lt;a href=&#34;https://t.co/tkAqql021E&#34;&gt;https://t.co/tkAqql021E&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;/p&gt;&amp;mdash; JPEG Depression (@FMS_Cat) &lt;a href=&#34;https://twitter.com/FMS_Cat/status/972495648883752960?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;シェーダーで音楽を作ってみたいと思いながらも、音楽知識が0で諦めていた私のような人のための発表でした。&lt;/p&gt;

&lt;p&gt;資料も説明も素晴らしくて、素人の私でもすっと頭に入ってきました。&lt;/p&gt;

&lt;p&gt;「ステレオサウンド」「音量・音階・音色」「コード」のような基礎用語の説明がカバーされていて助かりました。
GLSLの実装を踏まえた説明だったので、よく知らない音楽の概念も理解できました。&lt;/p&gt;

&lt;p&gt;特に印象的だったのは楽器編成です。
sin波や矩形波といった単純な波形をベースにして、本物の楽器のような音色を作れることに感動しました。&lt;/p&gt;

&lt;p&gt;またコードを構成する音からランダムに音を選択し、オクターブもランダムに変化させることで、
ランダムながらかなり曲っぽい感じになることにびっくりしました（アルペジオ？）。&lt;/p&gt;

&lt;p&gt;音楽は諦めかけていましたが、この発表のおかげで自分で音楽を制作する道筋が見えました。
発表で使われたコードはGitHubでも公開されているので、実際にShadertoyで動かして理解を深めているところです。
素敵な発表ありがとうございました！&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;勉強会から帰宅した後、FMS_Catさんの発表でオススメされていた「Moleman 2」という動画を家で見ました。
メガデモの起源から現在に至るまで、メガデモの歴史を1時間30分に凝縮された動画になっていて、デモシーナー必見の内容でした。&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/iRkZcTg1JWU&#34; frameborder=&#34;0&#34; allow=&#34;autoplay; encrypted-media&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;さいごに&#34;&gt;さいごに&lt;/h1&gt;

&lt;p&gt;ずっと気になっていた内容を聞けて大満足でした。どの発表も資料も説明も分かりやすくて素晴らしかったです。
懇親会では、以前の自分の発表でレイマーチングを知って、卒業制作にレイマーチングを使ったという学生とお話しました。
自分の活動を通して何かを得た人もいるということに嬉しくなりました。&lt;/p&gt;

&lt;p&gt;メガデモ制作のモチベーションが高まってきたので、今年の10〜11月のTDFに向けて頑張りたいです！&lt;/p&gt;

&lt;p&gt;運営の方々、発表者の方々、会場を提供していただいたさくらインターネット様、ご参加いただいた方々、ありがとうございました！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unityでメガデモ制作に挑戦（uRaymarchingとTimelineを試す）</title>
      <link>https://gam0022.net/blog/2017/12/25/unity-demoscene/</link>
      <pubDate>Mon, 25 Dec 2017 09:30:11 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2017/12/25/unity-demoscene/</guid>
      <description>&lt;p&gt;これは &lt;a href=&#34;https://qiita.com/advent-calendar/2017/unity2&#34;&gt;Unity #2 Advent Calendar 2017&lt;/a&gt; 21日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%A2%E3%82%B7%E3%83%BC%E3%83%B3&#34;&gt;デモシーン&lt;/a&gt;界隈では、美しいCGアニメーションをリアルタイムに生成するプログラムを「デモ」と呼びます。&lt;/p&gt;

&lt;p&gt;今回はUnityを使ったデモの制作に初挑戦しました。
13秒の短い無音の動画です。&lt;/p&gt;

&lt;iframe width=&#34;720&#34; height=&#34;405&#34; src=&#34;https://www.youtube.com/embed/BZGO5xXuPj8&#34; frameborder=&#34;0&#34; gesture=&#34;media&#34; allow=&#34;encrypted-media&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;!--
[![THE GLOW](/images/posts/2017-12-21-unity-demoscene/cut1.jpg)](/images/posts/2017-12-21-unity-demoscene/cut1.jpg)
--&gt;

&lt;h1 id=&#34;作品の解説&#34;&gt;作品の解説&lt;/h1&gt;

&lt;p&gt;「レイマーチングで動的に生成したモデル」と「ポリゴンメッシュのモデル」を混在させた作品です。
ロボットは通常の3Dモデルですが、床や柱のモデルはレイマーチングでプロシージャルに生成しました。&lt;/p&gt;

&lt;p&gt;レイマーチングにはuRaymarchingというAssetを利用しました。&lt;/p&gt;

&lt;p&gt;映像作品と相性が良さそうなので、Unity2017のTimelineも利用しました。&lt;/p&gt;

&lt;p&gt;今回は試作という意味から、uRaymarchingとTimelineの他にも様々なアセットを試しました。
色々と試行錯誤をしたので、この記事ではそのノウハウを共有したいと思います。&lt;/p&gt;

&lt;p&gt;Unityのバージョンは執筆時点の最新版である2017.2.1f1を用いました。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;uraymarchingによるレイマーチング&#34;&gt;uRaymarchingによるレイマーチング&lt;/h2&gt;

&lt;p&gt;uRaymarchingはレイマーチングのシェーダの作成をサポートするシェーダ群とエディタ拡張です。
開発者は&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching | GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tips.hecomi.com/entry/2016/10/11/225541&#34;&gt;Unity でレイマーチングするシェーダを簡単に作成できるツールを作ってみた&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;uRaymarchingではDefferedシェーディングを採用しており、レイマーチングのシェーダはGバッファに対して結果を書き込みます。
そのため、今回のようにレイマーチングとポリゴンのモデルが混在したシーンであっても、一貫したシェーディングを実現できました！&lt;/p&gt;

&lt;p&gt;レイマーチングの衝突判定などの共通処理は、uRaymarchingが提供する共通のシェーダが肩代わりしてくれます。
uRaymarchingの利用者は、レイマーチングの距離関数の定義とGバッファの書き込みの処理だけに集中できるため、開発効率が向上しました。&lt;/p&gt;

&lt;p&gt;具体的な使い方を簡単に説明しますと、まずはuRaymarchingのエディタ拡張でレイマーチングシェーダの雛形を作成します。
次に雛形シェーダの2つの関数をカスタマイズすれば、独自のレイマーチングシェーダをお手軽に作成できました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;距離関数の定義を&lt;code&gt;DistanceFunction&lt;/code&gt;関数に記述&lt;/li&gt;
&lt;li&gt;Gバッファへの書き込み処理を&lt;code&gt;PostEffect&lt;/code&gt;関数に記述&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;uRaymarchingのチュートリアル動画です。&lt;/p&gt;

&lt;iframe width=&#34;720&#34; height=&#34;540&#34; src=&#34;//www.youtube.com/embed/AppyVflAagc?wmode=transparent&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;距離関数の設計&#34;&gt;距離関数の設計&lt;/h3&gt;

&lt;p&gt;Boxの組み合わせだけでシーンを構成しました。
床はBoxを敷き詰めているのは見た目通りだと思いますが、柱もBoxの組み合わせで作っています！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfoldの記事&lt;/a&gt;で紹介した回転のfoldを利用して、
Boxから上から見たときに多角形になる柱を生成しました。&lt;/p&gt;

&lt;p&gt;単純なBoxの形状だけでも、時間経過で形状が変化する面白い形ができたと思っています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/distance-function.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/distance-function.jpg&#34; alt=&#34;柱の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;床がランダムな順番に光る演出&#34;&gt;床がランダムな順番に光る演出&lt;/h3&gt;

&lt;p&gt;床をランダムに光らせる演出は自分でも気に入っています。&lt;/p&gt;

&lt;p&gt;この演出はお手軽な方法で実装できました！&lt;/p&gt;

&lt;p&gt;まずは、Y座標に応じて光るように、Gバッファに書き出すemissionを設定します。
光らせるY座標の位置は時間でアニメーションさせます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 _SlideEmission;

inline void PostEffect(RaymarchInfo ray, inout PostEffectOutput o)
{
    float a = frac(4.0 * ray.endPos.y - 2.0 * _Time.x - 0.5);
    float width = 0.04;
    o.emission = _SlideEmission * abs(sin(PI * 12.0 * _Time.x)) * step(a, width) * ((a + 0.5 * width) / width);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、床のブロックの高さの動きをランダムに設定します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float dFloor(float3 pos)
{
    float3 p = pos;
    p.xz = Repeat(p.xz, 0.5);
    p.y += 1 + 0.1 * sin(36.0 * _Time.x + 2.0 * Rand(floor(2.0 * pos.xz)));
    return sdBox(p, float3(0.2, 0.2, 0.2));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけで、床をにランダムに光らせる演出の完成です！&lt;/p&gt;

&lt;p&gt;床の高さがバラバラになっているので、等高線で光らせるとタイミングが微妙にずれて、いい感じにバラバラのタイミングで光ります！&lt;/p&gt;

&lt;h3 id=&#34;uraymarchingのトラブルシューティング&#34;&gt;uRaymarchingのトラブルシューティング&lt;/h3&gt;

&lt;p&gt;2点だけつまずいたポイントがあったので、後学のためにメモを残しておきます。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ShaderTemplates で Direct GBuffer を選択すると、影が落ちない（Shadow Caster が動作しない）

&lt;ul&gt;
&lt;li&gt;これはUnityの仕様に原因があるらしく、hecomiさんの記事にも書いてありました&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;プロジェクトの設定で &lt;code&gt;metalEditorSupport: 0&lt;/code&gt; にしないと、Macで動作しない

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/commit/47f19613bbc032bef1b8b35b9b972f3f9983debc&#34;&gt;修正のコミット&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;timelineとの連携&#34;&gt;Timelineとの連携&lt;/h2&gt;

&lt;p&gt;Unity2017のTimeline機能でカメラワークやロボットの動き、UI上のテキストなどの演出の制御をしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline.jpg&#34; alt=&#34;timeline&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;カメラワーク&#34;&gt;カメラワーク&lt;/h3&gt;

&lt;p&gt;Timelineからゲームオブジェクトを操作する2つの方法があります。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Playables&lt;/code&gt;を実装・利用する方法

&lt;ul&gt;
&lt;li&gt;APIは複雑で、気軽に使うのは難しい&lt;/li&gt;
&lt;li&gt;作り込めば何でもできる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ITimeControl&lt;/code&gt;を継承したコンポーネントを実装・利用する方法

&lt;ul&gt;
&lt;li&gt;APIは単純で、気軽に使える&lt;/li&gt;
&lt;li&gt;できることが少ない（クリップの現在時間しか受け取れない）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;カメラワークの制御をどちらで行うのか悩みましたが、最終的には以下の理由で&lt;code&gt;ITimeControl&lt;/code&gt;に決めました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;とりあえずカメラを動かすだけなら、&lt;code&gt;ITimeControl&lt;/code&gt;が手っ取り早いと感じた&lt;/li&gt;
&lt;li&gt;カメラワークを汎用的な&lt;code&gt;Playables&lt;/code&gt;に落とし込む時間もスキルも足りなかった&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;とりあえずカメラワークを&lt;code&gt;ITimeControl&lt;/code&gt;で実装することはできましたが、
&lt;code&gt;ITimeControl&lt;/code&gt;では再生時間の情報しか受け取れず、クリップごとにパラメータを持たすことすらできません。
三角関数などを駆使してカメラのtransformを操作して、無理やりカメラワークを実装しましたが、
&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/blob/bdb84d7517b812f742363c971174d9435cea0cb2/Assets/Demoscene/TheGlow/TheGlowCameraWork.cs&#34;&gt;職人芸すぎてメンテナンスが困難なコード&lt;/a&gt;になりました。&lt;/p&gt;

&lt;p&gt;今回は満足するものはできなかったので、次回はこれらの方法でカメラワークに再挑戦したいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/95266&#34;&gt;Default Playables&lt;/a&gt;
に含まれているTimeline Playable Wizardを使えば、&lt;code&gt;Playables&lt;/code&gt;の雛形コードを作成できるそうなので、これを利用して独自&lt;code&gt;Playables&lt;/code&gt;の実装に再挑戦する&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tsubakit1.hateblo.jp/entry/2017/06/15/225504&#34;&gt;Cinemachine&lt;/a&gt;というUnity公式のカメラワークを作るための&lt;code&gt;Playables&lt;/code&gt;を利用する&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ロボットの動き&#34;&gt;ロボットの動き&lt;/h3&gt;

&lt;p&gt;ロボットに&lt;code&gt;Animator&lt;/code&gt;コンポーネントをアタッチすれば、普通に&lt;code&gt;Animation Track&lt;/code&gt;でクリップを再生できました。&lt;/p&gt;

&lt;p&gt;2つの&lt;code&gt;Animation Track&lt;/code&gt;のクリップを重ねるように配置すると、モーションのブレンドができるので、
待機モーションから走るモーションへのブレンドはこれを利用しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Animation Track&lt;/code&gt;の中に作成できる&lt;code&gt;Override Track&lt;/code&gt;でキャラクターの移動を実現しました。
&lt;code&gt;Override Track&lt;/code&gt;ではパラメータのアニメーションのカーブを直接編集できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline-animation.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline-animation.png&#34; alt=&#34;Animation Trackによるロボットの制御&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;テキスト&#34;&gt;テキスト&lt;/h3&gt;

&lt;p&gt;後半のタイトル文字には&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/84126&#34;&gt;TextMesh Pro&lt;/a&gt;を使用しました。
Timelineとの連携は、Activation Trackを使って実現しています。
1文字ずつ表示する部分は、TextMesh ProのサンプルのTextConsoleSimulatorクラスを使って制御しています。
しかし、このクラスはTimelineは考慮されておらず、通常再生時と録画時とで表示速度がずれる問題が残りました。
将来的には独自の&lt;code&gt;Playables&lt;/code&gt;を実装して、これらの問題を解決したいです。&lt;/p&gt;

&lt;h3 id=&#34;パーティクル&#34;&gt;パーティクル&lt;/h3&gt;

&lt;p&gt;ロボットの足元の火花には、&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/73777&#34;&gt;Unity Particle Pack&lt;/a&gt;
に含まれている「ElectricalSparksEffect」を使用しました。
Timelineとの連携は、Activation Trackを使って実現しています。&lt;/p&gt;

&lt;h2 id=&#34;その他&#34;&gt;その他&lt;/h2&gt;

&lt;h3 id=&#34;ポストエフェクト&#34;&gt;ポストエフェクト&lt;/h3&gt;

&lt;p&gt;ポストエフェクトには、&lt;a href=&#34;https://github.com/Unity-Technologies/PostProcessing&#34;&gt;Post-processing Stack v2&lt;/a&gt;を利用しました。&lt;/p&gt;

&lt;p&gt;以下のポストエフェクトを利用しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fog

&lt;ul&gt;
&lt;li&gt;レイマーチングでは遠景にエイリアシングが発生して汚くなる弱点があるので、Fogで遠景を暗くしました&lt;/li&gt;
&lt;li&gt;現実でも距離の二乗に比例して光が減衰するので、Fogで現実感が増します&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Bloom

&lt;ul&gt;
&lt;li&gt;Bloomは明るい光源からの光が周囲に漏れるように見える効果です&lt;/li&gt;
&lt;li&gt;今回はemissionを多用したシーンなので、Bloomが効果的に機能しました&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ambient Occlusion

&lt;ul&gt;
&lt;li&gt;AOで大域照明感を出しました&lt;/li&gt;
&lt;li&gt;暗いシーンなので、違いは分かりにくいかもしれませんね&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ポストエフェクトの有無で比較画像を用意しました。
左がポストエフェクトOFF、右がポストエフェクトONです。
違いが一目瞭然ですね！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/postprocessing.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/postprocessing.jpg&#34; alt=&#34;ポストエフェクトの有無で比較&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;3d素材&#34;&gt;3D素材&lt;/h3&gt;

&lt;p&gt;ロボットの3Dモデルは&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;を使わせていただきました。&lt;/p&gt;

&lt;p&gt;モーションは&lt;a href=&#34;http://unity-chan.com/download/releaseNote.php?id=UnityChan&#34;&gt;ユニティちゃん 3Dモデルデータ&lt;/a&gt;を利用しました。&lt;/p&gt;

&lt;h3 id=&#34;動画撮影&#34;&gt;動画撮影&lt;/h3&gt;

&lt;p&gt;冒頭のYouTubeの動画は、&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder&#34;&gt;Unity Recorder&lt;/a&gt;を使って撮影しました。
このアセットは、Unityの画面を録画し、動画として保存してくれます。
固定フレームレートに対応しているので、非力なPCでも撮影が可能です。&lt;/p&gt;

&lt;p&gt;Unity Recorderには、Timelineとの連携機能もありました。
Recorder trackをタイムラインに追加すると、エディター再生時に自動で録画ができます。&lt;/p&gt;

&lt;p&gt;注意点として、&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder/issues/11&#34;&gt;v0.1ではUIが録画できないという不具合&lt;/a&gt;がありました。
&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder/releases&#34;&gt;GitHubのReleases&lt;/a&gt;から、v0.2（現時点の最新版）をダウンロードすることで解決できました。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;Unityを上手に利用すれば効率的にデモ作成できると感じました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;便利なAssetがたくさん提供されている&lt;/li&gt;
&lt;li&gt;リアルタイムに見た目を確認しながら、シェーダのパラメータを調整できる

&lt;ul&gt;
&lt;li&gt;シェーダ（ShaderLab）に数行コードを足すだけで、インスペクタにパラメータを露出できる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リアルタイムに見た目を確認しながら、シェーダやスクリプトを編集できる

&lt;ul&gt;
&lt;li&gt;Unityに標準搭載されているホットリロード機能によって、シーンの再生中でもシェーダやスクリプトの変更が反映できる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!--
まだUnityを使いこなせていない感があるので、もっとUnityの経験値を貯めたいです。
--&gt;

&lt;h1 id=&#34;ソースコード&#34;&gt;ソースコード&lt;/h1&gt;

&lt;p&gt;UnityのプロジェクトをGitHubで公開しています。スターが欲しいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene&#34;&gt;Unity Demoscene | GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回のデモ用のファイルは&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/tree/master/Assets/Demoscene/TheGlow&#34;&gt;&lt;code&gt;Assets/Demoscene/TheGlow&lt;/code&gt;&lt;/a&gt;のディレクトリにあります。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
